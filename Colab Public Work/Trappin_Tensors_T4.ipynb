{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "                                Copyright 2025 Evan Wesley\n",
        "                                Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "                                you may not use this file except in compliance with the License.\n",
        "                                You may obtain a copy of the License at\n",
        "                                http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "                                Unless required by applicable law or agreed to in writing, software\n",
        "                                distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "                                WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "                                See the License for the specific language governing permissions and\n",
        "                                limitations under the License.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                                  Apache License\n",
        "                           Version 2.0, January 2004\n",
        "                        http://www.apache.org/licenses/\n",
        "\n",
        "   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n",
        "\n",
        "   1. Definitions.\n",
        "\n",
        "      \"License\" shall mean the terms and conditions for use, reproduction,\n",
        "      and distribution as defined by Sections 1 through 9 of this document.\n",
        "\n",
        "      \"Licensor\" shall mean the copyright owner or entity authorized by\n",
        "      the copyright owner that is granting the License.\n",
        "\n",
        "      \"Legal Entity\" shall mean the union of the acting entity and all\n",
        "      other entities that control, are controlled by, or are under common\n",
        "      control with that entity. For the purposes of this definition,\n",
        "      \"control\" means (i) the power, direct or indirect, to cause the\n",
        "      direction or management of such entity, whether by contract or\n",
        "      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n",
        "      outstanding shares, or (iii) beneficial ownership of such entity.\n",
        "\n",
        "      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n",
        "      exercising permissions granted by this License.\n",
        "\n",
        "      \"Source\" form shall mean the preferred form for making modifications,\n",
        "      including but not limited to software source code, documentation\n",
        "      source, and configuration files.\n",
        "\n",
        "      \"Object\" form shall mean any form resulting from mechanical\n",
        "      transformation or translation of a Source form, including but\n",
        "      not limited to compiled object code, generated documentation,\n",
        "      and conversions to other media types.\n",
        "\n",
        "      \"Work\" shall mean the work of authorship, whether in Source or\n",
        "      Object form, made available under the License, as indicated by a\n",
        "      copyright notice that is included in or attached to the work\n",
        "      (an example is provided in the Appendix below).\n",
        "\n",
        "      \"Derivative Works\" shall mean any work, whether in Source or Object\n",
        "      form, that is based on (or derived from) the Work and for which the\n",
        "      editorial revisions, annotations, elaborations, or other modifications\n",
        "      represent, as a whole, an original work of authorship. For the purposes\n",
        "      of this License, Derivative Works shall not include works that remain\n",
        "      separable from, or merely link (or bind by name) to the interfaces of,\n",
        "      the Work and Derivative Works thereof.\n",
        "\n",
        "      \"Contribution\" shall mean any work of authorship, including\n",
        "      the original version of the Work and any modifications or additions\n",
        "      to that Work or Derivative Works thereof, that is intentionally\n",
        "      submitted to Licensor for inclusion in the Work by the copyright owner\n",
        "      or by an individual or Legal Entity authorized to submit on behalf of\n",
        "      the copyright owner. For the purposes of this definition, \"submitted\"\n",
        "      means any form of electronic, verbal, or written communication sent\n",
        "      to the Licensor or its representatives, including but not limited to\n",
        "      communication on electronic mailing lists, source code control systems,\n",
        "      and issue tracking systems that are managed by, or on behalf of, the\n",
        "      Licensor for the purpose of discussing and improving the Work, but\n",
        "      excluding communication that is conspicuously marked or otherwise\n",
        "      designated in writing by the copyright owner as \"Not a Contribution.\"\n",
        "\n",
        "      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n",
        "      on behalf of whom a Contribution has been received by Licensor and\n",
        "      subsequently incorporated within the Work.\n",
        "\n",
        "   2. Grant of Copyright License. Subject to the terms and conditions of\n",
        "      this License, each Contributor hereby grants to You a perpetual,\n",
        "      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
        "      copyright license to reproduce, prepare Derivative Works of,\n",
        "      publicly display, publicly perform, sublicense, and distribute the\n",
        "      Work and such Derivative Works in Source or Object form.\n",
        "\n",
        "   3. Grant of Patent License. Subject to the terms and conditions of\n",
        "      this License, each Contributor hereby grants to You a perpetual,\n",
        "      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
        "      (except as stated in this section) patent license to make, have made,\n",
        "      use, offer to sell, sell, import, and otherwise transfer the Work,\n",
        "      where such license applies only to those patent claims licensable\n",
        "      by such Contributor that are necessarily infringed by their\n",
        "      Contribution(s) alone or by combination of their Contribution(s)\n",
        "      with the Work to which such Contribution(s) was submitted. If You\n",
        "      institute patent litigation against any entity (including a\n",
        "      cross-claim or counterclaim in a lawsuit) alleging that the Work\n",
        "      or a Contribution incorporated within the Work constitutes direct\n",
        "      or contributory patent infringement, then any patent licenses\n",
        "      granted to You under this License for that Work shall terminate\n",
        "      as of the date such litigation is filed.\n",
        "\n",
        "   4. Redistribution. You may reproduce and distribute copies of the\n",
        "      Work or Derivative Works thereof in any medium, with or without\n",
        "      modifications, and in Source or Object form, provided that You\n",
        "      meet the following conditions:\n",
        "\n",
        "      (a) You must give any other recipients of the Work or\n",
        "          Derivative Works a copy of this License; and\n",
        "\n",
        "      (b) You must cause any modified files to carry prominent notices\n",
        "          stating that You changed the files; and\n",
        "\n",
        "      (c) You must retain, in the Source form of any Derivative Works\n",
        "          that You distribute, all copyright, patent, trademark, and\n",
        "          attribution notices from the Source form of the Work,\n",
        "          excluding those notices that do not pertain to any part of\n",
        "          the Derivative Works; and\n",
        "\n",
        "      (d) If the Work includes a \"NOTICE\" text file as part of its\n",
        "          distribution, then any Derivative Works that You distribute must\n",
        "          include a readable copy of the attribution notices contained\n",
        "          within such NOTICE file, excluding those notices that do not\n",
        "          pertain to any part of the Derivative Works, in at least one\n",
        "          of the following places: within a NOTICE text file distributed\n",
        "          as part of the Derivative Works; within the Source form or\n",
        "          documentation, if provided along with the Derivative Works; or,\n",
        "          within a display generated by the Derivative Works, if and\n",
        "          wherever such third-party notices normally appear. The contents\n",
        "          of the NOTICE file are for informational purposes only and\n",
        "          do not modify the License. You may add Your own attribution\n",
        "          notices within Derivative Works that You distribute, alongside\n",
        "          or as an addendum to the NOTICE text from the Work, provided\n",
        "          that such additional attribution notices cannot be construed\n",
        "          as modifying the License.\n",
        "\n",
        "      You may add Your own copyright statement to Your modifications and\n",
        "      may provide additional or different license terms and conditions\n",
        "      for use, reproduction, or distribution of Your modifications, or\n",
        "      for any such Derivative Works as a whole, provided Your use,\n",
        "      reproduction, and distribution of the Work otherwise complies with\n",
        "      the conditions stated in this License.\n",
        "\n",
        "   5. Submission of Contributions. Unless You explicitly state otherwise,\n",
        "      any Contribution intentionally submitted for inclusion in the Work\n",
        "      by You to the Licensor shall be under the terms and conditions of\n",
        "      this License, without any additional terms or conditions.\n",
        "      Notwithstanding the above, nothing herein shall supersede or modify\n",
        "      the terms of any separate license agreement you may have executed\n",
        "      with Licensor regarding such Contributions.\n",
        "\n",
        "   6. Trademarks. This License does not grant permission to use the trade\n",
        "      names, trademarks, service marks, or product names of the Licensor,\n",
        "      except as required for reasonable and customary use in describing the\n",
        "      origin of the Work and reproducing the content of the NOTICE file.\n",
        "\n",
        "   7. Disclaimer of Warranty. Unless required by applicable law or\n",
        "      agreed to in writing, Licensor provides the Work (and each\n",
        "      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n",
        "      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
        "      implied, including, without limitation, any warranties or conditions\n",
        "      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n",
        "      PARTICULAR PURPOSE. You are solely responsible for determining the\n",
        "      appropriateness of using or redistributing the Work and assume any\n",
        "      risks associated with Your exercise of permissions under this License.\n",
        "\n",
        "   8. Limitation of Liability. In no event and under no legal theory,\n",
        "      whether in tort (including negligence), contract, or otherwise,\n",
        "      unless required by applicable law (such as deliberate and grossly\n",
        "      negligent acts) or agreed to in writing, shall any Contributor be\n",
        "      liable to You for damages, including any direct, indirect, special,\n",
        "      incidental, or consequential damages of any character arising as a\n",
        "      result of this License or out of the use or inability to use the\n",
        "      Work (including but not limited to damages for loss of goodwill,\n",
        "      work stoppage, computer failure or malfunction, or any and all\n",
        "      other commercial damages or losses), even if such Contributor\n",
        "      has been advised of the possibility of such damages.\n",
        "\n",
        "   9. Accepting Warranty or Additional Liability. While redistributing\n",
        "      the Work or Derivative Works thereof, You may choose to offer,\n",
        "      and charge a fee for, acceptance of support, warranty, indemnity,\n",
        "      or other liability obligations and/or rights consistent with this\n",
        "      License. However, in accepting such obligations, You may act only\n",
        "      on Your own behalf and on Your sole responsibility, not on behalf\n",
        "      of any other Contributor, and only if You agree to indemnify,\n",
        "      defend, and hold each Contributor harmless for any liability\n",
        "      incurred by, or claims asserted against, such Contributor by reason\n",
        "      of your accepting any such warranty or additional liability.\n",
        "\n",
        "   END OF TERMS AND CONDITIONS\n",
        "\n",
        "   \n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "oxUAfDPdt3CR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxkImBVtvNL-",
        "outputId": "4a3e8b06-739c-4468-efaa-4c1f6a7d5fa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== quick verify ===\n",
            "[M050_STARTER Verify] ISA=AVX2  logical=13.10869 G-ops/s  kernel=0.20482 G-upd/s  hash=0xd38f120d6ed134f7\n",
            "[M050_STARTER] STRICT64 check (first 50000): hash=0x33349dd858e8e24f\n",
            "\n",
            "=== micro-sweep (find good T/U/PF; modest fopsx) ===\n",
            "[M050_STARTER] T=2 U=8 PF=0 FX=128 -> logical=20.03150 G-ops/s, kernel=0.15650 G-upd/s (hash=0x195f47e66f359338)\n",
            "[M050_STARTER] T=2 U=8 PF=0 FX=256 -> logical=37.48046 G-ops/s, kernel=0.14641 G-upd/s (hash=0x7961aa960ee0c312)\n",
            "[M050_STARTER] T=2 U=8 PF=0 FX=512 -> logical=40.35665 G-ops/s, kernel=0.07882 G-upd/s (hash=0xbb86e0da3cc1dc11)\n",
            "[M050_STARTER] T=2 U=8 PF=0 FX=1024 -> logical=39.98598 G-ops/s, kernel=0.03905 G-upd/s (hash=0xa2a12f79df4bc1da)\n",
            "[M050_STARTER] T=2 U=8 PF=64 FX=128 -> logical=19.82093 G-ops/s, kernel=0.15485 G-upd/s (hash=0x52ae0654079bc1b5)\n",
            "[M050_STARTER] T=2 U=8 PF=64 FX=256 -> logical=39.81093 G-ops/s, kernel=0.15551 G-upd/s (hash=0x6be48e37c759b1db)\n",
            "[M050_STARTER] T=2 U=8 PF=64 FX=512 -> logical=39.34520 G-ops/s, kernel=0.07685 G-upd/s (hash=0xe703057519392030)\n",
            "[M050_STARTER] T=2 U=8 PF=64 FX=1024 -> logical=40.38544 G-ops/s, kernel=0.03944 G-upd/s (hash=0x1965577ea47cf951)\n",
            "[M050_STARTER] T=2 U=12 PF=0 FX=128 -> logical=19.95716 G-ops/s, kernel=0.15592 G-upd/s (hash=0x22ab0aefdd66d364)\n",
            "[M050_STARTER] T=2 U=12 PF=0 FX=256 -> logical=40.85779 G-ops/s, kernel=0.15960 G-upd/s (hash=0xd6099da1cf0691dd)\n",
            "[M050_STARTER] T=2 U=12 PF=0 FX=512 -> logical=33.77365 G-ops/s, kernel=0.06596 G-upd/s (hash=0x9c7538f8540b7262)\n",
            "[M050_STARTER] T=2 U=12 PF=0 FX=1024 -> logical=25.56024 G-ops/s, kernel=0.02496 G-upd/s (hash=0x7e3c3b9b303de4e4)\n",
            "[M050_STARTER] T=2 U=12 PF=64 FX=128 -> logical=13.12396 G-ops/s, kernel=0.10253 G-upd/s (hash=0xd935d580c14db62a)\n",
            "[M050_STARTER] T=2 U=12 PF=64 FX=256 -> logical=26.85321 G-ops/s, kernel=0.10490 G-upd/s (hash=0x62b8ac7f5c3e0cc1)\n",
            "[M050_STARTER] T=2 U=12 PF=64 FX=512 -> logical=27.09523 G-ops/s, kernel=0.05292 G-upd/s (hash=0xb89a2fbe2868cd05)\n",
            "[M050_STARTER] T=2 U=12 PF=64 FX=1024 -> logical=39.69850 G-ops/s, kernel=0.03877 G-upd/s (hash=0xa33dd0525d0f7c2f)\n",
            "[M050_STARTER] T=2 U=16 PF=0 FX=128 -> logical=20.05424 G-ops/s, kernel=0.15667 G-upd/s (hash=0x5ffbc42719021389)\n",
            "[M050_STARTER] T=2 U=16 PF=0 FX=256 -> logical=38.23897 G-ops/s, kernel=0.14937 G-upd/s (hash=0xa5bb2d15fa11d3b3)\n",
            "[M050_STARTER] T=2 U=16 PF=0 FX=512 -> logical=41.07856 G-ops/s, kernel=0.08023 G-upd/s (hash=0x658010bbe31d8bf1)\n",
            "[M050_STARTER] T=2 U=16 PF=0 FX=1024 -> logical=39.74425 G-ops/s, kernel=0.03881 G-upd/s (hash=0x4ab332bce814991b)\n",
            "[M050_STARTER] T=2 U=16 PF=64 FX=128 -> logical=19.22215 G-ops/s, kernel=0.15017 G-upd/s (hash=0x8c54dfbc35eb2a74)\n",
            "[M050_STARTER] T=2 U=16 PF=64 FX=256 -> logical=37.05296 G-ops/s, kernel=0.14474 G-upd/s (hash=0xf4db4419eb4e2c17)\n",
            "[M050_STARTER] T=2 U=16 PF=64 FX=512 -> logical=41.08953 G-ops/s, kernel=0.08025 G-upd/s (hash=0xb8caaf37161c6f3e)\n",
            "[M050_STARTER] T=2 U=16 PF=64 FX=1024 -> logical=40.54150 G-ops/s, kernel=0.03959 G-upd/s (hash=0xea4e8451f93e75ce)\n",
            "[M050_STARTER] T=2 U=24 PF=0 FX=128 -> logical=20.12888 G-ops/s, kernel=0.15726 G-upd/s (hash=0xee07c43883af8eff)\n",
            "[M050_STARTER] T=2 U=24 PF=0 FX=256 -> logical=41.16877 G-ops/s, kernel=0.16082 G-upd/s (hash=0xa5088326d81cef33)\n",
            "[M050_STARTER] T=2 U=24 PF=0 FX=512 -> logical=40.10978 G-ops/s, kernel=0.07834 G-upd/s (hash=0x95abccc1e93ada08)\n",
            "[M050_STARTER] T=2 U=24 PF=0 FX=1024 -> logical=35.53134 G-ops/s, kernel=0.03470 G-upd/s (hash=0x4456a124e134c775)\n",
            "[M050_STARTER] T=2 U=24 PF=64 FX=128 -> logical=12.56846 G-ops/s, kernel=0.09819 G-upd/s (hash=0xfa40f5f3d3949aa9)\n",
            "[M050_STARTER] T=2 U=24 PF=64 FX=256 -> logical=25.94986 G-ops/s, kernel=0.10137 G-upd/s (hash=0x6561abd3768f86c5)\n",
            "[M050_STARTER] T=2 U=24 PF=64 FX=512 -> logical=29.51006 G-ops/s, kernel=0.05764 G-upd/s (hash=0xf80cd1fa6c34b1ee)\n",
            "[M050_STARTER] T=2 U=24 PF=64 FX=1024 -> logical=37.23901 G-ops/s, kernel=0.03637 G-upd/s (hash=0x7872a13a8e9c5973)\n",
            "[M050_STARTER] T=2 U=32 PF=0 FX=128 -> logical=18.96901 G-ops/s, kernel=0.14820 G-upd/s (hash=0xaf0a3966a681fb3c)\n",
            "[M050_STARTER] T=2 U=32 PF=0 FX=256 -> logical=40.35195 G-ops/s, kernel=0.15762 G-upd/s (hash=0xb8299c747ae18319)\n",
            "[M050_STARTER] T=2 U=32 PF=0 FX=512 -> logical=40.44932 G-ops/s, kernel=0.07900 G-upd/s (hash=0x9bbe7476aed011c4)\n",
            "[M050_STARTER] T=2 U=32 PF=0 FX=1024 -> logical=40.65239 G-ops/s, kernel=0.03970 G-upd/s (hash=0x3dc43bee74985451)\n",
            "[M050_STARTER] T=2 U=32 PF=64 FX=128 -> logical=18.74325 G-ops/s, kernel=0.14643 G-upd/s (hash=0x5abb3c09ed9c55da)\n",
            "[M050_STARTER] T=2 U=32 PF=64 FX=256 -> logical=40.50605 G-ops/s, kernel=0.15823 G-upd/s (hash=0x1436ebe8caa5e1f2)\n",
            "[M050_STARTER] T=2 U=32 PF=64 FX=512 -> logical=38.69572 G-ops/s, kernel=0.07558 G-upd/s (hash=0x247793c5543e2935)\n",
            "[M050_STARTER] T=2 U=32 PF=64 FX=1024 -> logical=40.46708 G-ops/s, kernel=0.03952 G-upd/s (hash=0x02744f2ad7c13eb6)\n",
            "[M050_STARTER] T=4 U=8 PF=0 FX=128 -> logical=19.61681 G-ops/s, kernel=0.15326 G-upd/s (hash=0xe859fbe7881e9138)\n",
            "[M050_STARTER] T=4 U=8 PF=0 FX=256 -> logical=39.13302 G-ops/s, kernel=0.15286 G-upd/s (hash=0x4baa194ee699d169)\n",
            "[M050_STARTER] T=4 U=8 PF=0 FX=512 -> logical=41.45550 G-ops/s, kernel=0.08097 G-upd/s (hash=0xfb786ae6b40163b9)\n",
            "[M050_STARTER] T=4 U=8 PF=0 FX=1024 -> logical=36.44720 G-ops/s, kernel=0.03559 G-upd/s (hash=0xebbdfc7802bfe755)\n",
            "[M050_STARTER] T=4 U=8 PF=64 FX=128 -> logical=13.70142 G-ops/s, kernel=0.10704 G-upd/s (hash=0xa5548dada8ff33c3)\n",
            "[M050_STARTER] T=4 U=8 PF=64 FX=256 -> logical=20.75287 G-ops/s, kernel=0.08107 G-upd/s (hash=0x9d237e0b9674efc8)\n",
            "[M050_STARTER] T=4 U=8 PF=64 FX=512 -> logical=23.99088 G-ops/s, kernel=0.04686 G-upd/s (hash=0xd7beb309d066584c)\n",
            "[M050_STARTER] T=4 U=8 PF=64 FX=1024 -> logical=37.97015 G-ops/s, kernel=0.03708 G-upd/s (hash=0xdf1ff357ef516640)\n",
            "[M050_STARTER] T=4 U=12 PF=0 FX=128 -> logical=20.06763 G-ops/s, kernel=0.15678 G-upd/s (hash=0x24cb231d85b320d9)\n",
            "[M050_STARTER] T=4 U=12 PF=0 FX=256 -> logical=39.38911 G-ops/s, kernel=0.15386 G-upd/s (hash=0x9562146c2a6c30df)\n",
            "[M050_STARTER] T=4 U=12 PF=0 FX=512 -> logical=38.28837 G-ops/s, kernel=0.07478 G-upd/s (hash=0xdf162680bad447e9)\n",
            "[M050_STARTER] T=4 U=12 PF=0 FX=1024 -> logical=37.55285 G-ops/s, kernel=0.03667 G-upd/s (hash=0xdabfeed948499f74)\n",
            "[M050_STARTER] T=4 U=12 PF=64 FX=128 -> logical=20.19809 G-ops/s, kernel=0.15780 G-upd/s (hash=0x37448113754e3f83)\n",
            "[M050_STARTER] T=4 U=12 PF=64 FX=256 -> logical=39.36952 G-ops/s, kernel=0.15379 G-upd/s (hash=0x4b5e6a8c919e8b49)\n",
            "[M050_STARTER] T=4 U=12 PF=64 FX=512 -> logical=41.08386 G-ops/s, kernel=0.08024 G-upd/s (hash=0xbd0d097bf79424e6)\n",
            "[M050_STARTER] T=4 U=12 PF=64 FX=1024 -> logical=40.30985 G-ops/s, kernel=0.03937 G-upd/s (hash=0x75f861059b3415c3)\n",
            "[M050_STARTER] T=4 U=16 PF=0 FX=128 -> logical=20.12796 G-ops/s, kernel=0.15725 G-upd/s (hash=0x38b0254e12f0c1a1)\n",
            "[M050_STARTER] T=4 U=16 PF=0 FX=256 -> logical=40.20061 G-ops/s, kernel=0.15703 G-upd/s (hash=0xd1665facd7df2579)\n",
            "[M050_STARTER] T=4 U=16 PF=0 FX=512 -> logical=40.67199 G-ops/s, kernel=0.07944 G-upd/s (hash=0x8704a7fb6b74aeb9)\n",
            "[M050_STARTER] T=4 U=16 PF=0 FX=1024 -> logical=35.60784 G-ops/s, kernel=0.03477 G-upd/s (hash=0xe6b50dcc82911213)\n",
            "[M050_STARTER] T=4 U=16 PF=64 FX=128 -> logical=12.90225 G-ops/s, kernel=0.10080 G-upd/s (hash=0x6897a6e3e83711bd)\n",
            "[M050_STARTER] T=4 U=16 PF=64 FX=256 -> logical=28.16820 G-ops/s, kernel=0.11003 G-upd/s (hash=0x3eb94c6a221cf80a)\n",
            "[M050_STARTER] T=4 U=16 PF=64 FX=512 -> logical=23.54516 G-ops/s, kernel=0.04599 G-upd/s (hash=0xdf5c1b2461d49988)\n",
            "[M050_STARTER] T=4 U=16 PF=64 FX=1024 -> logical=28.66081 G-ops/s, kernel=0.02799 G-upd/s (hash=0xa29609efcd7797f3)\n",
            "[M050_STARTER] T=4 U=24 PF=0 FX=128 -> logical=19.96193 G-ops/s, kernel=0.15595 G-upd/s (hash=0xed4a66b00d8688db)\n",
            "[M050_STARTER] T=4 U=24 PF=0 FX=256 -> logical=39.12302 G-ops/s, kernel=0.15282 G-upd/s (hash=0xeb8ab003722413d2)\n",
            "[M050_STARTER] T=4 U=24 PF=0 FX=512 -> logical=41.11985 G-ops/s, kernel=0.08031 G-upd/s (hash=0x24051bbaeb80e43f)\n",
            "[M050_STARTER] T=4 U=24 PF=0 FX=1024 -> logical=40.43797 G-ops/s, kernel=0.03949 G-upd/s (hash=0x8de134c8b7f3647a)\n",
            "[M050_STARTER] T=4 U=24 PF=64 FX=128 -> logical=19.93718 G-ops/s, kernel=0.15576 G-upd/s (hash=0x2984839f49e4d1ef)\n",
            "[M050_STARTER] T=4 U=24 PF=64 FX=256 -> logical=39.23086 G-ops/s, kernel=0.15325 G-upd/s (hash=0x9715adcede786dba)\n",
            "[M050_STARTER] T=4 U=24 PF=64 FX=512 -> logical=40.24496 G-ops/s, kernel=0.07860 G-upd/s (hash=0x7c9a60331458fc32)\n",
            "[M050_STARTER] T=4 U=24 PF=64 FX=1024 -> logical=39.99104 G-ops/s, kernel=0.03905 G-upd/s (hash=0x6953be0183a4b4c7)\n",
            "[M050_STARTER] T=4 U=32 PF=0 FX=128 -> logical=20.04312 G-ops/s, kernel=0.15659 G-upd/s (hash=0x01acf89afb52a9a8)\n",
            "[M050_STARTER] T=4 U=32 PF=0 FX=256 -> logical=40.57135 G-ops/s, kernel=0.15848 G-upd/s (hash=0x43323aea05b47681)\n",
            "[M050_STARTER] T=4 U=32 PF=0 FX=512 -> logical=40.28555 G-ops/s, kernel=0.07868 G-upd/s (hash=0x0d2a7c2197fe9971)\n",
            "[M050_STARTER] T=4 U=32 PF=0 FX=1024 -> logical=32.15066 G-ops/s, kernel=0.03140 G-upd/s (hash=0x0e1b1fb4d5095a58)\n",
            "[M050_STARTER] T=4 U=32 PF=64 FX=128 -> logical=13.25307 G-ops/s, kernel=0.10354 G-upd/s (hash=0x00d5b19b517a9c56)\n",
            "[M050_STARTER] T=4 U=32 PF=64 FX=256 -> logical=27.19109 G-ops/s, kernel=0.10622 G-upd/s (hash=0x7cdcaef698bb79e5)\n",
            "[M050_STARTER] T=4 U=32 PF=64 FX=512 -> logical=32.23916 G-ops/s, kernel=0.06297 G-upd/s (hash=0x074b5a90c67a3caa)\n",
            "[M050_STARTER] T=4 U=32 PF=64 FX=1024 -> logical=40.38443 G-ops/s, kernel=0.03944 G-upd/s (hash=0x21119da3a67d4e84)\n",
            "[M050_STARTER] T=8 U=8 PF=0 FX=128 -> logical=19.41048 G-ops/s, kernel=0.15164 G-upd/s (hash=0x7cafd0ddcc95f4e2)\n",
            "[M050_STARTER] T=8 U=8 PF=0 FX=256 -> logical=40.06490 G-ops/s, kernel=0.15650 G-upd/s (hash=0x21a96f7837ed417d)\n",
            "[M050_STARTER] T=8 U=8 PF=0 FX=512 -> logical=40.30263 G-ops/s, kernel=0.07872 G-upd/s (hash=0x92dfb4516f8ed7d9)\n",
            "[M050_STARTER] T=8 U=8 PF=0 FX=1024 -> logical=41.00060 G-ops/s, kernel=0.04004 G-upd/s (hash=0x946ae0d084cfd47a)\n",
            "[M050_STARTER] T=8 U=8 PF=64 FX=128 -> logical=20.08695 G-ops/s, kernel=0.15693 G-upd/s (hash=0x73ef12bf892f077b)\n",
            "[M050_STARTER] T=8 U=8 PF=64 FX=256 -> logical=36.98769 G-ops/s, kernel=0.14448 G-upd/s (hash=0xb250ddfbfe72ae8e)\n",
            "[M050_STARTER] T=8 U=8 PF=64 FX=512 -> logical=37.63906 G-ops/s, kernel=0.07351 G-upd/s (hash=0x76dc3db8762b241d)\n",
            "[M050_STARTER] T=8 U=8 PF=64 FX=1024 -> logical=40.98236 G-ops/s, kernel=0.04002 G-upd/s (hash=0x651efbe0acb5e715)\n",
            "[M050_STARTER] T=8 U=12 PF=0 FX=128 -> logical=19.92393 G-ops/s, kernel=0.15566 G-upd/s (hash=0x9a9f9d14f796048d)\n",
            "[M050_STARTER] T=8 U=12 PF=0 FX=256 -> logical=39.26256 G-ops/s, kernel=0.15337 G-upd/s (hash=0x2668b7cbb097589d)\n",
            "[M050_STARTER] T=8 U=12 PF=0 FX=512 -> logical=37.69779 G-ops/s, kernel=0.07363 G-upd/s (hash=0xd9e031b252794181)\n",
            "[M050_STARTER] T=8 U=12 PF=0 FX=1024 -> logical=29.45167 G-ops/s, kernel=0.02876 G-upd/s (hash=0x001f2096d1d96d92)\n",
            "[M050_STARTER] T=8 U=12 PF=64 FX=128 -> logical=13.48184 G-ops/s, kernel=0.10533 G-upd/s (hash=0xf078394318c392ca)\n",
            "[M050_STARTER] T=8 U=12 PF=64 FX=256 -> logical=29.72718 G-ops/s, kernel=0.11612 G-upd/s (hash=0xe80732d84b205c6c)\n",
            "[M050_STARTER] T=8 U=12 PF=64 FX=512 -> logical=30.61933 G-ops/s, kernel=0.05980 G-upd/s (hash=0xf5182f87f52a6f00)\n",
            "[M050_STARTER] T=8 U=12 PF=64 FX=1024 -> logical=40.02857 G-ops/s, kernel=0.03909 G-upd/s (hash=0x080a0f79b6514f63)\n",
            "[M050_STARTER] T=8 U=16 PF=0 FX=128 -> logical=19.06835 G-ops/s, kernel=0.14897 G-upd/s (hash=0x7efdef008986f554)\n",
            "[M050_STARTER] T=8 U=16 PF=0 FX=256 -> logical=38.63314 G-ops/s, kernel=0.15091 G-upd/s (hash=0x891fc5f6baa57ab7)\n",
            "[M050_STARTER] T=8 U=16 PF=0 FX=512 -> logical=40.49895 G-ops/s, kernel=0.07910 G-upd/s (hash=0xcc10bff801b32775)\n",
            "[M050_STARTER] T=8 U=16 PF=0 FX=1024 -> logical=40.03957 G-ops/s, kernel=0.03910 G-upd/s (hash=0x429025579af13a71)\n",
            "[M050_STARTER] T=8 U=16 PF=64 FX=128 -> logical=19.23274 G-ops/s, kernel=0.15026 G-upd/s (hash=0xee8d973ee5511363)\n",
            "[M050_STARTER] T=8 U=16 PF=64 FX=256 -> logical=40.18194 G-ops/s, kernel=0.15696 G-upd/s (hash=0x37b5f83df6b344ee)\n",
            "[M050_STARTER] T=8 U=16 PF=64 FX=512 -> logical=38.02914 G-ops/s, kernel=0.07428 G-upd/s (hash=0x67d88605777dec12)\n",
            "[M050_STARTER] T=8 U=16 PF=64 FX=1024 -> logical=38.94346 G-ops/s, kernel=0.03803 G-upd/s (hash=0x864c3fd00b4627bd)\n",
            "[M050_STARTER] T=8 U=24 PF=0 FX=128 -> logical=19.84338 G-ops/s, kernel=0.15503 G-upd/s (hash=0xfde3c04001421417)\n",
            "[M050_STARTER] T=8 U=24 PF=0 FX=256 -> logical=41.12333 G-ops/s, kernel=0.16064 G-upd/s (hash=0x910ca04ab5f884c0)\n",
            "[M050_STARTER] T=8 U=24 PF=0 FX=512 -> logical=40.44748 G-ops/s, kernel=0.07900 G-upd/s (hash=0xc32d796241518f50)\n",
            "[M050_STARTER] T=8 U=24 PF=0 FX=1024 -> logical=31.96245 G-ops/s, kernel=0.03121 G-upd/s (hash=0x8e92ec164e55ae9d)\n",
            "[M050_STARTER] T=8 U=24 PF=64 FX=128 -> logical=12.65089 G-ops/s, kernel=0.09884 G-upd/s (hash=0xfe05f227f055da74)\n",
            "[M050_STARTER] T=8 U=24 PF=64 FX=256 -> logical=29.23960 G-ops/s, kernel=0.11422 G-upd/s (hash=0x17d2890ef3dddeab)\n",
            "[M050_STARTER] T=8 U=24 PF=64 FX=512 -> logical=30.84387 G-ops/s, kernel=0.06024 G-upd/s (hash=0x9e550b6478cca10e)\n",
            "[M050_STARTER] T=8 U=24 PF=64 FX=1024 -> logical=41.02853 G-ops/s, kernel=0.04007 G-upd/s (hash=0xab4d212c3677732e)\n",
            "[M050_STARTER] T=8 U=32 PF=0 FX=128 -> logical=18.91768 G-ops/s, kernel=0.14779 G-upd/s (hash=0x040963bcebbb5877)\n",
            "[M050_STARTER] T=8 U=32 PF=0 FX=256 -> logical=40.97493 G-ops/s, kernel=0.16006 G-upd/s (hash=0x33777a35487888df)\n",
            "[M050_STARTER] T=8 U=32 PF=0 FX=512 -> logical=38.51966 G-ops/s, kernel=0.07523 G-upd/s (hash=0xb9201378eff3a803)\n",
            "[M050_STARTER] T=8 U=32 PF=0 FX=1024 -> logical=40.34572 G-ops/s, kernel=0.03940 G-upd/s (hash=0xbeaa27bded8c2f7e)\n",
            "[M050_STARTER] T=8 U=32 PF=64 FX=128 -> logical=19.05744 G-ops/s, kernel=0.14889 G-upd/s (hash=0x30c20ec7f596a0b1)\n",
            "[M050_STARTER] T=8 U=32 PF=64 FX=256 -> logical=38.93922 G-ops/s, kernel=0.15211 G-upd/s (hash=0x0ca6526da10981ee)\n",
            "[M050_STARTER] T=8 U=32 PF=64 FX=512 -> logical=37.07231 G-ops/s, kernel=0.07241 G-upd/s (hash=0x09c51be74f31d5da)\n",
            "[M050_STARTER] T=8 U=32 PF=64 FX=1024 -> logical=38.57861 G-ops/s, kernel=0.03767 G-upd/s (hash=0xd2e41c4399f44bb2)\n",
            "=== AUTOTUNE BEST ===\n",
            "BEST kernel so far: T=2 U=24 PF=0 FX=256 | logical=41.16877 kernel=0.16082\n",
            "\n",
            "=== big logical (reuse your best T/U/PF and crank fopsx) ===\n",
            "[M050_STARTER] ISA=AVX2  logical=35.11770 G-ops/s  kernel=0.00857 G-upd/s  hash=0x5051ca51e5ccd430\n",
            "[M050_STARTER] STRICT64 check (first 50000): hash=0xd7410a1596d61372\n",
            "[M050_STARTER] ISA=AVX2  logical=37.83018 G-ops/s  kernel=0.00462 G-upd/s  hash=0xc791bef159790690\n",
            "[M050_STARTER] STRICT64 check (first 50000): hash=0xf4e25a0d7d602fd6\n",
            "[M050_STARTER] ISA=AVX2  logical=38.06614 G-ops/s  kernel=0.00232 G-upd/s  hash=0xeccd0d3ced43db75\n",
            "[M050_STARTER] STRICT64 check (first 50000): hash=0xe1f1b0310a4734c6\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# ====== M050_STARTER :: exact modular, wait 5 minutes for it to finish run! (AVX2 + OpenMP) ======\n",
        "cat > m050_starter.cpp <<'CPP'\n",
        "#include <bits/stdc++.h>\n",
        "#ifdef _OPENMP\n",
        "  #include <omp.h>\n",
        "#endif\n",
        "#include <immintrin.h>\n",
        "using namespace std;\n",
        "using clk = chrono::high_resolution_clock;\n",
        "\n",
        "// ---------- args ----------\n",
        "struct Args {\n",
        "  size_t N = 20'000'000;\n",
        "  int threads = -1;\n",
        "  int unroll  = 16;     // try 12..32\n",
        "  int prefetch= 64;     // 0 or 64\n",
        "  int fopsx   = 4096;   // extra exact ops per element (power-of-two recommended)\n",
        "  double secs = 0.30;   // min timing window\n",
        "  bool verify = false;\n",
        "  bool autotune = false;\n",
        "};\n",
        "static void parse(int argc, char** argv, Args& a){\n",
        "  for(int i=1;i<argc;i++){\n",
        "    string s=argv[i]; auto need=[&]{ if(i+1>=argc){ fprintf(stderr,\"Missing value for %s\\n\", s.c_str()); exit(1);} };\n",
        "    if(s==\"--N\"){ need(); a.N = strtoull(argv[++i],nullptr,10); }\n",
        "    else if(s==\"--threads\"){ need(); a.threads = atoi(argv[++i]); }\n",
        "    else if(s==\"--unroll\"){ need(); a.unroll = atoi(argv[++i]); }\n",
        "    else if(s==\"--prefetch\"){ need(); a.prefetch = atoi(argv[++i]); }\n",
        "    else if(s==\"--fopsx\"){ need(); a.fopsx = atoi(argv[++i]); }\n",
        "    else if(s==\"--secs\"){ need(); a.secs = atof(argv[++i]); }\n",
        "    else if(s==\"--verify\"){ a.verify = true; }\n",
        "    else if(s==\"--autotune\"){ a.autotune = true; }\n",
        "  }\n",
        "}\n",
        "\n",
        "// ---------- tiny utils ----------\n",
        "static inline uint64_t fnv1a64_append(uint64_t h, const void* p, size_t n){\n",
        "  const uint8_t* b = (const uint8_t*)p; const uint64_t prime = 1099511628211ull;\n",
        "  for(size_t i=0;i<n;i++){ h ^= b[i]; h *= prime; }\n",
        "  return h;\n",
        "}\n",
        "static inline double secs_since(clk::time_point t0){ return chrono::duration<double>(clk::now()-t0).count(); }\n",
        "\n",
        "static inline const char* isa_str(){\n",
        "#if defined(__AVX512F__)\n",
        "  return \"AVX-512\";\n",
        "#elif defined(__AVX2__)\n",
        "  return \"AVX2\";\n",
        "#else\n",
        "  return \"SSE/Scalar\";\n",
        "#endif\n",
        "}\n",
        "\n",
        "// ---------- exact mod core (two 31-bit primes for CRT lanes) ----------\n",
        "// Pairwise coprime primes near 2^31 (safe for 32-bit lanes).\n",
        "static constexpr uint32_t P0 = 2147483629u; // 2^31 - 19\n",
        "static constexpr uint32_t P1 = 2147483587u; // 2^31 - 61\n",
        "\n",
        "// Branchless add mod prime (scalar)\n",
        "static inline uint32_t addmod_u32(uint32_t a, uint32_t b, uint32_t p){\n",
        "  uint32_t s = a + b;\n",
        "  s -= (p & -(s >= p));\n",
        "  return s;\n",
        "}\n",
        "// Branchless sub mod prime (scalar)\n",
        "static inline uint32_t submod_u32(uint32_t a, uint32_t b, uint32_t p){\n",
        "  uint32_t d = a - b;\n",
        "  d += (p & -(a < b));\n",
        "  return d;\n",
        "}\n",
        "\n",
        "// AVX2 helpers (8 x u32 lanes)\n",
        "static inline __m256i addmod_8x_u32(__m256i a, __m256i b, __m256i p){\n",
        "  __m256i s = _mm256_add_epi32(a,b);\n",
        "  __m256i ge = _mm256_cmpgt_epi32(_mm256_add_epi32(s, _mm256_set1_epi32(-1)), _mm256_add_epi32(p, _mm256_set1_epi32(-1))); // s>=p\n",
        "  __m256i corr = _mm256_and_si256(p, ge);\n",
        "  return _mm256_sub_epi32(s, corr);\n",
        "}\n",
        "static inline __m256i submod_8x_u32(__m256i a, __m256i b, __m256i p){\n",
        "  __m256i d = _mm256_sub_epi32(a,b);\n",
        "  __m256i lt = _mm256_cmpgt_epi32(b, a); // a<b\n",
        "  __m256i corr = _mm256_and_si256(p, lt);\n",
        "  return _mm256_add_epi32(d, corr);\n",
        "}\n",
        "\n",
        "// ---------- data ----------\n",
        "struct PreBuf {\n",
        "  uint32_t *x0, *x1;   // SoA: per-prime lanes\n",
        "  uint32_t *k0, *k1;   // per-prime constant adds\n",
        "  size_t N;\n",
        "};\n",
        "\n",
        "static PreBuf alloc_data(size_t N){\n",
        "  auto alloc = [&](size_t n){ void* p=nullptr; if(posix_memalign(&p, 64, n*sizeof(uint32_t))) { perror(\"alloc\"); exit(1);} return (uint32_t*)p; };\n",
        "  PreBuf pb;\n",
        "  pb.N=N; pb.x0=alloc(N); pb.x1=alloc(N); pb.k0=alloc(N); pb.k1=alloc(N);\n",
        "  // init with deterministic pseudo-data (exact)\n",
        "  std::mt19937_64 rng(12345);\n",
        "  for(size_t i=0;i<N;i++){\n",
        "    uint64_t v = rng();\n",
        "    pb.x0[i] = (uint32_t)(v % P0);\n",
        "    pb.x1[i] = (uint32_t)(v % P1);\n",
        "    uint64_t c = (v * 0x9E3779B185EBCA87ull) ^ (v>>17);\n",
        "    pb.k0[i] = (uint32_t)((c + 13) % P0);\n",
        "    pb.k1[i] = (uint32_t)((c + 13) % P1);\n",
        "  }\n",
        "  return pb;\n",
        "}\n",
        "\n",
        "static void free_data(PreBuf& p){ free(p.x0); free(p.x1); free(p.k0); free(p.k1); memset(&p,0,sizeof(p)); }\n",
        "\n",
        "// ---------- kernel: exact per-element updates (add-mod loops) ----------\n",
        "static uint64_t kernel_hot(const PreBuf& pb, const Args& a, double& secs_out){\n",
        "  const size_t N = pb.N;\n",
        "  const int T = (a.threads>0? a.threads : max(1, (int)thread::hardware_concurrency()/2));\n",
        "  const int U = max(1, a.unroll);\n",
        "  const int PF = a.prefetch;\n",
        "  const __m256i P0v = _mm256_set1_epi32((int)P0);\n",
        "  const __m256i P1v = _mm256_set1_epi32((int)P1);\n",
        "\n",
        "  auto t0 = clk::now();\n",
        "  size_t iters = 0;\n",
        "  uint64_t h = 0;\n",
        "\n",
        "  #pragma omp parallel num_threads(T) reduction(+:iters) reduction(^:h)\n",
        "  {\n",
        "    #ifdef _OPENMP\n",
        "    if(omp_get_thread_num()==0){\n",
        "      // nothing; binding set from env outside\n",
        "    }\n",
        "    #endif\n",
        "\n",
        "    double secs = 0.0;\n",
        "    do {\n",
        "      // one sweep over the array\n",
        "      #pragma omp for schedule(static)\n",
        "      for (size_t i=0; i<N; i += 8*U){\n",
        "        if (PF) {\n",
        "          _mm_prefetch((const char*)(pb.x0 + i + 8*U + 64/sizeof(uint32_t)), _MM_HINT_T0);\n",
        "          _mm_prefetch((const char*)(pb.x1 + i + 8*U + 64/sizeof(uint32_t)), _MM_HINT_T0);\n",
        "          _mm_prefetch((const char*)(pb.k0 + i + 8*U + 64/sizeof(uint32_t)), _MM_HINT_T0);\n",
        "          _mm_prefetch((const char*)(pb.k1 + i + 8*U + 64/sizeof(uint32_t)), _MM_HINT_T0);\n",
        "        }\n",
        "\n",
        "        #pragma unroll 8\n",
        "        for (int u=0; u<U; ++u){\n",
        "          size_t j = i + 8u + 8u*u - 8u*u; // just j=i+8*u (avoid -Wsign issues)\n",
        "          j = i + 8u*u + 0;                // clear expression, keep simple\n",
        "          j = i + (size_t)8 * (size_t)u;\n",
        "          if (j+8 > N) break;\n",
        "\n",
        "          __m256i x0 = _mm256_load_si256((const __m256i*)(pb.x0 + j));\n",
        "          __m256i x1 = _mm256_load_si256((const __m256i*)(pb.x1 + j));\n",
        "          const __m256i k0 = _mm256_load_si256((const __m256i*)(pb.k0 + j));\n",
        "          const __m256i k1 = _mm256_load_si256((const __m256i*)(pb.k1 + j));\n",
        "\n",
        "          // fopsx exact \"work\": here, repeated addmod/submod with constants (branchless, all integer)\n",
        "          int fx = a.fopsx;\n",
        "          while (fx >= 8){\n",
        "            x0 = addmod_8x_u32(x0, k0, P0v);\n",
        "            x1 = addmod_8x_u32(x1, k1, P1v);\n",
        "            x0 = submod_8x_u32(x0, k0, P0v);\n",
        "            x1 = submod_8x_u32(x1, k1, P1v);\n",
        "            x0 = addmod_8x_u32(x0, k0, P0v);\n",
        "            x1 = addmod_8x_u32(x1, k1, P1v);\n",
        "            x0 = submod_8x_u32(x0, k0, P0v);\n",
        "            x1 = submod_8x_u32(x1, k1, P1v);\n",
        "            fx -= 8;\n",
        "          }\n",
        "          while (fx-- > 0){\n",
        "            x0 = addmod_8x_u32(x0, k0, P0v);\n",
        "            x1 = addmod_8x_u32(x1, k1, P1v);\n",
        "          }\n",
        "\n",
        "          _mm256_store_si256((__m256i*)(pb.x0 + j), x0);\n",
        "          _mm256_store_si256((__m256i*)(pb.x1 + j), x1);\n",
        "        }\n",
        "      }\n",
        "\n",
        "      iters++;\n",
        "      secs = secs_since(t0);\n",
        "    } while (secs < a.secs);\n",
        "\n",
        "    // cheap hash over a small tail per thread to avoid bandwidth\n",
        "    uint64_t local = 0;\n",
        "    size_t stride = max<size_t>(8, (size_t) (N / (size_t) (T*16) + 1));\n",
        "    for (size_t i=omp_get_thread_num(); i<N; i += stride*T){\n",
        "      uint32_t v0 = pb.x0[i], v1 = pb.x1[i];\n",
        "      local = fnv1a64_append(local, &v0, sizeof(v0));\n",
        "      local = fnv1a64_append(local, &v1, sizeof(v1));\n",
        "    }\n",
        "    h ^= local;\n",
        "  }\n",
        "\n",
        "  secs_out = secs_since(t0);\n",
        "  return h;\n",
        "}\n",
        "\n",
        "// reconstruct first K elements into 64-bit and check equality between two CRT primes\n",
        "static uint64_t strict64_check(const PreBuf& pb, size_t K){\n",
        "  uint64_t h=0;\n",
        "  uint64_t M = (uint64_t)P0 * (uint64_t)P1;\n",
        "  // Modular inverses for two-mod CRT\n",
        "  // m0 = P1^{-1} mod P0 ; m1 = P0^{-1} mod P1\n",
        "  auto invmod = [](uint64_t a, uint64_t mod)->uint64_t{\n",
        "    // extended gcd\n",
        "    int64_t t=0, newt=1; int64_t r=(int64_t)mod, newr=(int64_t)a;\n",
        "    while(newr!=0){ int64_t q=r/newr; tie(t,newt)=make_tuple(newt, t - q*newt); tie(r,newr)=make_tuple(newr, r - q*newr); }\n",
        "    if(r>1) return 0;\n",
        "    if(t<0) t+=mod;\n",
        "    return (uint64_t)t;\n",
        "  };\n",
        "  uint64_t m0 = invmod(P1, P0);\n",
        "  uint64_t m1 = invmod(P0, P1);\n",
        "\n",
        "  K = min(K, pb.N);\n",
        "  for(size_t i=0;i<K;i++){\n",
        "    uint64_t a0 = pb.x0[i];\n",
        "    uint64_t a1 = pb.x1[i];\n",
        "    uint64_t t0 = ( ( (a0 - (a1 % P0) + P0) % P0) * m0 ) % P0;\n",
        "    uint64_t x  = a1 + t0 * (uint64_t)P1; // reconstructed in [0,M)\n",
        "    h = fnv1a64_append(h, &x, sizeof(x));\n",
        "  }\n",
        "  return h;\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv){\n",
        "  ios::sync_with_stdio(false);\n",
        "  cin.tie(nullptr);\n",
        "\n",
        "  Args a; parse(argc, argv, a);\n",
        "  if(a.threads<=0){\n",
        "    int hw = (int)thread::hardware_concurrency();\n",
        "    a.threads = max(2, hw>0? hw/2 : 2);\n",
        "  }\n",
        "\n",
        "  // data\n",
        "  PreBuf pb = alloc_data(a.N);\n",
        "\n",
        "  // VERIFY path (small N recommended)\n",
        "  if(a.verify){\n",
        "    double secs=0;\n",
        "    uint64_t h = kernel_hot(pb, a, secs);\n",
        "    double gops  = 3.0 * (double)a.N * (double)a.fopsx / secs / 1e9;\n",
        "    double gups  = 3.0 * (double)a.N / secs / 1e9;\n",
        "    uint64_t h64 = strict64_check(pb, min<size_t>(50000, a.N));\n",
        "    printf(\"[M050_STARTER Verify] ISA=%s  logical=%.5f G-ops/s  kernel=%.5f G-upd/s  hash=0x%016llx\\n\",\n",
        "           isa_str(), gops, gups, (unsigned long long)h);\n",
        "    printf(\"[M050_STARTER] STRICT64 check (first 50000): hash=0x%016llx\\n\",\n",
        "           (unsigned long long)h64);\n",
        "    free_data(pb);\n",
        "    return 0;\n",
        "  }\n",
        "\n",
        "  // AUTOTUNE (micro)\n",
        "  if(a.autotune){\n",
        "    vector<int> Ts = {2,4,8};\n",
        "    vector<int> Us = {8,12,16,24,32};\n",
        "    vector<int> PFs= {0,64};\n",
        "    vector<int> FXs= {128,256,512,1024};\n",
        "\n",
        "    double best_gups = 0.0;\n",
        "    string best_line;\n",
        "    for(int T:Ts) for(int U:Us) for(int PF:PFs) for(int FX:FXs){\n",
        "      Args b=a; b.threads=T; b.unroll=U; b.prefetch=PF; b.fopsx=FX;\n",
        "      double secs=0;\n",
        "      uint64_t h = kernel_hot(pb, b, secs);\n",
        "      double gops = 3.0 * (double)b.N * (double)b.fopsx / secs / 1e9;\n",
        "      double gups = 3.0 * (double)b.N / secs / 1e9;\n",
        "      printf(\"[M050_STARTER] T=%d U=%d PF=%d FX=%d -> logical=%.5f G-ops/s, kernel=%.5f G-upd/s (hash=0x%016llx)\\n\",\n",
        "             T,U,PF,FX,gops,gups,(unsigned long long)h);\n",
        "      if(gups > best_gups){\n",
        "        best_gups = gups;\n",
        "        char buf[256];\n",
        "        snprintf(buf,sizeof(buf),\"BEST kernel so far: T=%d U=%d PF=%d FX=%d | logical=%.5f kernel=%.5f\",\n",
        "                 T,U,PF,FX,gops,gups);\n",
        "        best_line = buf;\n",
        "      }\n",
        "    }\n",
        "    printf(\"=== AUTOTUNE BEST ===\\n%s\\n\", best_line.c_str());\n",
        "    free_data(pb);\n",
        "    return 0;\n",
        "  }\n",
        "\n",
        "  // default single run\n",
        "  double secs=0;\n",
        "  uint64_t h = kernel_hot(pb, a, secs);\n",
        "  double gops = 3.0 * (double)a.N * (double)a.fopsx / secs / 1e9;\n",
        "  double gups = 3.0 * (double)a.N / secs / 1e9;\n",
        "  uint64_t h64 = strict64_check(pb, min<size_t>(50000, a.N));\n",
        "  printf(\"[M050_STARTER] ISA=%s  logical=%.5f G-ops/s  kernel=%.5f G-upd/s  hash=0x%016llx\\n\",\n",
        "         isa_str(), gops, gups, (unsigned long long)h);\n",
        "  printf(\"[M050_STARTER] STRICT64 check (first 50000): hash=0x%016llx\\n\",\n",
        "         (unsigned long long)h64);\n",
        "\n",
        "  free_data(pb);\n",
        "  return 0;\n",
        "}\n",
        "CPP\n",
        "\n",
        "# ===== build (aggressive & safe) =====\n",
        "g++ -O3 -Ofast -march=native -mavx2 -fopenmp \\\n",
        "    -funroll-loops -fno-exceptions -fno-rtti \\\n",
        "    -DNDEBUG -std=gnu++17 m050_starter.cpp -o m050_starter\n",
        "\n",
        "# sensible thread binding on colab-like VMs\n",
        "export OMP_PROC_BIND=close\n",
        "export OMP_PLACES=cores\n",
        "\n",
        "echo \"=== quick verify ===\"\n",
        "./m050_starter --verify --N 8000000 --fopsx 64 --secs 0.10\n",
        "\n",
        "echo\n",
        "echo \"=== micro-sweep (find good T/U/PF; modest fopsx) ===\"\n",
        "./m050_starter --autotune --N 20000000 --fopsx 512 --secs 0.35\n",
        "\n",
        "echo\n",
        "echo \"=== big logical (reuse your best T/U/PF and crank fopsx) ===\"\n",
        "# tweak T/U/PF to the best you observed from the sweep; these are just defaults:\n",
        "./m050_starter --N 20000000 --threads 8 --unroll 16 --prefetch 64 --fopsx 4096 --secs 0.35\n",
        "./m050_starter --N 20000000 --threads 8 --unroll 16 --prefetch 64 --fopsx 8192 --secs 0.35\n",
        "./m050_starter --N 20000000 --threads 8 --unroll 16 --prefetch 64 --fopsx 16384 --secs 0.35\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# =====================================================================\n",
        "# █████████████████  MODULE G00 :: CUDA exact modular starter  █████████\n",
        "#            (ports your M050 AVX2+OMP kernel to CUDA on T4)\n",
        "# =====================================================================\n",
        "\n",
        "cat > g000_cuda_starter.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "using namespace std;\n",
        "using clk = chrono::high_resolution_clock;\n",
        "\n",
        "// ---------- args ----------\n",
        "struct Args {\n",
        "  size_t N = 20'000'000;\n",
        "  int blocks = 0;       // 0 => auto\n",
        "  int threads = 256;    // 128..1024: autotune will sweep\n",
        "  int unroll  = 8;      // 4..32\n",
        "  int fopsx   = 4096;   // logical ops per element\n",
        "  double secs = 0.30;   // min timing window\n",
        "  bool verify = false;\n",
        "  bool autotune = false;\n",
        "};\n",
        "static void parse(int argc, char** argv, Args& a){\n",
        "  for(int i=1;i<argc;i++){\n",
        "    string s=argv[i]; auto need=[&]{ if(i+1>=argc){ fprintf(stderr,\"Missing value for %s\\n\", s.c_str()); exit(1);} };\n",
        "    if(s==\"--N\"){ need(); a.N = strtoull(argv[++i],nullptr,10); }\n",
        "    else if(s==\"--blocks\"){ need(); a.blocks = atoi(argv[++i]); }\n",
        "    else if(s==\"--threads\"){ need(); a.threads = atoi(argv[++i]); }\n",
        "    else if(s==\"--unroll\"){ need(); a.unroll = atoi(argv[++i]); }\n",
        "    else if(s==\"--fopsx\"){ need(); a.fopsx = atoi(argv[++i]); }\n",
        "    else if(s==\"--secs\"){ need(); a.secs = atof(argv[++i]); }\n",
        "    else if(s==\"--verify\"){ a.verify = true; }\n",
        "    else if(s==\"--autotune\"){ a.autotune = true; }\n",
        "  }\n",
        "}\n",
        "\n",
        "// ---------- tiny utils ----------\n",
        "static inline uint64_t fnv1a64_append(uint64_t h, const void* p, size_t n){\n",
        "  const uint8_t* b = (const uint8_t*)p; const uint64_t prime = 1099511628211ull;\n",
        "  for(size_t i=0;i<n;i++){ h ^= b[i]; h *= prime; }\n",
        "  return h;\n",
        "}\n",
        "static inline double secs_since(clk::time_point t0){ return chrono::duration<double>(clk::now()-t0).count(); }\n",
        "\n",
        "static inline void ck(cudaError_t e, const char* msg){\n",
        "  if(e!=cudaSuccess){ fprintf(stderr,\"CUDA error at %s: %s\\n\", msg, cudaGetErrorString(e)); exit(1); }\n",
        "}\n",
        "\n",
        "// ---------- exact mod core (two 31-bit primes for CRT lanes) ----------\n",
        "static constexpr uint32_t P0 = 2147483629u; // 2^31 - 19\n",
        "static constexpr uint32_t P1 = 2147483587u; // 2^31 - 61\n",
        "\n",
        "// ---------- data ----------\n",
        "struct PreBuf {\n",
        "  uint32_t *x0, *x1;   // host\n",
        "  uint32_t *k0, *k1;   // host\n",
        "  uint32_t *d_x0, *d_x1; // device\n",
        "  uint32_t *d_k0, *d_k1; // device\n",
        "  size_t N;\n",
        "};\n",
        "\n",
        "static PreBuf alloc_data(size_t N){\n",
        "  PreBuf pb; pb.N=N;\n",
        "  auto halloc = [&](size_t n){ void* p=nullptr; if(posix_memalign(&p, 64, n*sizeof(uint32_t))) { perror(\"alloc\"); exit(1);} return (uint32_t*)p; };\n",
        "  pb.x0=halloc(N); pb.x1=halloc(N); pb.k0=halloc(N); pb.k1=halloc(N);\n",
        "  std::mt19937_64 rng(12345);\n",
        "  for(size_t i=0;i<N;i++){\n",
        "    uint64_t v = rng();\n",
        "    pb.x0[i] = (uint32_t)(v % P0);\n",
        "    pb.x1[i] = (uint32_t)(v % P1);\n",
        "    uint64_t c = (v * 0x9E3779B185EBCA87ull) ^ (v>>17);\n",
        "    pb.k0[i] = (uint32_t)((c + 13) % P0);\n",
        "    pb.k1[i] = (uint32_t)((c + 13) % P1);\n",
        "  }\n",
        "  ck(cudaMalloc(&pb.d_x0, N*sizeof(uint32_t)), \"cudaMalloc d_x0\");\n",
        "  ck(cudaMalloc(&pb.d_x1, N*sizeof(uint32_t)), \"cudaMalloc d_x1\");\n",
        "  ck(cudaMalloc(&pb.d_k0, N*sizeof(uint32_t)), \"cudaMalloc d_k0\");\n",
        "  ck(cudaMalloc(&pb.d_k1, N*sizeof(uint32_t)), \"cudaMalloc d_k1\");\n",
        "  ck(cudaMemcpy(pb.d_x0, pb.x0, N*sizeof(uint32_t), cudaMemcpyHostToDevice), \"H2D x0\");\n",
        "  ck(cudaMemcpy(pb.d_x1, pb.x1, N*sizeof(uint32_t), cudaMemcpyHostToDevice), \"H2D x1\");\n",
        "  ck(cudaMemcpy(pb.d_k0, pb.k0, N*sizeof(uint32_t), cudaMemcpyHostToDevice), \"H2D k0\");\n",
        "  ck(cudaMemcpy(pb.d_k1, pb.k1, N*sizeof(uint32_t), cudaMemcpyHostToDevice), \"H2D k1\");\n",
        "  return pb;\n",
        "}\n",
        "static void free_data(PreBuf& p){\n",
        "  if(p.d_x0) cudaFree(p.d_x0);\n",
        "  if(p.d_x1) cudaFree(p.d_x1);\n",
        "  if(p.d_k0) cudaFree(p.d_k0);\n",
        "  if(p.d_k1) cudaFree(p.d_k1);\n",
        "  free(p.x0); free(p.x1); free(p.k0); free(p.k1);\n",
        "  memset(&p,0,sizeof(p));\n",
        "}\n",
        "\n",
        "// ---------- device-side branchless addmod/submod ----------\n",
        "__device__ __forceinline__ uint32_t addmod_u32(uint32_t a, uint32_t b, uint32_t p){\n",
        "  uint32_t s = a + b;\n",
        "  // s -= p if s >= p (branchless)\n",
        "  uint32_t ge = (s >= p);\n",
        "  return s - (p & -ge);\n",
        "}\n",
        "__device__ __forceinline__ uint32_t submod_u32(uint32_t a, uint32_t b, uint32_t p){\n",
        "  uint32_t d = a - b;\n",
        "  uint32_t lt = (a < b);\n",
        "  return d + (p & -lt);\n",
        "}\n",
        "\n",
        "// ---------- kernel ----------\n",
        "template<int UNROLL>\n",
        "__global__ void hotloop_kernel(uint32_t* __restrict__ x0,\n",
        "                               uint32_t* __restrict__ x1,\n",
        "                               const uint32_t* __restrict__ k0,\n",
        "                               const uint32_t* __restrict__ k1,\n",
        "                               size_t N, int fopsx)\n",
        "{\n",
        "  const uint32_t p0 = P0, p1 = P1;\n",
        "  size_t tid  = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  size_t step = (size_t)gridDim.x * blockDim.x;\n",
        "\n",
        "  for(size_t i = tid; i < N; i += step){\n",
        "    uint32_t v0 = x0[i];\n",
        "    uint32_t v1 = x1[i];\n",
        "    int fx = fopsx;\n",
        "\n",
        "    // do UNROLL-chunked “exact work”; mirror your add/sub cadence\n",
        "    while (fx >= 8*UNROLL){\n",
        "      #pragma unroll\n",
        "      for(int r=0; r<UNROLL; ++r){\n",
        "        v0 = addmod_u32(v0, k0[i], p0);\n",
        "        v1 = addmod_u32(v1, k1[i], p1);\n",
        "        v0 = submod_u32(v0, k0[i], p0);\n",
        "        v1 = submod_u32(v1, k1[i], p1);\n",
        "        v0 = addmod_u32(v0, k0[i], p0);\n",
        "        v1 = addmod_u32(v1, k1[i], p1);\n",
        "        v0 = submod_u32(v0, k0[i], p0);\n",
        "        v1 = submod_u32(v1, k1[i], p1);\n",
        "      }\n",
        "      fx -= 8*UNROLL;\n",
        "    }\n",
        "    while (fx-- > 0){\n",
        "      v0 = addmod_u32(v0, k0[i], p0);\n",
        "      v1 = addmod_u32(v1, k1[i], p1);\n",
        "    }\n",
        "    x0[i] = v0;\n",
        "    x1[i] = v1;\n",
        "  }\n",
        "}\n",
        "\n",
        "// reconstruct first K elements into 64-bit and hash (host-side CRT)\n",
        "static uint64_t strict64_check_host(const PreBuf& pb, size_t K){\n",
        "  uint64_t h=0;\n",
        "  uint64_t M0=P0, M1=P1;\n",
        "  auto invmod = [](uint64_t a, uint64_t mod)->uint64_t{\n",
        "    int64_t t=0, newt=1; int64_t r=(int64_t)mod, newr=(int64_t)a;\n",
        "    while(newr!=0){ int64_t q=r/newr; tie(t,newt)=make_tuple(newt, t - q*newt); tie(r,newr)=make_tuple(newr, r - q*newr); }\n",
        "    if(r>1) return 0;\n",
        "    if(t<0) t+=mod;\n",
        "    return (uint64_t)t;\n",
        "  };\n",
        "  uint64_t m0 = invmod(M1, M0);\n",
        "  K = min(K, pb.N);\n",
        "  // bring a small slice back if needed\n",
        "  vector<uint32_t> hx0(K), hx1(K);\n",
        "  cudaMemcpy(hx0.data(), pb.d_x0, K*sizeof(uint32_t), cudaMemcpyDeviceToHost);\n",
        "  cudaMemcpy(hx1.data(), pb.d_x1, K*sizeof(uint32_t), cudaMemcpyDeviceToHost);\n",
        "  for(size_t i=0;i<K;i++){\n",
        "    uint64_t a0 = hx0[i];\n",
        "    uint64_t a1 = hx1[i];\n",
        "    uint64_t t0 = ( ((a0 - (a1 % M0) + M0) % M0) * m0 ) % M0;\n",
        "    uint64_t x  = a1 + t0 * M1;\n",
        "    h = fnv1a64_append(h, &x, sizeof(x));\n",
        "  }\n",
        "  return h;\n",
        "}\n",
        "\n",
        "// time the kernel over >= secs window, return elapsed seconds\n",
        "template<int UNROLL>\n",
        "static double run_hotloop(const Args& a, PreBuf& pb, int blocks, int threads){\n",
        "  cudaEvent_t e0,e1; cudaEventCreate(&e0); cudaEventCreate(&e1);\n",
        "  double wall = 0.0; auto t0 = clk::now();\n",
        "\n",
        "  // warmup\n",
        "  hotloop_kernel<UNROLL><<<blocks, threads>>>(pb.d_x0, pb.d_x1, pb.d_k0, pb.d_k1, pb.N, a.fopsx);\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  int iters = 0;\n",
        "  do{\n",
        "    cudaEventRecord(e0);\n",
        "    hotloop_kernel<UNROLL><<<blocks, threads>>>(pb.d_x0, pb.d_x1, pb.d_k0, pb.d_k1, pb.N, a.fopsx);\n",
        "    cudaEventRecord(e1);\n",
        "    cudaEventSynchronize(e1);\n",
        "    iters++;\n",
        "    wall = secs_since(t0);\n",
        "  } while (wall < a.secs);\n",
        "\n",
        "  float ms=0; cudaEventElapsedTime(&ms, e0, e1);\n",
        "  // we timed only the last iteration with events; wall covers all. Use wall for rates.\n",
        "  cudaEventDestroy(e0); cudaEventDestroy(e1);\n",
        "  return wall;\n",
        "}\n",
        "\n",
        "static void gpu_banner(){\n",
        "  int dev=0; cudaDeviceProp p{}; cudaGetDeviceProperties(&p, dev);\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" GPU DETECTED\\n\");\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" Name: %s\\n\", p.name);\n",
        "  printf(\" SM:   %d.%d  (SM_%d)\\n\", p.major, p.minor, p.major*10+p.minor);\n",
        "  printf(\" Multiprocessors: %d | MaxThreads/Block: %d\\n\", p.multiProcessorCount, p.maxThreadsPerBlock);\n",
        "  printf(\"============================================================================\\n\\n\");\n",
        "}\n",
        "\n",
        "template<int UNROLL>\n",
        "static void one_run(const Args& a, PreBuf& pb, int blocks, int threads, const char* tag){\n",
        "  double secs = run_hotloop<UNROLL>(a, pb, blocks, threads);\n",
        "  double gops = 3.0 * (double)pb.N * (double)a.fopsx / secs / 1e9;\n",
        "  double gups = 3.0 * (double)pb.N / secs / 1e9;\n",
        "  uint64_t h64 = strict64_check_host(pb, min<size_t>(50000, pb.N));\n",
        "  printf(\"[%s] CUDA  logical=%.5f G-ops/s  kernel=%.5f G-upd/s  STRICT64=0x%016llx  cfg=B%dxT%d U=%d FX=%d secs=%.2f\\n\",\n",
        "         tag, gops, gups, (unsigned long long)h64, blocks, threads, UNROLL, a.fopsx, secs);\n",
        "}\n",
        "\n",
        "static int auto_blocks(int threads){\n",
        "  cudaDeviceProp p{}; cudaGetDeviceProperties(&p, 0);\n",
        "  // heuristic: few waves per SM to keep latency hidden\n",
        "  int sms = p.multiProcessorCount;\n",
        "  int waves = 8;\n",
        "  return max(1, sms * waves);\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv){\n",
        "  ios::sync_with_stdio(false);\n",
        "  cin.tie(nullptr);\n",
        "\n",
        "  Args a; parse(argc, argv, a);\n",
        "  gpu_banner();\n",
        "\n",
        "  // data\n",
        "  PreBuf pb = alloc_data(a.N);\n",
        "\n",
        "  // choose blocks\n",
        "  int blocks = (a.blocks>0 ? a.blocks : auto_blocks(a.threads));\n",
        "\n",
        "  // VERIFY path\n",
        "  if(a.verify){\n",
        "    // run a short pass with multiple unrolls for sanity\n",
        "    one_run<4>(a, pb, blocks, a.threads, \"G000_VERIFY_U4\");\n",
        "    one_run<8>(a, pb, blocks, a.threads, \"G000_VERIFY_U8\");\n",
        "    one_run<16>(a, pb, blocks, a.threads, \"G000_VERIFY_U16\");\n",
        "    free_data(pb);\n",
        "    return 0;\n",
        "  }\n",
        "\n",
        "  // AUTOTUNE sweep\n",
        "  if(a.autotune){\n",
        "    vector<int> Ts = {128,256,512,1024};\n",
        "    vector<int> Us = {4,8,12,16,24,32};\n",
        "\n",
        "    double best_gups = 0.0;\n",
        "    string best_line;\n",
        "    for(int T:Ts){\n",
        "      int B = (a.blocks>0 ? a.blocks : auto_blocks(T));\n",
        "      for(int U:Us){\n",
        "        // reinit device state each try to keep comparison fair\n",
        "        cudaMemcpy(pb.d_x0, pb.x0, pb.N*sizeof(uint32_t), cudaMemcpyHostToDevice);\n",
        "        cudaMemcpy(pb.d_x1, pb.x1, pb.N*sizeof(uint32_t), cudaMemcpyHostToDevice);\n",
        "\n",
        "        double secs=0.0; double gops=0.0, gups=0.0;\n",
        "        if(U==4){ secs = run_hotloop<4>(a, pb, B, T); }\n",
        "        else if(U==8){ secs = run_hotloop<8>(a, pb, B, T); }\n",
        "        else if(U==12){ secs = run_hotloop<12>(a, pb, B, T); }\n",
        "        else if(U==16){ secs = run_hotloop<16>(a, pb, B, T); }\n",
        "        else if(U==24){ secs = run_hotloop<24>(a, pb, B, T); }\n",
        "        else if(U==32){ secs = run_hotloop<32>(a, pb, B, T); }\n",
        "        gops = 3.0 * (double)pb.N * (double)a.fopsx / secs / 1e9;\n",
        "        gups = 3.0 * (double)pb.N / secs / 1e9;\n",
        "\n",
        "        printf(\"[G000_AUTOTUNE] B=%d T=%d U=%d FX=%d -> logical=%.5f G-ops/s, kernel=%.5f G-upd/s\\n\",\n",
        "               B,T,U,a.fopsx,gops,gups);\n",
        "        if(gups > best_gups){\n",
        "          best_gups = gups;\n",
        "          char buf[256];\n",
        "          snprintf(buf,sizeof(buf),\"BEST: B=%d T=%d U=%d FX=%d | logical=%.5f kernel=%.5f\",\n",
        "                   B,T,U,a.fopsx,gops,gups);\n",
        "          best_line = buf;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    printf(\"=== AUTOTUNE BEST ===\\n%s\\n\", best_line.c_str());\n",
        "    free_data(pb);\n",
        "    return 0;\n",
        "  }\n",
        "\n",
        "  // DEFAULT single run with chosen unroll\n",
        "  int U = a.unroll;\n",
        "  if(U==4){ one_run<4>(a, pb, blocks, a.threads, \"G000_RUN\"); }\n",
        "  else if(U==8){ one_run<8>(a, pb, blocks, a.threads, \"G000_RUN\"); }\n",
        "  else if(U==12){ one_run<12>(a, pb, blocks, a.threads, \"G000_RUN\"); }\n",
        "  else if(U==16){ one_run<16>(a, pb, blocks, a.threads, \"G000_RUN\"); }\n",
        "  else if(U==24){ one_run<24>(a, pb, blocks, a.threads, \"G000_RUN\"); }\n",
        "  else if(U==32){ one_run<32>(a, pb, blocks, a.threads, \"G000_RUN\"); }\n",
        "  else {\n",
        "    fprintf(stderr,\"Unsupported --unroll=%d; pick one of {4,8,12,16,24,32}\\n\", U);\n",
        "    free_data(pb);\n",
        "    return 2;\n",
        "  }\n",
        "\n",
        "  free_data(pb);\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# ===== build =====\n",
        "# Targeting T4 (sm_75). Colab’s T4 has compute 7.5.\n",
        "nvcc -O3 -std=c++17 -Xcompiler \"-Ofast -DNDEBUG\" \\\n",
        "     -arch=sm_75 -lineinfo -o g000_cuda_starter g000_cuda_starter.cu\n",
        "\n",
        "echo \"=== quick verify (GPU) ===\"\n",
        "./g000_cuda_starter --verify --N 8000000 --fopsx 64 --secs 0.10\n",
        "\n",
        "echo\n",
        "echo \"=== micro-sweep AUTOTUNE (GPU) ===\"\n",
        "./g000_cuda_starter --autotune --N 20000000 --fopsx 512 --secs 0.35\n",
        "\n",
        "echo\n",
        "echo \"=== big logical (GPU) ===\"\n",
        "# tweak blocks/threads/unroll using your best from sweep:\n",
        "./g000_cuda_starter --N 20000000 --threads 256 --unroll 16 --fopsx 4096 --secs 0.35\n",
        "./g000_cuda_starter --N 20000000 --threads 256 --unroll 16 --fopsx 8192 --secs 0.35\n",
        "./g000_cuda_starter --N 20000000 --threads 256 --unroll 16 --fopsx 16384 --secs 0.35\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISdopEtQ4zxJ",
        "outputId": "46f4f57d-95f1-4017-a8bc-eefc5a561b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== quick verify (GPU) ===\n",
            "============================================================================\n",
            " GPU DETECTED\n",
            "============================================================================\n",
            " Name: Tesla T4\n",
            " SM:   7.5  (SM_75)\n",
            " Multiprocessors: 40 | MaxThreads/Block: 1024\n",
            "============================================================================\n",
            "\n",
            "[G000_VERIFY_U4] CUDA  logical=15.35873 G-ops/s  kernel=0.23998 G-upd/s  STRICT64=0x1cff1862541dc5f4  cfg=B320xT256 U=4 FX=64 secs=0.10\n",
            "[G000_VERIFY_U8] CUDA  logical=15.24607 G-ops/s  kernel=0.23822 G-upd/s  STRICT64=0x1cff1862541dc5f4  cfg=B320xT256 U=8 FX=64 secs=0.10\n",
            "[G000_VERIFY_U16] CUDA  logical=15.34348 G-ops/s  kernel=0.23974 G-upd/s  STRICT64=0xdeb871c2d599d92a  cfg=B320xT256 U=16 FX=64 secs=0.10\n",
            "\n",
            "=== micro-sweep AUTOTUNE (GPU) ===\n",
            "============================================================================\n",
            " GPU DETECTED\n",
            "============================================================================\n",
            " Name: Tesla T4\n",
            " SM:   7.5  (SM_75)\n",
            " Multiprocessors: 40 | MaxThreads/Block: 1024\n",
            "============================================================================\n",
            "\n",
            "[G000_AUTOTUNE] B=320 T=128 U=4 FX=512 -> logical=85.60912 G-ops/s, kernel=0.16721 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=128 U=8 FX=512 -> logical=87.75161 G-ops/s, kernel=0.17139 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=128 U=12 FX=512 -> logical=86.02399 G-ops/s, kernel=0.16802 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=128 U=16 FX=512 -> logical=85.58131 G-ops/s, kernel=0.16715 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=128 U=24 FX=512 -> logical=84.90667 G-ops/s, kernel=0.16583 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=128 U=32 FX=512 -> logical=85.85952 G-ops/s, kernel=0.16769 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=256 U=4 FX=512 -> logical=86.88978 G-ops/s, kernel=0.16971 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=256 U=8 FX=512 -> logical=87.63006 G-ops/s, kernel=0.17115 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=256 U=12 FX=512 -> logical=87.48195 G-ops/s, kernel=0.17086 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=256 U=16 FX=512 -> logical=87.03094 G-ops/s, kernel=0.16998 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=256 U=24 FX=512 -> logical=86.10875 G-ops/s, kernel=0.16818 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=256 U=32 FX=512 -> logical=87.72262 G-ops/s, kernel=0.17133 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=512 U=4 FX=512 -> logical=86.69717 G-ops/s, kernel=0.16933 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=512 U=8 FX=512 -> logical=87.44659 G-ops/s, kernel=0.17079 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=512 U=12 FX=512 -> logical=86.02442 G-ops/s, kernel=0.16802 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=512 U=16 FX=512 -> logical=86.90794 G-ops/s, kernel=0.16974 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=512 U=24 FX=512 -> logical=86.35952 G-ops/s, kernel=0.16867 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=512 U=32 FX=512 -> logical=85.74804 G-ops/s, kernel=0.16748 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=1024 U=4 FX=512 -> logical=86.81955 G-ops/s, kernel=0.16957 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=1024 U=8 FX=512 -> logical=87.13842 G-ops/s, kernel=0.17019 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=1024 U=12 FX=512 -> logical=85.62223 G-ops/s, kernel=0.16723 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=1024 U=16 FX=512 -> logical=85.57976 G-ops/s, kernel=0.16715 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=1024 U=24 FX=512 -> logical=86.84669 G-ops/s, kernel=0.16962 G-upd/s\n",
            "[G000_AUTOTUNE] B=320 T=1024 U=32 FX=512 -> logical=85.82213 G-ops/s, kernel=0.16762 G-upd/s\n",
            "=== AUTOTUNE BEST ===\n",
            "BEST: B=320 T=128 U=8 FX=512 | logical=87.75161 kernel=0.17139\n",
            "\n",
            "=== big logical (GPU) ===\n",
            "============================================================================\n",
            " GPU DETECTED\n",
            "============================================================================\n",
            " Name: Tesla T4\n",
            " SM:   7.5  (SM_75)\n",
            " Multiprocessors: 40 | MaxThreads/Block: 1024\n",
            "============================================================================\n",
            "\n",
            "[G000_RUN] CUDA  logical=610.61795 G-ops/s  kernel=0.14908 G-upd/s  STRICT64=0x1cff1862541dc5f4  cfg=B320xT256 U=16 FX=4096 secs=0.40\n",
            "============================================================================\n",
            " GPU DETECTED\n",
            "============================================================================\n",
            " Name: Tesla T4\n",
            " SM:   7.5  (SM_75)\n",
            " Multiprocessors: 40 | MaxThreads/Block: 1024\n",
            "============================================================================\n",
            "\n",
            "[G000_RUN] CUDA  logical=1081.85900 G-ops/s  kernel=0.13206 G-upd/s  STRICT64=0x1cff1862541dc5f4  cfg=B320xT256 U=16 FX=8192 secs=0.45\n",
            "============================================================================\n",
            " GPU DETECTED\n",
            "============================================================================\n",
            " Name: Tesla T4\n",
            " SM:   7.5  (SM_75)\n",
            " Multiprocessors: 40 | MaxThreads/Block: 1024\n",
            "============================================================================\n",
            "\n",
            "[G000_RUN] CUDA  logical=2185.79613 G-ops/s  kernel=0.13341 G-upd/s  STRICT64=0x1cff1862541dc5f4  cfg=B320xT256 U=16 FX=16384 secs=0.45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# =====================================================================\n",
        "# █████████████████  MODULE G01 :: OPS ACCOUNTING OVERLAY  █████████████\n",
        "#    CPU (AVX2+OMP) and GPU (CUDA) exact modular kernels with\n",
        "#    side-by-side logical + low-level ops accounting\n",
        "# =====================================================================\n",
        "\n",
        "# -------------------------- CPU: M051 (ops) ---------------------------\n",
        "cat > m051_ops.cpp <<'CPP'\n",
        "#include <bits/stdc++.h>\n",
        "#ifdef _OPENMP\n",
        "  #include <omp.h>\n",
        "#endif\n",
        "#include <immintrin.h>\n",
        "using namespace std;\n",
        "using clk = chrono::high_resolution_clock;\n",
        "\n",
        "// ---- args (same as M050) ----\n",
        "struct Args {\n",
        "  size_t N = 20'000'000;\n",
        "  int threads = -1;\n",
        "  int unroll  = 16;\n",
        "  int prefetch= 64;\n",
        "  int fopsx   = 4096;     // = # modular ops per PRIME per element (see notes)\n",
        "  double secs = 0.30;\n",
        "  bool verify = false;\n",
        "  bool autotune = false;\n",
        "};\n",
        "static void parse(int argc, char** argv, Args& a){\n",
        "  for(int i=1;i<argc;i++){\n",
        "    string s=argv[i]; auto need=[&]{ if(i+1>=argc){ fprintf(stderr,\"Missing value for %s\\n\", s.c_str()); exit(1);} };\n",
        "    if(s==\"--N\"){ need(); a.N = strtoull(argv[++i],nullptr,10); }\n",
        "    else if(s==\"--threads\"){ need(); a.threads = atoi(argv[++i]); }\n",
        "    else if(s==\"--unroll\"){ need(); a.unroll = atoi(argv[++i]); }\n",
        "    else if(s==\"--prefetch\"){ need(); a.prefetch = atoi(argv[++i]); }\n",
        "    else if(s==\"--fopsx\"){ need(); a.fopsx = atoi(argv[++i]); }\n",
        "    else if(s==\"--secs\"){ need(); a.secs = atof(argv[++i]); }\n",
        "    else if(s==\"--verify\"){ a.verify = true; }\n",
        "    else if(s==\"--autotune\"){ a.autotune = true; }\n",
        "  }\n",
        "}\n",
        "\n",
        "static inline const char* isa_str(){\n",
        "#if defined(__AVX512F__)\n",
        "  return \"AVX-512\";\n",
        "#elif defined(__AVX2__)\n",
        "  return \"AVX2\";\n",
        "#else\n",
        "  return \"SSE/Scalar\";\n",
        "#endif\n",
        "}\n",
        "\n",
        "static inline double secs_since(clk::time_point t0){ return chrono::duration<double>(clk::now()-t0).count(); }\n",
        "static inline uint64_t fnv1a64_append(uint64_t h, const void* p, size_t n){\n",
        "  const uint8_t* b=(const uint8_t*)p; const uint64_t prime=1099511628211ull;\n",
        "  for(size_t i=0;i<n;i++){ h^=b[i]; h*=prime; } return h;\n",
        "}\n",
        "\n",
        "// ---- primes (same as M050) ----\n",
        "static constexpr uint32_t P0 = 2147483629u; // 2^31 - 19\n",
        "static constexpr uint32_t P1 = 2147483587u; // 2^31 - 61\n",
        "\n",
        "// ---- AVX2 helpers ----\n",
        "static inline __m256i addmod_8x_u32(__m256i a, __m256i b, __m256i p){\n",
        "  __m256i s = _mm256_add_epi32(a,b);\n",
        "  __m256i ge = _mm256_cmpgt_epi32(_mm256_add_epi32(s, _mm256_set1_epi32(-1)), _mm256_add_epi32(p, _mm256_set1_epi32(-1))); // s>=p\n",
        "  __m256i corr = _mm256_and_si256(p, ge);\n",
        "  return _mm256_sub_epi32(s, corr);\n",
        "}\n",
        "static inline __m256i submod_8x_u32(__m256i a, __m256i b, __m256i p){\n",
        "  __m256i d = _mm256_sub_epi32(a,b);\n",
        "  __m256i lt = _mm256_cmpgt_epi32(b, a); // a<b\n",
        "  __m256i corr = _mm256_and_si256(p, lt);\n",
        "  return _mm256_add_epi32(d, corr);\n",
        "}\n",
        "\n",
        "struct PreBuf {\n",
        "  uint32_t *x0,*x1,*k0,*k1; size_t N;\n",
        "};\n",
        "static PreBuf alloc_data(size_t N){\n",
        "  auto alloc=[&](size_t n){ void* p=nullptr; if(posix_memalign(&p,64,n*sizeof(uint32_t))) { perror(\"alloc\"); exit(1);} return (uint32_t*)p; };\n",
        "  PreBuf pb{alloc(N),alloc(N),alloc(N),alloc(N),N};\n",
        "  std::mt19937_64 rng(12345);\n",
        "  for(size_t i=0;i<N;i++){\n",
        "    uint64_t v=rng();\n",
        "    pb.x0[i]=(uint32_t)(v%P0); pb.x1[i]=(uint32_t)(v%P1);\n",
        "    uint64_t c=(v*0x9E3779B185EBCA87ull)^(v>>17);\n",
        "    pb.k0[i]=(uint32_t)((c+13)%P0); pb.k1[i]=(uint32_t)((c+13)%P1);\n",
        "  } return pb;\n",
        "}\n",
        "static void free_data(PreBuf& p){ free(p.x0); free(p.x1); free(p.k0); free(p.k1); memset(&p,0,sizeof(p)); }\n",
        "\n",
        "// ---- hot kernel (same math as M050) ----\n",
        "static uint64_t kernel_hot(const PreBuf& pb, const Args& a, double& secs_out){\n",
        "  const size_t N=pb.N; const int T=(a.threads>0? a.threads : max(1,(int)thread::hardware_concurrency()/2));\n",
        "  const int U=max(1,a.unroll); const int PF=a.prefetch;\n",
        "  const __m256i P0v=_mm256_set1_epi32((int)P0), P1v=_mm256_set1_epi32((int)P1);\n",
        "\n",
        "  auto t0=clk::now(); size_t iters=0; uint64_t h=0;\n",
        "  #pragma omp parallel num_threads(T) reduction(+:iters) reduction(^:h)\n",
        "  {\n",
        "    double secs=0.0;\n",
        "    do{\n",
        "      #pragma omp for schedule(static)\n",
        "      for(size_t i=0;i<N;i+=8*U){\n",
        "        if(PF){\n",
        "          _mm_prefetch((const char*)(pb.x0+i+8*U+16),_MM_HINT_T0);\n",
        "          _mm_prefetch((const char*)(pb.x1+i+8*U+16),_MM_HINT_T0);\n",
        "          _mm_prefetch((const char*)(pb.k0+i+8*U+16),_MM_HINT_T0);\n",
        "          _mm_prefetch((const char*)(pb.k1+i+8*U+16),_MM_HINT_T0);\n",
        "        }\n",
        "        #pragma unroll 8\n",
        "        for(int u=0; u<U; ++u){\n",
        "          size_t j=i + (size_t)8*u; if(j+8>N) break;\n",
        "          __m256i x0=_mm256_load_si256((const __m256i*)(pb.x0+j));\n",
        "          __m256i x1=_mm256_load_si256((const __m256i*)(pb.x1+j));\n",
        "          const __m256i k0=_mm256_load_si256((const __m256i*)(pb.k0+j));\n",
        "          const __m256i k1=_mm256_load_si256((const __m256i*)(pb.k1+j));\n",
        "\n",
        "          int fx=a.fopsx;\n",
        "          while(fx>=8){\n",
        "            x0=addmod_8x_u32(x0,k0,P0v); x1=addmod_8x_u32(x1,k1,P1v);\n",
        "            x0=submod_8x_u32(x0,k0,P0v); x1=submod_8x_u32(x1,k1,P1v);\n",
        "            x0=addmod_8x_u32(x0,k0,P0v); x1=addmod_8x_u32(x1,k1,P1v);\n",
        "            x0=submod_8x_u32(x0,k0,P0v); x1=submod_8x_u32(x1,k1,P1v);\n",
        "            fx-=8;\n",
        "          }\n",
        "          while(fx-- > 0){ x0=addmod_8x_u32(x0,k0,P0v); x1=addmod_8x_u32(x1,k1,P1v); }\n",
        "          _mm256_store_si256((__m256i*)(pb.x0+j),x0);\n",
        "          _mm256_store_si256((__m256i*)(pb.x1+j),x1);\n",
        "        }\n",
        "      }\n",
        "      iters++; secs=secs_since(t0);\n",
        "    } while(secs < a.secs);\n",
        "\n",
        "    // light hash sample\n",
        "    uint64_t local=0; size_t stride=max<size_t>(8, (size_t)(N/(size_t)(T*16)+1));\n",
        "    for(size_t i=omp_get_thread_num(); i<N; i+=stride*T){\n",
        "      uint32_t v0=pb.x0[i], v1=pb.x1[i];\n",
        "      local=fnv1a64_append(local,&v0,sizeof(v0));\n",
        "      local=fnv1a64_append(local,&v1,sizeof(v1));\n",
        "    }\n",
        "    h^=local;\n",
        "  }\n",
        "  secs_out=secs_since(t0);\n",
        "  return h;\n",
        "}\n",
        "\n",
        "static uint64_t strict64_check(const PreBuf& pb, size_t K){\n",
        "  uint64_t h=0; uint64_t M=(uint64_t)P0*(uint64_t)P1;\n",
        "  auto invmod=[](uint64_t a, uint64_t mod)->uint64_t{\n",
        "    int64_t t=0,newt=1; int64_t r=(int64_t)mod,newr=(int64_t)a;\n",
        "    while(newr){ int64_t q=r/newr; tie(t,newt)=make_tuple(newt, t-q*newt); tie(r,newr)=make_tuple(newr, r-q*newr); }\n",
        "    if(r>1) return 0; if(t<0) t+=mod; return (uint64_t)t;\n",
        "  };\n",
        "  uint64_t m0=invmod(P1,P0); K=min(K,pb.N);\n",
        "  for(size_t i=0;i<K;i++){\n",
        "    uint64_t a0=pb.x0[i], a1=pb.x1[i];\n",
        "    uint64_t t0=(((a0-(a1%P0)+P0)%P0) * m0) % P0;\n",
        "    uint64_t x = a1 + t0*(uint64_t)P1;\n",
        "    h=fnv1a64_append(h,&x,sizeof(x));\n",
        "  }\n",
        "  return h;\n",
        "}\n",
        "\n",
        "// ---- accounting helper ----\n",
        "// Each modular op (addmod/submod) does ~4 primitive integer ops (add/sub, compare, and, add/sub).\n",
        "// Per element: per-prime modular ops = fopsx  ⇒ both-primes = 2*fopsx.\n",
        "// So totals: modular_ops = N * 2 * fopsx; primitive_ops ≈ modular_ops * 4.\n",
        "struct Counters {\n",
        "  double logical_gops, kernel_gups;\n",
        "  double modular_gops, primitive_gops; // “G-ops/s” style rates\n",
        "  uint64_t strict64_hash;\n",
        "};\n",
        "static Counters report(double secs, size_t N, int fopsx, uint64_t h){\n",
        "  const double logical = 3.0 * (double)N * (double)fopsx / secs / 1e9; // your legacy metric\n",
        "  const double kernel  = 3.0 * (double)N / secs / 1e9;                  // your kernel updates/s\n",
        "  const double modular = (double)N * 2.0 * (double)fopsx / secs / 1e9;  // both primes\n",
        "  const double prim    = modular * 4.0;                                  // ~4 primitive ops per modular op\n",
        "  return Counters{logical,kernel,modular,prim,h};\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv){\n",
        "  ios::sync_with_stdio(false); cin.tie(nullptr);\n",
        "  Args a; parse(argc, argv, a);\n",
        "  if(a.threads<=0){ int hw=(int)thread::hardware_concurrency(); a.threads = max(2, hw>0? hw/2 : 2); }\n",
        "\n",
        "  PreBuf pb=alloc_data(a.N);\n",
        "  double secs=0; uint64_t h=kernel_hot(pb,a,secs);\n",
        "  uint64_t h64=strict64_check(pb, min<size_t>(50000,a.N));\n",
        "  auto c = report(secs, a.N, a.fopsx, h64);\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [M051_OPS] ISA=%s | N=%zu fopsx=%d secs=%.2f threads=%d unroll=%d prefetch=%d\\n\",\n",
        "         isa_str(), a.N, a.fopsx, secs, a.threads, a.unroll, a.prefetch);\n",
        "  printf(\"  Logical Ops Rate:       %.5f G-ops/s   (legacy: 3*N*fopsx / secs)\\n\", c.logical_gops);\n",
        "  printf(\"  Kernel Updates Rate:    %.5f G-upd/s   (legacy: 3*N       / secs)\\n\", c.kernel_gups);\n",
        "  printf(\"  Modular Ops Rate:       %.5f G-mod/s   (= 2*N*fopsx / secs)\\n\", c.modular_gops);\n",
        "  printf(\"  Primitive Int Ops Rate: %.5f G-ops/s   (~ 4 * modular ops)\\n\", c.primitive_gops);\n",
        "  printf(\"  STRICT64 hash(first 50k)=0x%016llx\\n\", (unsigned long long)c.strict64_hash);\n",
        "  printf(\"============================================================================\\n\");\n",
        "  free_data(pb);\n",
        "  return 0;\n",
        "}\n",
        "CPP\n",
        "\n",
        "# -------------------------- GPU: G001 (ops) ---------------------------\n",
        "cat > g001_cuda_ops.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "using namespace std;\n",
        "using clk = chrono::high_resolution_clock;\n",
        "\n",
        "// ---- args ----\n",
        "struct Args {\n",
        "  size_t N = 20'000'000;\n",
        "  int blocks = 0;\n",
        "  int threads = 256;\n",
        "  int unroll  = 16;\n",
        "  int fopsx   = 4096;\n",
        "  double secs = 0.30;\n",
        "  bool verify = false; // kept for symmetry; single path here\n",
        "};\n",
        "static void parse(int argc, char** argv, Args& a){\n",
        "  for(int i=1;i<argc;i++){\n",
        "    string s=argv[i]; auto need=[&]{ if(i+1>=argc){ fprintf(stderr,\"Missing value for %s\\n\", s.c_str()); exit(1);} };\n",
        "    if(s==\"--N\"){ need(); a.N = strtoull(argv[++i],nullptr,10); }\n",
        "    else if(s==\"--blocks\"){ need(); a.blocks = atoi(argv[++i]); }\n",
        "    else if(s==\"--threads\"){ need(); a.threads = atoi(argv[++i]); }\n",
        "    else if(s==\"--unroll\"){ need(); a.unroll = atoi(argv[++i]); }\n",
        "    else if(s==\"--fopsx\"){ need(); a.fopsx = atoi(argv[++i]); }\n",
        "    else if(s==\"--secs\"){ need(); a.secs = atof(argv[++i]); }\n",
        "    else if(s==\"--verify\"){ a.verify = true; }\n",
        "  }\n",
        "}\n",
        "static inline void ck(cudaError_t e, const char* m){ if(e!=cudaSuccess){ fprintf(stderr,\"CUDA error @%s: %s\\n\", m, cudaGetErrorString(e)); exit(1);} }\n",
        "static inline double secs_since(clk::time_point t0){ return chrono::duration<double>(clk::now()-t0).count(); }\n",
        "static inline uint64_t fnv1a64_append(uint64_t h, const void* p, size_t n){ const uint8_t* b=(const uint8_t*)p; const uint64_t P=1099511628211ull; for(size_t i=0;i<n;i++){ h^=b[i]; h*=P; } return h; }\n",
        "\n",
        "// ---- primes ----\n",
        "static constexpr uint32_t P0 = 2147483629u;\n",
        "static constexpr uint32_t P1 = 2147483587u;\n",
        "\n",
        "struct PreBuf {\n",
        "  uint32_t *x0,*x1,*k0,*k1;      // host\n",
        "  uint32_t *d_x0,*d_x1,*d_k0,*d_k1; // device\n",
        "  size_t N;\n",
        "};\n",
        "static PreBuf alloc_data(size_t N){\n",
        "  PreBuf pb; pb.N=N;\n",
        "  auto halloc=[&](size_t n){ void* p=nullptr; if(posix_memalign(&p,64,n*sizeof(uint32_t))) { perror(\"alloc\"); exit(1);} return (uint32_t*)p; };\n",
        "  pb.x0=halloc(N); pb.x1=halloc(N); pb.k0=halloc(N); pb.k1=halloc(N);\n",
        "  std::mt19937_64 rng(12345);\n",
        "  for(size_t i=0;i<N;i++){\n",
        "    uint64_t v=rng();\n",
        "    pb.x0[i]=(uint32_t)(v%P0); pb.x1[i]=(uint32_t)(v%P1);\n",
        "    uint64_t c=(v*0x9E3779B185EBCA87ull)^(v>>17);\n",
        "    pb.k0[i]=(uint32_t)((c+13)%P0); pb.k1[i]=(uint32_t)((c+13)%P1);\n",
        "  }\n",
        "  ck(cudaMalloc(&pb.d_x0,N*sizeof(uint32_t)),\"malloc x0\");\n",
        "  ck(cudaMalloc(&pb.d_x1,N*sizeof(uint32_t)),\"malloc x1\");\n",
        "  ck(cudaMalloc(&pb.d_k0,N*sizeof(uint32_t)),\"malloc k0\");\n",
        "  ck(cudaMalloc(&pb.d_k1,N*sizeof(uint32_t)),\"malloc k1\");\n",
        "  ck(cudaMemcpy(pb.d_x0,pb.x0,N*sizeof(uint32_t),cudaMemcpyHostToDevice),\"H2D x0\");\n",
        "  ck(cudaMemcpy(pb.d_x1,pb.x1,N*sizeof(uint32_t),cudaMemcpyHostToDevice),\"H2D x1\");\n",
        "  ck(cudaMemcpy(pb.d_k0,pb.k0,N*sizeof(uint32_t),cudaMemcpyHostToDevice),\"H2D k0\");\n",
        "  ck(cudaMemcpy(pb.d_k1,pb.k1,N*sizeof(uint32_t),cudaMemcpyHostToDevice),\"H2D k1\");\n",
        "  return pb;\n",
        "}\n",
        "static void free_data(PreBuf& p){\n",
        "  if(p.d_x0) cudaFree(p.d_x0);\n",
        "  if(p.d_x1) cudaFree(p.d_x1);\n",
        "  if(p.d_k0) cudaFree(p.d_k0);\n",
        "  if(p.d_k1) cudaFree(p.d_k1);\n",
        "  free(p.x0); free(p.x1); free(p.k0); free(p.k1); memset(&p,0,sizeof(p));\n",
        "}\n",
        "\n",
        "__device__ __forceinline__ uint32_t addmod_u32(uint32_t a, uint32_t b, uint32_t p){\n",
        "  uint32_t s=a+b; uint32_t ge=(s>=p); return s - (p & -ge);\n",
        "}\n",
        "__device__ __forceinline__ uint32_t submod_u32(uint32_t a, uint32_t b, uint32_t p){\n",
        "  uint32_t d=a-b; uint32_t lt=(a<b);  return d + (p & -lt);\n",
        "}\n",
        "\n",
        "template<int UNROLL>\n",
        "__global__ void hotloop(uint32_t* __restrict__ x0,\n",
        "                        uint32_t* __restrict__ x1,\n",
        "                        const uint32_t* __restrict__ k0,\n",
        "                        const uint32_t* __restrict__ k1,\n",
        "                        size_t N, int fopsx)\n",
        "{\n",
        "  const uint32_t p0=P0, p1=P1;\n",
        "  size_t tid=blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  size_t step=(size_t)gridDim.x*blockDim.x;\n",
        "\n",
        "  for(size_t i=tid; i<N; i+=step){\n",
        "    uint32_t v0=x0[i], v1=x1[i]; int fx=fopsx;\n",
        "    while(fx >= 8*UNROLL){\n",
        "      #pragma unroll\n",
        "      for(int r=0;r<UNROLL;++r){\n",
        "        v0=addmod_u32(v0,k0[i],p0); v1=addmod_u32(v1,k1[i],p1);\n",
        "        v0=submod_u32(v0,k0[i],p0); v1=submod_u32(v1,k1[i],p1);\n",
        "        v0=addmod_u32(v0,k0[i],p0); v1=addmod_u32(v1,k1[i],p1);\n",
        "        v0=submod_u32(v0,k0[i],p0); v1=submod_u32(v1,k1[i],p1);\n",
        "      }\n",
        "      fx -= 8*UNROLL;\n",
        "    }\n",
        "    while(fx-- > 0){ v0=addmod_u32(v0,k0[i],p0); v1=addmod_u32(v1,k1[i],p1); }\n",
        "    x0[i]=v0; x1[i]=v1;\n",
        "  }\n",
        "}\n",
        "\n",
        "static int auto_blocks(int threads){\n",
        "  cudaDeviceProp p{}; cudaGetDeviceProperties(&p,0);\n",
        "  int sms=p.multiProcessorCount; int waves=8; return max(1, sms*waves);\n",
        "}\n",
        "\n",
        "static void gpu_banner(){\n",
        "  int dev=0; cudaDeviceProp p{}; cudaGetDeviceProperties(&p,dev);\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" GPU DETECTED  %s  SM_%d  MPs=%d  MaxThreads/Block=%d\\n\", p.name, p.major*10+p.minor, p.multiProcessorCount, p.maxThreadsPerBlock);\n",
        "  printf(\"============================================================================\\n\");\n",
        "}\n",
        "\n",
        "static uint64_t strict64_hash(const PreBuf& pb, size_t K){\n",
        "  uint64_t h=0; uint64_t M0=P0, M1=P1;\n",
        "  auto invmod=[](uint64_t a, uint64_t mod)->uint64_t{\n",
        "    int64_t t=0,newt=1; int64_t r=(int64_t)mod,newr=(int64_t)a;\n",
        "    while(newr){ int64_t q=r/newr; tie(t,newt)=make_tuple(newt, t-q*newt); tie(r,newr)=make_tuple(newr, r-q*newr); }\n",
        "    if(r>1) return 0; if(t<0) t+=mod; return (uint64_t)t;\n",
        "  };\n",
        "  uint64_t m0=invmod(M1,M0); K=min(K,pb.N);\n",
        "  vector<uint32_t> hx0(K),hx1(K);\n",
        "  cudaMemcpy(hx0.data(),pb.d_x0,K*sizeof(uint32_t),cudaMemcpyDeviceToHost);\n",
        "  cudaMemcpy(hx1.data(),pb.d_x1,K*sizeof(uint32_t),cudaMemcpyDeviceToHost);\n",
        "  for(size_t i=0;i<K;i++){\n",
        "    uint64_t a0=hx0[i], a1=hx1[i];\n",
        "    uint64_t t0=(((a0-(a1%M0)+M0)%M0) * m0) % M0;\n",
        "    uint64_t x = a1 + t0*M1;\n",
        "    h=fnv1a64_append(h,&x,sizeof(x));\n",
        "  } return h;\n",
        "}\n",
        "\n",
        "template<int UNROLL>\n",
        "static double run(const Args& a, PreBuf& pb, int blocks, int threads){\n",
        "  cudaEvent_t e0,e1; cudaEventCreate(&e0); cudaEventCreate(&e1);\n",
        "  hotloop<UNROLL><<<blocks,threads>>>(pb.d_x0,pb.d_x1,pb.d_k0,pb.d_k1,pb.N,a.fopsx);\n",
        "  cudaDeviceSynchronize();\n",
        "  auto t0=clk::now(); double wall=0;\n",
        "  do{\n",
        "    cudaEventRecord(e0);\n",
        "    hotloop<UNROLL><<<blocks,threads>>>(pb.d_x0,pb.d_x1,pb.d_k0,pb.d_k1,pb.N,a.fopsx);\n",
        "    cudaEventRecord(e1); cudaEventSynchronize(e1);\n",
        "    wall = secs_since(t0);\n",
        "  } while (wall < a.secs);\n",
        "  cudaEventDestroy(e0); cudaEventDestroy(e1);\n",
        "  return wall;\n",
        "}\n",
        "\n",
        "static void print_report(double secs, size_t N, int fopsx, uint64_t h64,\n",
        "                         int B, int T, int U)\n",
        "{\n",
        "  // Same accounting model as CPU:\n",
        "  double logical = 3.0 * (double)N * (double)fopsx / secs / 1e9;\n",
        "  double kernel  = 3.0 * (double)N / secs / 1e9;\n",
        "  double modular = (double)N * 2.0 * (double)fopsx / secs / 1e9;\n",
        "  double prim    = modular * 4.0;\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [G001_OPS] cfg=B%dxT%d U=%d | N=%zu fopsx=%d secs=%.2f\\n\", B,T,U,N,fopsx,secs);\n",
        "  printf(\"  Logical Ops Rate:       %.5f G-ops/s   (legacy: 3*N*fopsx / secs)\\n\", logical);\n",
        "  printf(\"  Kernel Updates Rate:    %.5f G-upd/s   (legacy: 3*N       / secs)\\n\", kernel);\n",
        "  printf(\"  Modular Ops Rate:       %.5f G-mod/s   (= 2*N*fopsx / secs)  [both primes]\\n\", modular);\n",
        "  printf(\"  Primitive Int Ops Rate: %.5f G-ops/s   (~ 4 * modular ops)\\n\", prim);\n",
        "  printf(\"  STRICT64 hash(first 50k)=0x%016llx\\n\", (unsigned long long)h64);\n",
        "  printf(\"============================================================================\\n\");\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv){\n",
        "  ios::sync_with_stdio(false); cin.tie(nullptr);\n",
        "  Args a; parse(argc, argv, a);\n",
        "  gpu_banner();\n",
        "\n",
        "  PreBuf pb=alloc_data(a.N);\n",
        "  int T=a.threads;\n",
        "  int B=(a.blocks>0? a.blocks : auto_blocks(T));\n",
        "  int U=a.unroll;\n",
        "\n",
        "  double secs=0.0;\n",
        "  if(U==4)      secs=run<4>(a,pb,B,T);\n",
        "  else if(U==8) secs=run<8>(a,pb,B,T);\n",
        "  else if(U==12)secs=run<12>(a,pb,B,T);\n",
        "  else if(U==16)secs=run<16>(a,pb,B,T);\n",
        "  else if(U==24)secs=run<24>(a,pb,B,T);\n",
        "  else if(U==32)secs=run<32>(a,pb,B,T);\n",
        "  else { fprintf(stderr,\"Choose --unroll in {4,8,12,16,24,32}\\n\"); return 2; }\n",
        "\n",
        "  uint64_t h64=strict64_hash(pb, min<size_t>(50000,a.N));\n",
        "  print_report(secs, a.N, a.fopsx, h64, B, T, U);\n",
        "\n",
        "  free_data(pb);\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# ----------------------------- build ---------------------------------\n",
        "g++ -O3 -Ofast -march=native -mavx2 -fopenmp -funroll-loops -fno-exceptions -fno-rtti \\\n",
        "    -DNDEBUG -std=gnu++17 m051_ops.cpp -o m051_ops\n",
        "\n",
        "nvcc -O3 -std=c++17 -Xcompiler \"-Ofast -DNDEBUG\" -arch=sm_75 -lineinfo g001_cuda_ops.cu -o g001_cuda_ops\n",
        "\n",
        "# ---------------------------- demo runs -------------------------------\n",
        "echo \"=== CPU OPS ACCOUNTING (quick) ===\"\n",
        "./m051_ops --N 8000000 --fopsx 64 --secs 0.10\n",
        "\n",
        "echo\n",
        "echo \"=== GPU OPS ACCOUNTING (quick) ===\"\n",
        "./g001_cuda_ops --N 8000000 --threads 256 --unroll 16 --fopsx 64 --secs 0.10\n",
        "\n",
        "echo\n",
        "echo \"=== GPU OPS ACCOUNTING (bigger logical) ===\"\n",
        "./g001_cuda_ops --N 20000000 --threads 256 --unroll 16 --fopsx 4096 --secs 0.35\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuZtdDnC5PNB",
        "outputId": "160f868a-20f5-4244-8691-85a66fbebfa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CPU OPS ACCOUNTING (quick) ===\n",
            "============================================================================\n",
            " [M051_OPS] ISA=AVX-512 | N=8000000 fopsx=64 secs=0.13 threads=2 unroll=16 prefetch=64\n",
            "  Logical Ops Rate:       11.61853 G-ops/s   (legacy: 3*N*fopsx / secs)\n",
            "  Kernel Updates Rate:    0.18154 G-upd/s   (legacy: 3*N       / secs)\n",
            "  Modular Ops Rate:       7.74569 G-mod/s   (= 2*N*fopsx / secs)\n",
            "  Primitive Int Ops Rate: 30.98275 G-ops/s   (~ 4 * modular ops)\n",
            "  STRICT64 hash(first 50k)=0x83f61680ff3fc218\n",
            "============================================================================\n",
            "\n",
            "=== GPU OPS ACCOUNTING (quick) ===\n",
            "============================================================================\n",
            " GPU DETECTED  Tesla T4  SM_75  MPs=40  MaxThreads/Block=1024\n",
            "============================================================================\n",
            "============================================================================\n",
            " [G001_OPS] cfg=B320xT256 U=16 | N=8000000 fopsx=64 secs=0.10\n",
            "  Logical Ops Rate:       15.25535 G-ops/s   (legacy: 3*N*fopsx / secs)\n",
            "  Kernel Updates Rate:    0.23836 G-upd/s   (legacy: 3*N       / secs)\n",
            "  Modular Ops Rate:       10.17023 G-mod/s   (= 2*N*fopsx / secs)  [both primes]\n",
            "  Primitive Int Ops Rate: 40.68093 G-ops/s   (~ 4 * modular ops)\n",
            "  STRICT64 hash(first 50k)=0x37b379811ddc01a9\n",
            "============================================================================\n",
            "\n",
            "=== GPU OPS ACCOUNTING (bigger logical) ===\n",
            "============================================================================\n",
            " GPU DETECTED  Tesla T4  SM_75  MPs=40  MaxThreads/Block=1024\n",
            "============================================================================\n",
            "============================================================================\n",
            " [G001_OPS] cfg=B320xT256 U=16 | N=20000000 fopsx=4096 secs=0.40\n",
            "  Logical Ops Rate:       612.65502 G-ops/s   (legacy: 3*N*fopsx / secs)\n",
            "  Kernel Updates Rate:    0.14957 G-upd/s   (legacy: 3*N       / secs)\n",
            "  Modular Ops Rate:       408.43668 G-mod/s   (= 2*N*fopsx / secs)  [both primes]\n",
            "  Primitive Int Ops Rate: 1633.74673 G-ops/s   (~ 4 * modular ops)\n",
            "  STRICT64 hash(first 50k)=0x1cff1862541dc5f4\n",
            "============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# =====================================================================\n",
        "# █████████████  MODULE G002c-fix (Wait for 5 to 10 minutes for run to finish!!!!):: ROCKET (lbounds+chunk knob)  ██████\n",
        "#   - FIXED: pragma placement + parse() args\n",
        "#   - Softer __launch_bounds__(256,2), --chunk knob (64/128)\n",
        "#   - Exact two-prime math, vec=4 path, ILP=4\n",
        "# =====================================================================\n",
        "\n",
        "cat > g002c_fix_cuda_rocket.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "using namespace std; using clk = chrono::high_resolution_clock;\n",
        "\n",
        "struct Args {\n",
        "  size_t N = 20'000'000;\n",
        "  int    blocks = 0;\n",
        "  int    threads = 256;\n",
        "  int    unroll  = 16;\n",
        "  int    fopsx   = 4096;\n",
        "  int    vec     = 4;    // 1 or 4\n",
        "  int    waves   = 8;\n",
        "  int    chunk   = 64;   // multiple of 8; try 64 or 128\n",
        "  double secs    = 0.30;\n",
        "};\n",
        "static void parse(int argc, char** argv, Args& a){\n",
        "  for(int i=1;i<argc;i++){\n",
        "    string s=argv[i]; auto need=[&]{ if(i+1>=argc){ fprintf(stderr,\"Missing value for %s\\n\", s.c_str()); exit(1);} };\n",
        "    if(s==\"--N\"){ need(); a.N=strtoull(argv[++i],nullptr,10); }\n",
        "    else if(s==\"--blocks\"){ need(); a.blocks=atoi(argv[++i]); }\n",
        "    else if(s==\"--threads\"){ need(); a.threads=atoi(argv[++i]); }\n",
        "    else if(s==\"--unroll\"){ need(); a.unroll=atoi(argv[++i]); }\n",
        "    else if(s==\"--fopsx\"){ need(); a.fopsx=atoi(argv[++i]); }\n",
        "    else if(s==\"--vec\"){ need(); a.vec=atoi(argv[++i]); }\n",
        "    else if(s==\"--waves\"){ need(); a.waves=atoi(argv[++i]); }\n",
        "    else if(s==\"--chunk\"){ need(); a.chunk=atoi(argv[++i]); }\n",
        "    else if(s==\"--secs\"){ need(); a.secs=atof(argv[++i]); }\n",
        "  }\n",
        "}\n",
        "static inline void ck(cudaError_t e,const char* m){ if(e!=cudaSuccess){ fprintf(stderr,\"CUDA error @%s: %s\\n\", m, cudaGetErrorString(e)); exit(1);} }\n",
        "static inline double secs_since(clk::time_point t0){ return chrono::duration<double>(clk::now()-t0).count(); }\n",
        "static inline uint64_t fnv1a64_append(uint64_t h,const void* p,size_t n){ const uint8_t* b=(const uint8_t*)p; const uint64_t P=1099511628211ull; for(size_t i=0;i<n;i++){ h^=b[i]; h*=P; } return h; }\n",
        "\n",
        "__constant__ uint32_t cP0=2147483629u,cP1=2147483587u;\n",
        "\n",
        "struct PreBuf{ uint32_t *x0,*x1,*k0,*k1,*d_x0,*d_x1,*d_k0,*d_k1; size_t N; };\n",
        "static PreBuf alloc_data(size_t N){\n",
        "  PreBuf pb; pb.N=N; auto halloc=[&](size_t n){ void* p=nullptr; if(posix_memalign(&p,64,n*sizeof(uint32_t))) { perror(\"alloc\"); exit(1);} return (uint32_t*)p; };\n",
        "  pb.x0=halloc(N); pb.x1=halloc(N); pb.k0=halloc(N); pb.k1=halloc(N);\n",
        "  std::mt19937_64 rng(12345);\n",
        "  for(size_t i=0;i<N;i++){ uint64_t v=rng(); pb.x0[i]=(uint32_t)(v%2147483629ull); pb.x1[i]=(uint32_t)(v%2147483587ull);\n",
        "    uint64_t c=(v*0x9E3779B185EBCA87ull)^(v>>17); pb.k0[i]=(uint32_t)((c+13)%2147483629ull); pb.k1[i]=(uint32_t)((c+13)%2147483587ull); }\n",
        "  ck(cudaMalloc(&pb.d_x0,N*sizeof(uint32_t)),\"malloc x0\"); ck(cudaMalloc(&pb.d_x1,N*sizeof(uint32_t)),\"malloc x1\");\n",
        "  ck(cudaMalloc(&pb.d_k0,N*sizeof(uint32_t)),\"malloc k0\"); ck(cudaMalloc(&pb.d_k1,N*sizeof(uint32_t)),\"malloc k1\");\n",
        "  ck(cudaMemcpy(pb.d_x0,pb.x0,N*sizeof(uint32_t),cudaMemcpyHostToDevice),\"H2D x0\");\n",
        "  ck(cudaMemcpy(pb.d_x1,pb.x1,N*sizeof(uint32_t),cudaMemcpyHostToDevice),\"H2D x1\");\n",
        "  ck(cudaMemcpy(pb.d_k0,pb.k0,N*sizeof(uint32_t),cudaMemcpyHostToDevice),\"H2D k0\");\n",
        "  ck(cudaMemcpy(pb.d_k1,pb.k1,N*sizeof(uint32_t),cudaMemcpyHostToDevice),\"H2D k1\");\n",
        "  return pb;\n",
        "}\n",
        "static void free_data(PreBuf& p){ if(p.d_x0) cudaFree(p.d_x0); if(p.d_x1) cudaFree(p.d_x1);\n",
        "  if(p.d_k0) cudaFree(p.d_k0); if(p.d_k1) cudaFree(p.d_k1); free(p.x0); free(p.x1); free(p.k0); free(p.k1); memset(&p,0,sizeof(p)); }\n",
        "\n",
        "__device__ __forceinline__ uint32_t addmod_u32(uint32_t a,uint32_t b,uint32_t p){ uint32_t s=a+b; uint32_t ge=(s>=p); return s - (p & -ge); }\n",
        "__device__ __forceinline__ uint32_t submod_u32(uint32_t a,uint32_t b,uint32_t p){ uint32_t d=a-b; uint32_t lt=(a<b);  return d + (p & -lt); }\n",
        "\n",
        "template<int CHUNK>\n",
        "__device__ __forceinline__ void do_chunks(uint32_t& v0,uint32_t& v1,uint32_t k0,uint32_t k1,uint32_t p0,uint32_t p1,int& fx){\n",
        "  #pragma unroll\n",
        "  for(int c=0;c<CHUNK/8; ++c){\n",
        "    v0=addmod_u32(v0,k0,p0); v1=addmod_u32(v1,k1,p1);\n",
        "    v0=submod_u32(v0,k0,p0); v1=submod_u32(v1,k1,p1);\n",
        "    v0=addmod_u32(v0,k0,p0); v1=addmod_u32(v1,k1,p1);\n",
        "    v0=submod_u32(v0,k0,p0); v1=submod_u32(v1,k1,p1);\n",
        "  } fx -= CHUNK;\n",
        "}\n",
        "\n",
        "template<int UNROLL,int CHUNK>\n",
        "__launch_bounds__(256,2)\n",
        "__global__ void hotloop_v4(uint32_t* __restrict__ x0,uint32_t* __restrict__ x1,\n",
        "                           const uint32_t* __restrict__ k0,const uint32_t* __restrict__ k1,\n",
        "                           size_t N,int fopsx){\n",
        "  const uint32_t p0=cP0,p1=cP1; const size_t V=4;\n",
        "  size_t elemsV=(N/V)*V; size_t tid=blockIdx.x*blockDim.x + threadIdx.x; size_t step=(size_t)gridDim.x*blockDim.x;\n",
        "  uint4* __restrict__ x0v=(uint4*)x0; uint4* __restrict__ x1v=(uint4*)x1;\n",
        "  const uint4* __restrict__ k0v=(const uint4*)k0; const uint4* __restrict__ k1v=(const uint4*)k1; size_t Nv=elemsV/V;\n",
        "\n",
        "  for(size_t i=tid;i<Nv;i+=step){\n",
        "    uint4 vx0=x0v[i], vx1=x1v[i], vk0=__ldg(&k0v[i]), vk1=__ldg(&k1v[i]);\n",
        "\n",
        "    uint32_t a0=vx0.x,b0=vx1.x,k00=vk0.x,l00=vk1.x; int fx0=fopsx;\n",
        "    uint32_t a1=vx0.y,b1=vx1.y,k01=vk0.y,l01=vk1.y; int fx1=fopsx;\n",
        "    uint32_t a2=vx0.z,b2=vx1.z,k02=vk0.z,l02=vk1.z; int fx2=fopsx;\n",
        "    uint32_t a3=vx0.w,b3=vx1.w,k03=vk0.w,l03=vk1.w; int fx3=fopsx;\n",
        "\n",
        "    int fxMin=min(min(fx0,fx1),min(fx2,fx3));\n",
        "    while(fxMin >= CHUNK*UNROLL){\n",
        "      #pragma unroll\n",
        "      for(int u=0;u<UNROLL;++u){\n",
        "        do_chunks<CHUNK>(a0,b0,k00,l00,p0,p1,fx0);\n",
        "        do_chunks<CHUNK>(a1,b1,k01,l01,p0,p1,fx1);\n",
        "        do_chunks<CHUNK>(a2,b2,k02,l02,p0,p1,fx2);\n",
        "        do_chunks<CHUNK>(a3,b3,k03,l03,p0,p1,fx3);\n",
        "      }\n",
        "      fxMin -= CHUNK*UNROLL;\n",
        "    }\n",
        "    while(fx0-- > 0){ a0=addmod_u32(a0,k00,p0); b0=addmod_u32(b0,l00,p1); }\n",
        "    while(fx1-- > 0){ a1=addmod_u32(a1,k01,p0); b1=addmod_u32(b1,l01,p1); }\n",
        "    while(fx2-- > 0){ a2=addmod_u32(a2,k02,p0); b2=addmod_u32(b2,l02,p1); }\n",
        "    while(fx3-- > 0){ a3=addmod_u32(a3,k03,p0); b3=addmod_u32(b3,l03,p1); }\n",
        "    x0v[i]=uint4{a0,a1,a2,a3}; x1v[i]=uint4{b0,b1,b2,b3};\n",
        "  }\n",
        "\n",
        "  for(size_t i=elemsV+tid;i<N;i+=step){\n",
        "    uint32_t v0=x0[i],v1=x1[i]; uint32_t kk0=__ldg(&k0[i]), kk1=__ldg(&k1[i]); int fx=fopsx;\n",
        "    while(fx >= CHUNK*UNROLL){\n",
        "      #pragma unroll\n",
        "      for(int u=0;u<UNROLL;++u){ do_chunks<CHUNK>(v0,v1,kk0,kk1,p0,p1,fx); }\n",
        "    }\n",
        "    while(fx-- > 0){ v0=addmod_u32(v0,kk0,p0); v1=addmod_u32(v1,kk1,p1); }\n",
        "    x0[i]=v0; x1[i]=v1;\n",
        "  }\n",
        "}\n",
        "\n",
        "static uint64_t strict64_hash(uint32_t* d_x0,uint32_t* d_x1,size_t N,size_t K){\n",
        "  uint64_t h=0; uint64_t P0=2147483629ull,P1=2147483587ull;\n",
        "  auto invmod=[](uint64_t a,uint64_t mod)->uint64_t{ int64_t t=0,newt=1; int64_t r=(int64_t)mod,newr=(int64_t)a;\n",
        "    while(newr){ int64_t q=r/newr; tie(t,newt)=make_tuple(newt,t-q*newt); tie(r,newr)=make_tuple(newr,r-q*newr); }\n",
        "    if(r>1) return 0; if(t<0) t+=mod; return (uint64_t)t; };\n",
        "  uint64_t m0=invmod(P1,P0); K=min(K,N);\n",
        "  vector<uint32_t> hx0(K),hx1(K);\n",
        "  cudaMemcpy(hx0.data(),d_x0,K*sizeof(uint32_t),cudaMemcpyDeviceToHost);\n",
        "  cudaMemcpy(hx1.data(),d_x1,K*sizeof(uint32_t),cudaMemcpyDeviceToHost);\n",
        "  for(size_t i=0;i<K;i++){ uint64_t a0=hx0[i],a1=hx1[i];\n",
        "    uint64_t t0=(((a0-(a1%P0)+P0)%P0)*m0)%P0; uint64_t x=a1 + t0*P1; h=fnv1a64_append(h,&x,sizeof(x)); }\n",
        "  return h;\n",
        "}\n",
        "\n",
        "static void gpu_banner(){ int dev=0; cudaDeviceProp p{}; cudaGetDeviceProperties(&p,dev);\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" GPU DETECTED  %s  SM_%d  MPs=%d  MaxThreads/Block=%d\\n\", p.name, p.major*10+p.minor, p.multiProcessorCount, p.maxThreadsPerBlock);\n",
        "  printf(\"============================================================================\\n\"); }\n",
        "static int auto_blocks(int threads,int waves){ cudaDeviceProp p{}; cudaGetDeviceProperties(&p,0); return max(1, p.multiProcessorCount * max(1,waves)); }\n",
        "\n",
        "static void print_report(const char* tag,double secs,size_t N,int fopsx,uint64_t h64,int B,int T,int U,int V,int CHUNK){\n",
        "  double logical=3.0*(double)N*(double)fopsx/secs/1e9;\n",
        "  double kernel =3.0*(double)N/secs/1e9;\n",
        "  double modular=(double)N*2.0*(double)fopsx/secs/1e9;\n",
        "  double prim   =modular*4.0;\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [%s] cfg=B%dxT%d U=%d V=%d CHUNK=%d | N=%zu fopsx=%d secs=%.2f\\n\", tag,B,T,U,V,CHUNK,N,fopsx,secs);\n",
        "  printf(\"  Logical Ops Rate:       %.5f G-ops/s\\n\", logical);\n",
        "  printf(\"  Kernel Updates Rate:    %.5f G-upd/s\\n\", kernel);\n",
        "  printf(\"  Modular Ops Rate:       %.5f G-mod/s\\n\", modular);\n",
        "  printf(\"  Primitive Int Ops Rate: %.5f G-ops/s\\n\", prim);\n",
        "  printf(\"  STRICT64 hash(first 50k)=0x%016llx\\n\", (unsigned long long)h64);\n",
        "  printf(\"============================================================================\\n\");\n",
        "}\n",
        "\n",
        "template<int UNROLL,int CHUNK>\n",
        "static double run_v4(uint32_t* dx0,uint32_t* dx1,const uint32_t* dk0,const uint32_t* dk1,\n",
        "                     size_t N,int fopsx,int B,int T,double minsecs){\n",
        "  hotloop_v4<UNROLL,CHUNK><<<B,T>>>(dx0,dx1,dk0,dk1,N,fopsx); cudaDeviceSynchronize();\n",
        "  auto t0=clk::now(); double wall=0.0;\n",
        "  do{\n",
        "    hotloop_v4<UNROLL,CHUNK><<<B,T>>>(dx0,dx1,dk0,dk1,N,fopsx); cudaDeviceSynchronize();\n",
        "    wall=secs_since(t0);\n",
        "  } while(wall<minsecs);\n",
        "  return wall;\n",
        "}\n",
        "\n",
        "int main(int argc,char** argv){\n",
        "  ios::sync_with_stdio(false); cin.tie(nullptr);\n",
        "  Args a; parse(argc,argv,a); gpu_banner();\n",
        "  uint32_t P0=2147483629u,P1=2147483587u; cudaMemcpyToSymbol(cP0,&P0,sizeof(P0)); cudaMemcpyToSymbol(cP1,&P1,sizeof(P1));\n",
        "\n",
        "  // data\n",
        "  auto pb = alloc_data(a.N); int T=a.threads; int B=(a.blocks>0? a.blocks : auto_blocks(T,a.waves));\n",
        "  const int CHUNK = (a.chunk%8==0 ? a.chunk : 64);\n",
        "\n",
        "  double secs=0.0;\n",
        "  #define CASE(U) case U: (CHUNK==64? secs=run_v4<U,64 >(pb.d_x0,pb.d_x1,pb.d_k0,pb.d_k1,pb.N,a.fopsx,B,T,a.secs) : \\\n",
        "                                  secs=run_v4<U,128>(pb.d_x0,pb.d_x1,pb.d_k0,pb.d_k1,pb.N,a.fopsx,B,T,a.secs)); break;\n",
        "  switch(a.unroll){\n",
        "    CASE(8) CASE(12) CASE(16) CASE(24) CASE(32)\n",
        "    default: fprintf(stderr,\"Choose --unroll in {8,12,16,24,32}\\n\"); return 2;\n",
        "  }\n",
        "  #undef CASE\n",
        "\n",
        "  uint64_t h64 = strict64_hash(pb.d_x0,pb.d_x1,pb.N, min<size_t>(50000,pb.N));\n",
        "  print_report(\"G002c_fix_ROCKET_V4\", secs, a.N, a.fopsx, h64, B, T, a.unroll, 4, CHUNK);\n",
        "\n",
        "  free_data(pb); return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# Build with register/smem report\n",
        "nvcc -O3 -std=c++17 -Xptxas -v,-dlcm=ca -Xcompiler \"-Ofast -DNDEBUG\" \\\n",
        "     -arch=sm_75 -lineinfo g002c_fix_cuda_rocket.cu -o g002c_fix_cuda_rocket\n",
        "\n",
        "echo \"=== ROCKET quick (fixed-fixed) ===\"\n",
        "./g002c_fix_cuda_rocket --N 8000000 --threads 256 --unroll 16 --vec 4 --fopsx 64 --chunk 64 --secs 0.10\n",
        "\n",
        "echo\n",
        "echo \"=== ROCKET big (try CHUNK=128, more threads) ===\"\n",
        "./g002c_fix_cuda_rocket --N 20000000 --threads 512 --unroll 24 --vec 4 --fopsx 4096 --waves 10 --chunk 128 --secs 0.35\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp7NhJ0dC2hK",
        "outputId": "5f8f3e76-dff2-4359-cfe3-1cc06c859d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ROCKET quick (fixed-fixed) ===\n",
            "============================================================================\n",
            " GPU DETECTED  Tesla T4  SM_75  MPs=40  MaxThreads/Block=1024\n",
            "============================================================================\n",
            "============================================================================\n",
            " [G002c_fix_ROCKET_V4] cfg=B320xT256 U=16 V=4 CHUNK=64 | N=8000000 fopsx=64 secs=0.10\n",
            "  Logical Ops Rate:       15.28934 G-ops/s\n",
            "  Kernel Updates Rate:    0.23890 G-upd/s\n",
            "  Modular Ops Rate:       10.19289 G-mod/s\n",
            "  Primitive Int Ops Rate: 40.77157 G-ops/s\n",
            "  STRICT64 hash(first 50k)=0x05281caacc27e313\n",
            "============================================================================\n",
            "\n",
            "=== ROCKET big (try CHUNK=128, more threads) ===\n",
            "============================================================================\n",
            " GPU DETECTED  Tesla T4  SM_75  MPs=40  MaxThreads/Block=1024\n",
            "============================================================================\n",
            "============================================================================\n",
            " [G002c_fix_ROCKET_V4] cfg=B400xT512 U=24 V=4 CHUNK=128 | N=20000000 fopsx=4096 secs=0.35\n",
            "  Logical Ops Rate:       702.17022 G-ops/s\n",
            "  Kernel Updates Rate:    0.17143 G-upd/s\n",
            "  Modular Ops Rate:       468.11348 G-mod/s\n",
            "  Primitive Int Ops Rate: 1872.45391 G-ops/s\n",
            "  STRICT64 hash(first 50k)=0x1cff1862541dc5f4\n",
            "============================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ptxas info    : 0 bytes gmem, 8 bytes cmem[3]\n",
            "ptxas info    : Compiling entry function '_Z10hotloop_v4ILi32ELi128EEvPjS0_PKjS2_mi' for 'sm_75'\n",
            "ptxas info    : Function properties for _Z10hotloop_v4ILi32ELi128EEvPjS0_PKjS2_mi\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 35 registers, 396 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z10hotloop_v4ILi32ELi64EEvPjS0_PKjS2_mi' for 'sm_75'\n",
            "ptxas info    : Function properties for _Z10hotloop_v4ILi32ELi64EEvPjS0_PKjS2_mi\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 31 registers, 396 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z10hotloop_v4ILi24ELi128EEvPjS0_PKjS2_mi' for 'sm_75'\n",
            "ptxas info    : Function properties for _Z10hotloop_v4ILi24ELi128EEvPjS0_PKjS2_mi\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 35 registers, 396 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z10hotloop_v4ILi24ELi64EEvPjS0_PKjS2_mi' for 'sm_75'\n",
            "ptxas info    : Function properties for _Z10hotloop_v4ILi24ELi64EEvPjS0_PKjS2_mi\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 31 registers, 396 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z10hotloop_v4ILi16ELi128EEvPjS0_PKjS2_mi' for 'sm_75'\n",
            "ptxas info    : Function properties for _Z10hotloop_v4ILi16ELi128EEvPjS0_PKjS2_mi\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 31 registers, 396 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z10hotloop_v4ILi16ELi64EEvPjS0_PKjS2_mi' for 'sm_75'\n",
            "ptxas info    : Function properties for _Z10hotloop_v4ILi16ELi64EEvPjS0_PKjS2_mi\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 31 registers, 396 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z10hotloop_v4ILi12ELi128EEvPjS0_PKjS2_mi' for 'sm_75'\n",
            "ptxas info    : Function properties for _Z10hotloop_v4ILi12ELi128EEvPjS0_PKjS2_mi\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 30 registers, 396 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z10hotloop_v4ILi12ELi64EEvPjS0_PKjS2_mi' for 'sm_75'\n",
            "ptxas info    : Function properties for _Z10hotloop_v4ILi12ELi64EEvPjS0_PKjS2_mi\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 30 registers, 396 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z10hotloop_v4ILi8ELi128EEvPjS0_PKjS2_mi' for 'sm_75'\n",
            "ptxas info    : Function properties for _Z10hotloop_v4ILi8ELi128EEvPjS0_PKjS2_mi\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 31 registers, 396 bytes cmem[0]\n",
            "ptxas info    : Compiling entry function '_Z10hotloop_v4ILi8ELi64EEvPjS0_PKjS2_mi' for 'sm_75'\n",
            "ptxas info    : Function properties for _Z10hotloop_v4ILi8ELi64EEvPjS0_PKjS2_mi\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 29 registers, 396 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# =====================================================================\n",
        "# ███████████████  MODULE G009b :: DP4A RNS GEMM (exact, clean)  ███████\n",
        "#  - Exact residue-number GEMM with int8 (__dp4a) on T4 (sm_75)\n",
        "#  - Simple 2D tiling (1 thread => 1 C element), K loop in 4s\n",
        "#  - Multi-prime residues (int8), int32 acc, mod-reduce, CRT hash\n",
        "#  - Two clocks: logical MACs/s and modular MACs/s (+ dp4a inst/s)\n",
        "# =====================================================================\n",
        "\n",
        "cat > g009b_dp4a_rns_gemm.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "using namespace std;\n",
        "using clk = chrono::high_resolution_clock;\n",
        "\n",
        "// ====== args ======\n",
        "struct Args {\n",
        "  int M = 1024, N = 1024, K = 1024;\n",
        "  int primes = 9;              // number of residue primes\n",
        "  int bx = 16, by = 16;        // block dims (threads per block = bx*by)\n",
        "  int ms_min = 300;            // timing window in ms (>=)\n",
        "  int verify = 1;              // CRT hash slice\n",
        "  int recon_K = 4096;          // elements to reconstruct/hash\n",
        "  long long cert_bound = 0;    // if >0, print uniqueness cert vs 2*bound\n",
        "  unsigned seed = 12345u;      // RNG seed\n",
        "};\n",
        "static void parse(int argc, char** argv, Args& a){\n",
        "  for(int i=1;i<argc;i++){\n",
        "    string s=argv[i]; auto need=[&]{ if(i+1>=argc){ fprintf(stderr,\"Missing value for %s\\n\", s.c_str()); exit(1);} };\n",
        "    if(s==\"--M\"){ need(); a.M=atoi(argv[++i]); }\n",
        "    else if(s==\"--N\"){ need(); a.N=atoi(argv[++i]); }\n",
        "    else if(s==\"--K\"){ need(); a.K=atoi(argv[++i]); }\n",
        "    else if(s==\"--primes\"){ need(); a.primes=atoi(argv[++i]); }\n",
        "    else if(s==\"--bx\"){ need(); a.bx=atoi(argv[++i]); }\n",
        "    else if(s==\"--by\"){ need(); a.by=atoi(argv[++i]); }\n",
        "    else if(s==\"--ms\"){ need(); a.ms_min=atoi(argv[++i]); }\n",
        "    else if(s==\"--verify\"){ a.verify=1; }\n",
        "    else if(s==\"--noverify\"){ a.verify=0; }\n",
        "    else if(s==\"--reconK\"){ need(); a.recon_K=atoi(argv[++i]); }\n",
        "    else if(s==\"--cert\"){ need(); a.cert_bound=atoll(argv[++i]); }\n",
        "    else if(s==\"--seed\"){ need(); a.seed=(unsigned)strtoul(argv[++i],nullptr,10); }\n",
        "  }\n",
        "}\n",
        "\n",
        "// ====== primes ≤ 127 (pairwise coprime) ======\n",
        "static const int PRIMETBL[16] = {\n",
        "  127, 113, 109, 107, 103, 101, 97, 89,\n",
        "   83,  79,  73,  71,  67,  61, 59, 53\n",
        "};\n",
        "\n",
        "// ====== util ======\n",
        "static inline double secs_since(clk::time_point t0){ return chrono::duration<double>(clk::now()-t0).count(); }\n",
        "static inline uint64_t fnv1a64_append(uint64_t h, const void* p, size_t n){\n",
        "  const uint8_t* b=(const uint8_t*)p; const uint64_t P=1099511628211ull;\n",
        "  for(size_t i=0;i<n;i++){ h^=b[i]; h*=P; } return h;\n",
        "}\n",
        "static uint64_t invmod_u64(uint64_t a, uint64_t mod){\n",
        "  int64_t t=0,newt=1; int64_t r=(int64_t)mod,newr=(int64_t)a;\n",
        "  while(newr){ int64_t q=r/newr; tie(t,newt)=make_tuple(newt,t-q*newt); tie(r,newr)=make_tuple(newr,r-q*newr); }\n",
        "  if(r>1) return 0; if(t<0) t+=mod; return (uint64_t)t;\n",
        "}\n",
        "\n",
        "// pack int32 -> int8 residues mod p in symmetric range [-p/2, p/2]\n",
        "static void pack_mod_int8(const vector<int32_t>& X, vector<int8_t>& Y, int rows, int cols, int p){\n",
        "  Y.resize((size_t)rows*cols);\n",
        "  for(size_t i=0;i<Y.size();++i){\n",
        "    int v = (int)(((long long)X[i]%p + p) % p);\n",
        "    if(v > p/2) v -= p;\n",
        "    Y[i] = (int8_t)v;\n",
        "  }\n",
        "}\n",
        "static void fill_rand_int32(vector<int32_t>& A, int rows, int cols, unsigned seed, int maxAbs=1000){\n",
        "  std::mt19937 rng(seed); std::uniform_int_distribution<int> dist(-maxAbs, maxAbs);\n",
        "  for(size_t i=0;i<(size_t)rows*cols;i++) A[i]=dist(rng);\n",
        "}\n",
        "\n",
        "// ====== device: dp4a helper ======\n",
        "__device__ __forceinline__ int dp4a_pack(char4 a, char4 b, int acc){\n",
        "#if __CUDA_ARCH__ >= 610\n",
        "  int ai, bi;\n",
        "  memcpy(&ai,&a,4); memcpy(&bi,&b,4);\n",
        "  return __dp4a(ai, bi, acc);\n",
        "#else\n",
        "  return acc + (int)a.x*(int)b.x + (int)a.y*(int)b.y + (int)a.z*(int)b.z + (int)a.w*(int)b.w;\n",
        "#endif\n",
        "}\n",
        "\n",
        "// ====== kernel: 1 thread computes one C[row,col] mod p ======\n",
        "__global__ void gemm_dp4a_mod(const int8_t* __restrict__ A,   // [M×K]\n",
        "                              const int8_t* __restrict__ B,   // [K×N]\n",
        "                              int32_t* __restrict__ C,        // [M×N], reduced to [0,p)\n",
        "                              int M, int N, int K, int p)\n",
        "{\n",
        "  int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "  int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if(row>=M || col>=N) return;\n",
        "\n",
        "  int acc = 0;\n",
        "  int kk = 0;\n",
        "  for(; kk+3 < K; kk += 4){\n",
        "    // pack 4 A(row, kk..kk+3) and 4 B(kk..kk+3, col)\n",
        "    char4 a4 = make_char4(A[row*(size_t)K + kk + 0],\n",
        "                          A[row*(size_t)K + kk + 1],\n",
        "                          A[row*(size_t)K + kk + 2],\n",
        "                          A[row*(size_t)K + kk + 3]);\n",
        "    char4 b4 = make_char4(B[(kk+0)*(size_t)N + col],\n",
        "                          B[(kk+1)*(size_t)N + col],\n",
        "                          B[(kk+2)*(size_t)N + col],\n",
        "                          B[(kk+3)*(size_t)N + col]);\n",
        "    acc = dp4a_pack(a4, b4, acc);\n",
        "  }\n",
        "  // tail (0..3 leftover)\n",
        "  for(; kk < K; ++kk){\n",
        "    acc += (int)A[row*(size_t)K + kk] * (int)B[kk*(size_t)N + col];\n",
        "  }\n",
        "\n",
        "  int v = acc % p; if(v<0) v += p;\n",
        "  C[row*(size_t)N + col] = v;\n",
        "}\n",
        "\n",
        "// ====== CRT reconstruct a slice for hash & optional uniqueness cert ======\n",
        "static uint64_t crt_reconstruct_hash(const vector<vector<int32_t>>& Cmods, int M, int N, int reconK,\n",
        "                                     const vector<int>& primes, long long cert_bound)\n",
        "{\n",
        "  int P = (int)primes.size();\n",
        "  uint64_t Mprod=1; for(int i=0;i<P;i++) Mprod *= (uint64_t)primes[i];\n",
        "  if(cert_bound>0){\n",
        "    printf(\"CRT certificate: Mprod=%llu  vs  2*bound=%llu  %s\\n\",\n",
        "           (unsigned long long)Mprod,\n",
        "           (unsigned long long)(2ull*(uint64_t)cert_bound),\n",
        "           (Mprod > 2ull*(uint64_t)cert_bound ? \"(UNIQUE RECON OK)\" : \"(INSUFFICIENT)\"));\n",
        "  }\n",
        "  vector<uint64_t> Mi(P), yi(P);\n",
        "  uint64_t Mtot=1; for(int i=0;i<P;i++) Mtot *= (uint64_t)primes[i];\n",
        "  for(int i=0;i<P;i++){ Mi[i]=Mtot/(uint64_t)primes[i]; yi[i]=invmod_u64(Mi[i]%primes[i], primes[i]); }\n",
        "\n",
        "  int K = min(reconK, M*N);\n",
        "  uint64_t h=0;\n",
        "  for(int idx=0; idx<K; ++idx){\n",
        "    uint64_t x=0;\n",
        "    for(int i=0;i<P;i++){\n",
        "      uint64_t ai = (uint64_t)((Cmods[i])[idx] % primes[i] + primes[i]) % primes[i];\n",
        "      x = (x + ai * Mi[i] % Mtot * yi[i] % Mtot) % Mtot;\n",
        "    }\n",
        "    h = fnv1a64_append(h,&x,sizeof(x));\n",
        "  }\n",
        "  return h;\n",
        "}\n",
        "\n",
        "// ====== main ======\n",
        "int main(int argc, char** argv){\n",
        "  ios::sync_with_stdio(false); cin.tie(nullptr);\n",
        "  Args a; parse(argc, argv, a);\n",
        "\n",
        "  // choose primes\n",
        "  int P = max(1, min(a.primes, (int)(sizeof(PRIMETBL)/sizeof(PRIMETBL[0]))));\n",
        "  vector<int> primes(P); for(int i=0;i<P;i++) primes[i]=PRIMETBL[i];\n",
        "\n",
        "  const int M=a.M, N=a.N, K=a.K;\n",
        "  // host int32 inputs\n",
        "  vector<int32_t> Ah((size_t)M*K), Bh((size_t)K*N);\n",
        "  fill_rand_int32(Ah, M, K, a.seed+1);\n",
        "  fill_rand_int32(Bh, K, N, a.seed+2);\n",
        "\n",
        "  // device reuse buffers\n",
        "  int8_t *dA=nullptr, *dB=nullptr; int32_t *dC=nullptr;\n",
        "  cudaMalloc(&dA, (size_t)M*K);\n",
        "  cudaMalloc(&dB, (size_t)K*N);\n",
        "  cudaMalloc(&dC, (size_t)M*N*sizeof(int32_t));\n",
        "\n",
        "  dim3 block(a.bx, a.by);\n",
        "  dim3 grid( (N + block.x - 1)/block.x, (M + block.y - 1)/block.y );\n",
        "\n",
        "  auto t0 = clk::now(); int iters=0;\n",
        "  vector<vector<int32_t>> Cmods(P); for(int i=0;i<P;i++) Cmods[i].resize((size_t)M*N);\n",
        "\n",
        "  double wall_ms=0.0;\n",
        "  do{\n",
        "    for(int pi=0; pi<P; ++pi){\n",
        "      int p = primes[pi];\n",
        "      vector<int8_t> A8, B8;\n",
        "      pack_mod_int8(Ah, A8, M, K, p);\n",
        "      pack_mod_int8(Bh, B8, K, N, p);\n",
        "      cudaMemcpy(dA, A8.data(), (size_t)M*K, cudaMemcpyHostToDevice);\n",
        "      cudaMemcpy(dB, B8.data(), (size_t)K*N, cudaMemcpyHostToDevice);\n",
        "\n",
        "      gemm_dp4a_mod<<<grid, block>>>(dA, dB, dC, M, N, K, p);\n",
        "      cudaDeviceSynchronize();\n",
        "\n",
        "      cudaMemcpy(Cmods[pi].data(), dC, (size_t)M*N*sizeof(int32_t), cudaMemcpyDeviceToHost);\n",
        "    }\n",
        "    iters++;\n",
        "    wall_ms = chrono::duration<double, std::milli>(clk::now()-t0).count();\n",
        "  } while (wall_ms < a.ms_min);\n",
        "\n",
        "  const double secs = wall_ms/1000.0;\n",
        "  const double logical_macs = (double)M * (double)N * (double)K;\n",
        "  const double modular_macs = logical_macs * (double)P;\n",
        "  const double macs_per_sec = modular_macs * iters / secs;\n",
        "  const double dp4a_inst_per_sec = macs_per_sec / 4.0;\n",
        "\n",
        "  uint64_t h=0;\n",
        "  if(a.verify){\n",
        "    h = crt_reconstruct_hash(Cmods, M, N, a.recon_K, primes, a.cert_bound);\n",
        "  }\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [G009b_DP4A_RNS_GEMM] M=%d N=%d K=%d  primes=%d  iters=%d  time=%.2f ms\\n\", M,N,K,P,iters,wall_ms);\n",
        "  printf(\"  Logical MACs/s:        %.3f G-mac/s   (per real GEMM)\\n\", (logical_macs*iters)/secs/1e9);\n",
        "  printf(\"  Modular MACs/s:        %.3f G-mac/s   (× primes)\\n\", (modular_macs*iters)/secs/1e9);\n",
        "  printf(\"  Effective dp4a instr/s %.3f G-inst/s  (~ MACs/4)\\n\", dp4a_inst_per_sec/1e9);\n",
        "  if(a.verify){\n",
        "    printf(\"  CRT slice hash (first %d of C): 0x%016llx\\n\", a.recon_K, (unsigned long long)h);\n",
        "  }\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  cudaFree(dA); cudaFree(dB); cudaFree(dC);\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# Build: sm_75 for T4\n",
        "nvcc -O3 -std=c++17 -arch=sm_75 -Xptxas -dlcm=ca -lineinfo g009b_dp4a_rns_gemm.cu -o g009b_dp4a_rns_gemm\n",
        "\n",
        "echo \"=== G009b: quick sanity (small) ===\"\n",
        "./g009b_dp4a_rns_gemm --M 512 --N 512 --K 512 --primes 5 --ms 300 --reconK 4096 --cert 1000000\n",
        "\n",
        "echo\n",
        "echo \"=== G009b: bigger (fits T4) ===\"\n",
        "./g009b_dp4a_rns_gemm --M 1024 --N 1024 --K 2048 --primes 9 --bx 16 --by 16 --ms 500 --reconK 8192 --cert 100000000\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEOqPvKZLEft",
        "outputId": "5183578c-1cc8-4d3a-fc8e-fee89d7b7935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== G009b: quick sanity (small) ===\n",
            "CRT certificate: Mprod=17239698439  vs  2*bound=2000000  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G009b_DP4A_RNS_GEMM] M=512 N=512 K=512  primes=5  iters=4  time=306.76 ms\n",
            "  Logical MACs/s:        1.750 G-mac/s   (per real GEMM)\n",
            "  Modular MACs/s:        8.751 G-mac/s   (× primes)\n",
            "  Effective dp4a instr/s 2.188 G-inst/s  (~ MACs/4)\n",
            "  CRT slice hash (first 4096 of C): 0x3512e7a68919782b\n",
            "============================================================================\n",
            "\n",
            "=== G009b: bigger (fits T4) ===\n",
            "CRT certificate: Mprod=1247644544258044721  vs  2*bound=200000000  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G009b_DP4A_RNS_GEMM] M=1024 N=1024 K=2048  primes=9  iters=1  time=911.83 ms\n",
            "  Logical MACs/s:        2.355 G-mac/s   (per real GEMM)\n",
            "  Modular MACs/s:        21.196 G-mac/s   (× primes)\n",
            "  Effective dp4a instr/s 5.299 G-inst/s  (~ MACs/4)\n",
            "  CRT slice hash (first 8192 of C): 0x5e062954aa5fd665\n",
            "============================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "g009b_dp4a_rns_gemm.cu(42): warning #177-D: function \"secs_since\" was declared but never referenced\n",
            "  static inline double secs_since(clk::time_point t0){ return chrono::duration<double>(clk::now()-t0).count(); }\n",
            "                       ^\n",
            "\n",
            "Remark: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# =====================================================================\n",
        "# ███████████████  MODULE G009c :: DP4A RNS GEMM (tiled, fast)  ███████\n",
        "#  - Exact multi-prime RNS GEMM on T4 using int8 (__dp4a)\n",
        "#  - 128x128x64 tiling with shared memory\n",
        "#  - Each thread computes a 4x4 output micro-tile in registers\n",
        "#  - Coalesced global->smem loads, int32 acc, mod-reduce\n",
        "#  - CRT slice hash + uniqueness certificate + ops accounting\n",
        "# =====================================================================\n",
        "\n",
        "cat > g009c_dp4a_rns_gemm_tiled.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "using namespace std;\n",
        "using clk = chrono::high_resolution_clock;\n",
        "\n",
        "// ====== args ======\n",
        "struct Args {\n",
        "  int M = 1024, N = 1024, K = 2048;\n",
        "  int primes = 9;              // number of residue primes (<= PRIMETBL)\n",
        "  int ms_min = 500;            // run time window (ms)\n",
        "  int verify = 1;              // 1 => CRT slice hash\n",
        "  int recon_K = 8192;          // elems to reconstruct for hash\n",
        "  long long cert_bound = 100000000; // for uniqueness cert\n",
        "  unsigned seed = 12345u;      // RNG seed\n",
        "};\n",
        "static void parse(int argc, char** argv, Args& a){\n",
        "  for(int i=1;i<argc;i++){\n",
        "    string s=argv[i]; auto need=[&]{ if(i+1>=argc){ fprintf(stderr,\"Missing value for %s\\n\", s.c_str()); exit(1);} };\n",
        "    if(s==\"--M\"){ need(); a.M=atoi(argv[++i]); }\n",
        "    else if(s==\"--N\"){ need(); a.N=atoi(argv[++i]); }\n",
        "    else if(s==\"--K\"){ need(); a.K=atoi(argv[++i]); }\n",
        "    else if(s==\"--primes\"){ need(); a.primes=atoi(argv[++i]); }\n",
        "    else if(s==\"--ms\"){ need(); a.ms_min=atoi(argv[++i]); }\n",
        "    else if(s==\"--verify\"){ a.verify=1; }\n",
        "    else if(s==\"--noverify\"){ a.verify=0; }\n",
        "    else if(s==\"--reconK\"){ need(); a.recon_K=atoi(argv[++i]); }\n",
        "    else if(s==\"--cert\"){ need(); a.cert_bound=atoll(argv[++i]); }\n",
        "    else if(s==\"--seed\"){ need(); a.seed=(unsigned)strtoul(argv[++i],nullptr,10); }\n",
        "  }\n",
        "}\n",
        "\n",
        "// ====== primes ≤ 127 (pairwise coprime) ======\n",
        "static const int PRIMETBL[16] = {\n",
        "  127, 113, 109, 107, 103, 101, 97, 89,\n",
        "   83,  79,  73,  71,  67,  61, 59, 53\n",
        "};\n",
        "\n",
        "// ====== host utils ======\n",
        "static inline uint64_t fnv1a64_append(uint64_t h, const void* p, size_t n){\n",
        "  const uint8_t* b=(const uint8_t*)p; const uint64_t P=1099511628211ull;\n",
        "  for(size_t i=0;i<n;i++){ h^=b[i]; h*=P; } return h;\n",
        "}\n",
        "static uint64_t invmod_u64(uint64_t a, uint64_t mod){\n",
        "  int64_t t=0,newt=1; int64_t r=(int64_t)mod,newr=(int64_t)a;\n",
        "  while(newr){ int64_t q=r/newr; tie(t,newt)=make_tuple(newt,t-q*newt); tie(r,newr)=make_tuple(newr,r-q*newr); }\n",
        "  if(r>1) return 0; if(t<0) t+=mod; return (uint64_t)t;\n",
        "}\n",
        "static void fill_rand_int32(vector<int32_t>& A, int rows, int cols, unsigned seed, int maxAbs=1000){\n",
        "  std::mt19937 rng(seed); std::uniform_int_distribution<int> dist(-maxAbs, maxAbs);\n",
        "  for(size_t i=0;i<(size_t)rows*cols;i++) A[i]=dist(rng);\n",
        "}\n",
        "static void pack_mod_int8(const vector<int32_t>& X, vector<int8_t>& Y, int rows, int cols, int p){\n",
        "  Y.resize((size_t)rows*cols);\n",
        "  for(size_t i=0;i<Y.size();++i){\n",
        "    int v = (int)(((long long)X[i]%p + p) % p);\n",
        "    if(v > p/2) v -= p; // symmetric range to stay within int8\n",
        "    Y[i] = (int8_t)v;\n",
        "  }\n",
        "}\n",
        "\n",
        "// ====== device helpers ======\n",
        "__device__ __forceinline__ int dp4a_pack(char4 a, char4 b, int acc){\n",
        "#if __CUDA_ARCH__ >= 610\n",
        "  int ai, bi; memcpy(&ai,&a,4); memcpy(&bi,&b,4);\n",
        "  return __dp4a(ai, bi, acc);\n",
        "#else\n",
        "  return acc + (int)a.x*(int)b.x + (int)a.y*(int)b.y + (int)a.z*(int)b.z + (int)a.w*(int)b.w;\n",
        "#endif\n",
        "}\n",
        "\n",
        "// ====== tiled dp4a GEMM (mod prime) ======\n",
        "// Tile sizes\n",
        "constexpr int TM = 128;  // tile M\n",
        "constexpr int TN = 128;  // tile N\n",
        "constexpr int TK = 64;   // tile K (multiple of 4)\n",
        "constexpr int BLK_X = 32; // threads.x\n",
        "constexpr int BLK_Y = 8;  // threads.y\n",
        "// Each thread computes 4x4 outputs\n",
        "__global__ void gemm_dp4a_mod_tiled(const int8_t* __restrict__ A,   // [M×K]\n",
        "                                    const int8_t* __restrict__ B,   // [K×N]\n",
        "                                    int32_t* __restrict__ C,        // [M×N], reduced to [0,p)\n",
        "                                    int M, int N, int K, int p)\n",
        "{\n",
        "  __shared__ int8_t As[TM*TK];\n",
        "  __shared__ int8_t Bs[TK*TN];\n",
        "\n",
        "  const int tidx = threadIdx.x;\n",
        "  const int tidy = threadIdx.y;\n",
        "  const int rowBlock = blockIdx.y * TM;\n",
        "  const int colBlock = blockIdx.x * TN;\n",
        "\n",
        "  // thread's 4x4 micro-tile origin inside the 128x128 C tile\n",
        "  // Map 32x8 threads to 32*4 = 128 cols and 8*4 = 32 rows? We'll do 4 rows per thread and 4 cols per thread:\n",
        "  const int rowBase = rowBlock + tidy*4;\n",
        "  const int colBase = colBlock + tidx*4;\n",
        "\n",
        "  // accumulators\n",
        "  int acc[4][4];\n",
        "  #pragma unroll\n",
        "  for(int i=0;i<4;i++){\n",
        "    #pragma unroll\n",
        "    for(int j=0;j<4;j++) acc[i][j]=0;\n",
        "  }\n",
        "\n",
        "  // loop over K in TK steps\n",
        "  for(int kk=0; kk<K; kk+=TK){\n",
        "    // cooperative load As (TM x TK)\n",
        "    // linear index per thread\n",
        "    int linear = tidy*BLK_X + tidx;          // 0..255\n",
        "    int stride = BLK_X*BLK_Y;                // 256\n",
        "    int totalA = TM*TK;                      // 8192\n",
        "    for(int t = linear; t < totalA; t += stride){\n",
        "      int a_r = t / TK;\n",
        "      int a_k = t % TK;\n",
        "      int g_r = rowBlock + a_r;\n",
        "      int g_k = kk + a_k;\n",
        "      int8_t v = 0;\n",
        "      if(g_r < M && g_k < K){\n",
        "        v = A[g_r*(size_t)K + g_k];\n",
        "      }\n",
        "      As[t] = v;\n",
        "    }\n",
        "\n",
        "    // cooperative load Bs (TK x TN)\n",
        "    int totalB = TK*TN;                      // 8192\n",
        "    for(int t = linear; t < totalB; t += stride){\n",
        "      int b_k = t / TN;\n",
        "      int b_c = t % TN;\n",
        "      int g_k = kk + b_k;\n",
        "      int g_c = colBlock + b_c;\n",
        "      int8_t v = 0;\n",
        "      if(g_k < K && g_c < N){\n",
        "        v = B[g_k*(size_t)N + g_c];\n",
        "      }\n",
        "      Bs[t] = v;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // iterate this TK tile in steps of 4 (dp4a width)\n",
        "    for(int k4=0; k4<TK; k4+=4){\n",
        "      // load 4 As elements for each of our 4 rows\n",
        "      char4 a4[4];\n",
        "      #pragma unroll\n",
        "      for(int i=0;i<4;i++){\n",
        "        int r = tidy*4 + i;                // 0..31 within tile\n",
        "        int aoff = r*TK + k4;\n",
        "        char4 val = make_char4( As[aoff+0], As[aoff+1], As[aoff+2], As[aoff+3] );\n",
        "        a4[i] = val;\n",
        "      }\n",
        "      // load 4 Bs elements for each of our 4 cols (gather in K dimension)\n",
        "      char4 b4[4];\n",
        "      #pragma unroll\n",
        "      for(int j=0;j<4;j++){\n",
        "        int c = tidx*4 + j;                // 0..127 within tile\n",
        "        int boff0 = (k4+0)*TN + c;\n",
        "        int boff1 = (k4+1)*TN + c;\n",
        "        int boff2 = (k4+2)*TN + c;\n",
        "        int boff3 = (k4+3)*TN + c;\n",
        "        char4 val = make_char4( Bs[boff0], Bs[boff1], Bs[boff2], Bs[boff3] );\n",
        "        b4[j] = val;\n",
        "      }\n",
        "      // FMA into 4x4 accumulators\n",
        "      #pragma unroll\n",
        "      for(int i=0;i<4;i++){\n",
        "        #pragma unroll\n",
        "        for(int j=0;j<4;j++){\n",
        "          acc[i][j] = dp4a_pack(a4[i], b4[j], acc[i][j]);\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "\n",
        "  // write out reduced results (guard edges)\n",
        "  #pragma unroll\n",
        "  for(int i=0;i<4;i++){\n",
        "    int r = rowBase + i;\n",
        "    if(r >= M) break;\n",
        "    #pragma unroll\n",
        "    for(int j=0;j<4;j++){\n",
        "      int c = colBase + j;\n",
        "      if(c >= N) break;\n",
        "      int v = acc[i][j] % p; if(v<0) v += p;\n",
        "      C[r*(size_t)N + c] = v;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "// ====== CRT and report ======\n",
        "static uint64_t crt_reconstruct_hash(const vector<vector<int32_t>>& Cmods, int M, int N, int reconK,\n",
        "                                     const vector<int>& primes, long long cert_bound)\n",
        "{\n",
        "  int P = (int)primes.size();\n",
        "  uint64_t Mprod=1; for(int i=0;i<P;i++) Mprod *= (uint64_t)primes[i];\n",
        "  if(cert_bound>0){\n",
        "    printf(\"CRT certificate: Mprod=%llu  vs  2*bound=%llu  %s\\n\",\n",
        "           (unsigned long long)Mprod,\n",
        "           (unsigned long long)(2ull*(uint64_t)cert_bound),\n",
        "           (Mprod > 2ull*(uint64_t)cert_bound ? \"(UNIQUE RECON OK)\" : \"(INSUFFICIENT)\"));\n",
        "  }\n",
        "  vector<uint64_t> Mi(P), yi(P);\n",
        "  uint64_t Mtot=1; for(int i=0;i<P;i++) Mtot *= (uint64_t)primes[i];\n",
        "  for(int i=0;i<P;i++){ Mi[i]=Mtot/(uint64_t)primes[i]; yi[i]=invmod_u64(Mi[i]%primes[i], primes[i]); }\n",
        "\n",
        "  int K = min(reconK, M*N);\n",
        "  uint64_t h=0;\n",
        "  for(int idx=0; idx<K; ++idx){\n",
        "    uint64_t x=0;\n",
        "    for(int i=0;i<P;i++){\n",
        "      uint64_t ai = (uint64_t)((Cmods[i])[idx] % primes[i] + primes[i]) % primes[i];\n",
        "      x = (x + ai * Mi[i] % Mtot * yi[i] % Mtot) % Mtot;\n",
        "    }\n",
        "    h = fnv1a64_append(h,&x,sizeof(x));\n",
        "  }\n",
        "  return h;\n",
        "}\n",
        "\n",
        "// ====== main ======\n",
        "int main(int argc, char** argv){\n",
        "  ios::sync_with_stdio(false); cin.tie(nullptr);\n",
        "  Args a; parse(argc, argv, a);\n",
        "\n",
        "  // choose primes\n",
        "  int P = max(1, min(a.primes, (int)(sizeof(PRIMETBL)/sizeof(PRIMETBL[0]))));\n",
        "  vector<int> primes(P); for(int i=0;i<P;i++) primes[i]=PRIMETBL[i];\n",
        "\n",
        "  const int M=a.M, N=a.N, K=a.K;\n",
        "  vector<int32_t> Ah((size_t)M*K), Bh((size_t)K*N);\n",
        "  fill_rand_int32(Ah, M, K, a.seed+1);\n",
        "  fill_rand_int32(Bh, K, N, a.seed+2);\n",
        "\n",
        "  // device buffers (reused across primes)\n",
        "  int8_t *dA=nullptr, *dB=nullptr; int32_t *dC=nullptr;\n",
        "  cudaMalloc(&dA, (size_t)M*K);\n",
        "  cudaMalloc(&dB, (size_t)K*N);\n",
        "  cudaMalloc(&dC, (size_t)M*N*sizeof(int32_t));\n",
        "\n",
        "  dim3 block(BLK_X, BLK_Y);                 // 32x8 = 256 threads per block\n",
        "  dim3 grid( (N + TM - 1)/TN, (M + TM - 1)/TM );\n",
        "\n",
        "  auto t0 = clk::now(); int iters=0;\n",
        "  vector<vector<int32_t>> Cmods(P); for(int i=0;i<P;i++) Cmods[i].resize((size_t)M*N);\n",
        "\n",
        "  double wall_ms=0.0;\n",
        "  do{\n",
        "    for(int pi=0; pi<P; ++pi){\n",
        "      int p = primes[pi];\n",
        "      vector<int8_t> A8, B8;\n",
        "      pack_mod_int8(Ah, A8, M, K, p);\n",
        "      pack_mod_int8(Bh, B8, K, N, p);\n",
        "      cudaMemcpy(dA, A8.data(), (size_t)M*K, cudaMemcpyHostToDevice);\n",
        "      cudaMemcpy(dB, B8.data(), (size_t)K*N, cudaMemcpyHostToDevice);\n",
        "\n",
        "      gemm_dp4a_mod_tiled<<<grid, block>>>(dA, dB, dC, M, N, K, p);\n",
        "      cudaDeviceSynchronize();\n",
        "\n",
        "      cudaMemcpy(Cmods[pi].data(), dC, (size_t)M*N*sizeof(int32_t), cudaMemcpyDeviceToHost);\n",
        "    }\n",
        "    iters++;\n",
        "    wall_ms = chrono::duration<double, std::milli>(clk::now()-t0).count();\n",
        "  } while (wall_ms < a.ms_min);\n",
        "\n",
        "  const double secs = wall_ms/1000.0;\n",
        "  const double logical_macs = (double)M * (double)N * (double)K;\n",
        "  const double modular_macs = logical_macs * (double)P;\n",
        "  const double macs_per_sec = modular_macs * iters / secs;\n",
        "  const double dp4a_inst_per_sec = macs_per_sec / 4.0;\n",
        "\n",
        "  uint64_t h=0;\n",
        "  if(a.verify){\n",
        "    h = crt_reconstruct_hash(Cmods, M, N, a.recon_K, primes, a.cert_bound);\n",
        "  }\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [G009c_DP4A_RNS_GEMM_TILED] M=%d N=%d K=%d  primes=%d  iters=%d  time=%.2f ms\\n\", M,N,K,P,iters,wall_ms);\n",
        "  printf(\"  Logical MACs/s:        %.3f G-mac/s   (per real GEMM)\\n\", (logical_macs*iters)/secs/1e9);\n",
        "  printf(\"  Modular MACs/s:        %.3f G-mac/s   (× primes)\\n\", (modular_macs*iters)/secs/1e9);\n",
        "  printf(\"  Effective dp4a instr/s %.3f G-inst/s  (~ MACs/4)\\n\", dp4a_inst_per_sec/1e9);\n",
        "  if(a.verify){\n",
        "    printf(\"  CRT slice hash (first %d of C): 0x%016llx\\n\", a.recon_K, (unsigned long long)h);\n",
        "  }\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  cudaFree(dA); cudaFree(dB); cudaFree(dC);\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# Build for T4\n",
        "nvcc -O3 -std=c++17 -arch=sm_75 -Xptxas -dlcm=ca -lineinfo g009c_dp4a_rns_gemm_tiled.cu -o g009c_dp4a_rns_gemm_tiled\n",
        "\n",
        "echo \"=== G009c: quick sanity (same dims as before) ===\"\n",
        "./g009c_dp4a_rns_gemm_tiled --M 512 --N 512 --K 512 --primes 5 --ms 300 --reconK 4096 --cert 1000000\n",
        "\n",
        "echo\n",
        "echo \"=== G009c: bigger (same as your big test) ===\"\n",
        "./g009c_dp4a_rns_gemm_tiled --M 1024 --N 1024 --K 2048 --primes 9 --ms 500 --reconK 8192 --cert 200000000\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_q5mfhbLrMW",
        "outputId": "5ac51bc6-5898-4795-b6f3-6ef41dac0aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== G009c: quick sanity (same dims as before) ===\n",
            "CRT certificate: Mprod=17239698439  vs  2*bound=2000000  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G009c_DP4A_RNS_GEMM_TILED] M=512 N=512 K=512  primes=5  iters=6  time=307.92 ms\n",
            "  Logical MACs/s:        2.615 G-mac/s   (per real GEMM)\n",
            "  Modular MACs/s:        13.077 G-mac/s   (× primes)\n",
            "  Effective dp4a instr/s 3.269 G-inst/s  (~ MACs/4)\n",
            "  CRT slice hash (first 4096 of C): 0x3512e7a68919782b\n",
            "============================================================================\n",
            "\n",
            "=== G009c: bigger (same as your big test) ===\n",
            "CRT certificate: Mprod=1247644544258044721  vs  2*bound=400000000  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G009c_DP4A_RNS_GEMM_TILED] M=1024 N=1024 K=2048  primes=9  iters=1  time=766.47 ms\n",
            "  Logical MACs/s:        2.802 G-mac/s   (per real GEMM)\n",
            "  Modular MACs/s:        25.216 G-mac/s   (× primes)\n",
            "  Effective dp4a instr/s 6.304 G-inst/s  (~ MACs/4)\n",
            "  CRT slice hash (first 8192 of C): 0x5e062954aa5fd665\n",
            "============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# =====================================================================\n",
        "# ████████████  MODULE G009e_REPLACE3 :: DP4A RNS GEMM (512 thr)  █████\n",
        "#   - Fix \"too many resources requested\": 32x16 threads (512/block)\n",
        "#   - Per-thread microtile 8x4 → covers 128x128 tile fully\n",
        "#   - TK=64 ping-pong shared, strict __dp4a packing, exact mod p\n",
        "#   - Robust host: CUDA error checks + STRIDED CRT slice\n",
        "#   - Exports same kernel symbol: gemm_dp4a_mod_tiler\n",
        "# =====================================================================\n",
        "\n",
        "cat > g009e_dp4a_rns_gemm_tiler.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "using namespace std;\n",
        "using clk = chrono::high_resolution_clock;\n",
        "\n",
        "// ====== args ======\n",
        "struct Args {\n",
        "  int M = 1024, N = 1024, K = 2048;\n",
        "  int primes = 9;\n",
        "  int ms_min = 500;\n",
        "  int verify = 1;\n",
        "  int recon_K = 8192;\n",
        "  long long cert_bound = 200000000;\n",
        "  unsigned seed = 12345u;\n",
        "};\n",
        "static void parse(int argc, char** argv, Args& a){\n",
        "  for(int i=1;i<argc;i++){\n",
        "    string s=argv[i]; auto need=[&]{ if(i+1>=argc){ fprintf(stderr,\"Missing value for %s\\n\", s.c_str()); exit(1);} };\n",
        "    if(s==\"--M\"){ need(); a.M=atoi(argv[++i]); }\n",
        "    else if(s==\"--N\"){ need(); a.N=atoi(argv[++i]); }\n",
        "    else if(s==\"--K\"){ need(); a.K=atoi(argv[++i]); }\n",
        "    else if(s==\"--primes\"){ need(); a.primes=atoi(argv[++i]); }\n",
        "    else if(s==\"--ms\"){ need(); a.ms_min=atoi(argv[++i]); }\n",
        "    else if(s==\"--verify\"){ a.verify=1; }\n",
        "    else if(s==\"--noverify\"){ a.verify=0; }\n",
        "    else if(s==\"--reconK\"){ need(); a.recon_K=atoi(argv[++i]); }\n",
        "    else if(s==\"--cert\"){ need(); a.cert_bound=atoll(argv[++i]); }\n",
        "    else if(s==\"--seed\"){ need(); a.seed=(unsigned)strtoul(argv[++i],nullptr,10); }\n",
        "  }\n",
        "}\n",
        "\n",
        "// ====== primes ≤127 ======\n",
        "static const int PRIMETBL[16] = {\n",
        "  127, 113, 109, 107, 103, 101, 97, 89,\n",
        "   83,  79,  73,  71,  67,  61, 59, 53\n",
        "};\n",
        "\n",
        "// ====== host utils ======\n",
        "static inline void CUDA_OK(cudaError_t e, const char* where){\n",
        "  if(e!=cudaSuccess){ fprintf(stderr,\"CUDA ERROR at %s: %s\\n\", where, cudaGetErrorString(e)); exit(1); }\n",
        "}\n",
        "static inline uint64_t fnv1a64_append(uint64_t h, const void* p, size_t n){\n",
        "  const uint8_t* b=(const uint8_t*)p; const uint64_t P=1099511628211ull;\n",
        "  for(size_t i=0;i<n;i++){ h^=b[i]; h*=P; } return h;\n",
        "}\n",
        "static uint64_t invmod_u64(uint64_t a, uint64_t mod){\n",
        "  int64_t t=0,newt=1; int64_t r=(int64_t)mod,newr=(int64_t)a;\n",
        "  while(newr){ int64_t q=r/newr; tie(t,newt)=make_tuple(newt,t-q*newt); tie(r,newr)=make_tuple(newr,r-q*newr); }\n",
        "  if(r>1) return 0; if(t<0) t+=mod; return (uint64_t)t;\n",
        "}\n",
        "static void fill_rand_int32(vector<int32_t>& A, int rows, int cols, unsigned seed, int maxAbs=511){\n",
        "  std::mt19937 rng(seed); std::uniform_int_distribution<int> dist(-maxAbs, maxAbs);\n",
        "  for(size_t i=0;i<(size_t)rows*cols;i++) A[i]=dist(rng);\n",
        "}\n",
        "static void pack_mod_int8(const vector<int32_t>& X, vector<int8_t>& Y, int rows, int cols, int p){\n",
        "  Y.resize((size_t)rows*cols);\n",
        "  for(size_t i=0;i<Y.size();++i){\n",
        "    int v = (int)(((long long)X[i]%p + p) % p);\n",
        "    if(v > p/2) v -= p;\n",
        "    Y[i] = (int8_t)v;\n",
        "  }\n",
        "}\n",
        "\n",
        "// ====== device helpers ======\n",
        "__device__ __forceinline__ int pack_char4_i32_strict(char4 v){\n",
        "  union { int i; signed char b[4]; } u;\n",
        "  u.b[0]=v.x; u.b[1]=v.y; u.b[2]=v.z; u.b[3]=v.w;\n",
        "  return u.i;\n",
        "}\n",
        "__device__ __forceinline__ int dp4a_i32_safe(int ai, int bi, int acc){\n",
        "#if __CUDA_ARCH__ >= 610\n",
        "  return __dp4a(ai, bi, acc);\n",
        "#else\n",
        "  union { int i; signed char b[4]; } A,B; A.i=ai; B.i=bi;\n",
        "  acc += (int)A.b[0]*(int)B.b[0];\n",
        "  acc += (int)A.b[1]*(int)B.b[1];\n",
        "  acc += (int)A.b[2]*(int)B.b[2];\n",
        "  acc += (int)A.b[3]*(int)B.b[3];\n",
        "  return acc;\n",
        "#endif\n",
        "}\n",
        "\n",
        "// ====== tiled dp4a GEMM (lighter block) ======\n",
        "constexpr int TM = 128;   // tile M\n",
        "constexpr int TN = 128;   // tile N\n",
        "constexpr int TK = 64;    // tile K (×2 ping-pong)\n",
        "\n",
        "constexpr int BLK_X = 32; // threads.x (512 threads total)\n",
        "constexpr int BLK_Y = 16; // threads.y\n",
        "constexpr int RM = 8;     // rows per thread\n",
        "constexpr int CN = 4;     // cols per thread\n",
        "// coverage: BLK_Y*RM = 16*8 = 128 rows, BLK_X*CN = 32*4 = 128 cols\n",
        "\n",
        "extern \"C\"\n",
        "__global__ void gemm_dp4a_mod_tiler(const int8_t* __restrict__ A,\n",
        "                                    const int8_t* __restrict__ B,\n",
        "                                    int32_t* __restrict__ C,\n",
        "                                    int M, int N, int K, int p)\n",
        "{\n",
        "  extern __shared__ __align__(16) int8_t smem[];\n",
        "  int8_t* As0 = smem;                  // TM*TK\n",
        "  int8_t* Bs0 = As0 + TM*TK;           // TK*TN\n",
        "  int8_t* As1 = Bs0 + TK*TN;\n",
        "  int8_t* Bs1 = As1 + TM*TK;\n",
        "\n",
        "  const int tx = threadIdx.x;\n",
        "  const int ty = threadIdx.y;\n",
        "\n",
        "  const int rowBlock = blockIdx.y * TM;\n",
        "  const int colBlock = blockIdx.x * TN;\n",
        "\n",
        "  // per-thread microtile origin inside 128x128\n",
        "  const int rowBase = rowBlock + ty*RM;\n",
        "  const int colBase = colBlock + tx*CN;\n",
        "\n",
        "  int acc[RM][CN];\n",
        "  #pragma unroll\n",
        "  for(int i=0;i<RM;i++){\n",
        "    #pragma unroll\n",
        "    for(int j=0;j<CN;j++) acc[i][j]=0;\n",
        "  }\n",
        "\n",
        "  auto coop_load_A = [&](int8_t* As, int kk){\n",
        "    const int linear = ty*BLK_X + tx;      // 0..511\n",
        "    const int stride = BLK_X*BLK_Y;        // 512\n",
        "    const int total  = TM*TK;              // 8192\n",
        "    for(int t=linear; t<total; t+=stride){\n",
        "      int a_r = t / TK;\n",
        "      int a_k = t % TK;\n",
        "      int g_r = rowBlock + a_r;\n",
        "      int g_k = kk + a_k;\n",
        "      As[t] = (g_r<M && g_k<K) ? A[g_r*(size_t)K + g_k] : 0;\n",
        "    }\n",
        "  };\n",
        "  auto coop_load_B = [&](int8_t* Bs, int kk){\n",
        "    const int linear = ty*BLK_X + tx;\n",
        "    const int stride = BLK_X*BLK_Y;\n",
        "    const int total  = TK*TN;              // 8192\n",
        "    for(int t=linear; t<total; t+=stride){\n",
        "      int b_k = t / TN;\n",
        "      int b_c = t % TN;\n",
        "      int g_k = kk + b_k;\n",
        "      int g_c = colBlock + b_c;\n",
        "      Bs[t] = (g_k<K && g_c<N) ? B[g_k*(size_t)N + g_c] : 0;\n",
        "    }\n",
        "  };\n",
        "\n",
        "  int kk = 0;\n",
        "  coop_load_A(As0, kk);\n",
        "  coop_load_B(Bs0, kk);\n",
        "  __syncthreads();\n",
        "\n",
        "  for(; kk < K; kk += TK){\n",
        "    int nextk = kk + TK;\n",
        "    if(nextk < K){\n",
        "      if(((kk/TK)&1)==0){ coop_load_A(As1,nextk); coop_load_B(Bs1,nextk); }\n",
        "      else               { coop_load_A(As0,nextk); coop_load_B(Bs0,nextk); }\n",
        "    }\n",
        "    int8_t* As = ((kk/TK)&1)? As1:As0;\n",
        "    int8_t* Bs = ((kk/TK)&1)? Bs1:Bs0;\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // iterate TK in steps of 4 (dp4a width)\n",
        "    #pragma unroll\n",
        "    for(int k4=0; k4<TK; k4+=4){\n",
        "      // build 8 A rows × 4-lane chunk\n",
        "      char4 a4[RM];\n",
        "      #pragma unroll\n",
        "      for(int i=0;i<RM;i++){\n",
        "        int ar = ty*RM + i;               // 0..127 within tile\n",
        "        int aoff = ar*TK + k4;\n",
        "        a4[i] = make_char4(As[aoff+0], As[aoff+1], As[aoff+2], As[aoff+3]);\n",
        "      }\n",
        "      // build 4 B cols × 4-lane chunk\n",
        "      char4 b4[CN];\n",
        "      #pragma unroll\n",
        "      for(int j=0;j<CN;j++){\n",
        "        int c = tx*CN + j;                // 0..127 within tile\n",
        "        int bo0 = (k4+0)*TN + c;\n",
        "        int bo1 = (k4+1)*TN + c;\n",
        "        int bo2 = (k4+2)*TN + c;\n",
        "        int bo3 = (k4+3)*TN + c;\n",
        "        b4[j] = make_char4(Bs[bo0], Bs[bo1], Bs[bo2], Bs[bo3]);\n",
        "      }\n",
        "\n",
        "      int ai[RM];\n",
        "      int bi[CN];\n",
        "      #pragma unroll\n",
        "      for(int i=0;i<RM;i++) ai[i] = pack_char4_i32_strict(a4[i]);\n",
        "      #pragma unroll\n",
        "      for(int j=0;j<CN;j++) bi[j] = pack_char4_i32_strict(b4[j]);\n",
        "\n",
        "      // RM×CN MACs\n",
        "      #pragma unroll\n",
        "      for(int i=0;i<RM;i++){\n",
        "        #pragma unroll\n",
        "        for(int j=0;j<CN;j++){\n",
        "          acc[i][j] = dp4a_i32_safe(ai[i], bi[j], acc[i][j]);\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "\n",
        "  // write-back with mod reduction\n",
        "  #pragma unroll\n",
        "  for(int i=0;i<RM;i++){\n",
        "    int r = rowBase + i; if(r>=M) break;\n",
        "    #pragma unroll\n",
        "    for(int j=0;j<CN;j++){\n",
        "      int c = colBase + j; if(c>=N) break;\n",
        "      int v = acc[i][j] % p; if(v<0) v += p;\n",
        "      C[r*(size_t)N + c] = v;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "// ====== CRT: STRIDED sampler ======\n",
        "static uint64_t crt_reconstruct_hash_strided(const vector<vector<int32_t>>& Cmods, int M, int N, int reconK,\n",
        "                                             const vector<int>& primes, long long cert_bound)\n",
        "{\n",
        "  int P = (int)primes.size();\n",
        "  uint64_t Mprod=1; for(int i=0;i<P;i++) Mprod *= (uint64_t)primes[i];\n",
        "  if(cert_bound>0){\n",
        "    printf(\"CRT certificate: Mprod=%llu  vs  2*bound=%llu  %s\\n\",\n",
        "           (unsigned long long)Mprod,\n",
        "           (unsigned long long)(2ull*(uint64_t)cert_bound),\n",
        "           (Mprod > 2ull*(uint64_t)cert_bound ? \"(UNIQUE RECON OK)\" : \"(INSUFFICIENT)\"));\n",
        "  }\n",
        "  vector<uint64_t> Mi(P), yi(P);\n",
        "  uint64_t Mtot=1; for(int i=0;i<P;i++) Mtot *= (uint64_t)primes[i];\n",
        "  for(int i=0;i<P;i++){ Mi[i]=Mtot/(uint64_t)primes[i]; yi[i]=invmod_u64(Mi[i]%primes[i], primes[i]); }\n",
        "\n",
        "  const int total = M*N;\n",
        "  const int K = min(reconK, total);\n",
        "  const int stride = 1315423911u % max(1,total); // big odd-ish stride\n",
        "  int idx = 0;\n",
        "\n",
        "  uint64_t h=0;\n",
        "  for(int t=0; t<K; ++t){\n",
        "    uint64_t x=0;\n",
        "    for(int i=0;i<P;i++){\n",
        "      uint64_t ai = (uint64_t)((Cmods[i])[idx] % primes[i] + primes[i]) % primes[i];\n",
        "      x = (x + ai * Mi[i] % Mtot * yi[i] % Mtot) % Mtot;\n",
        "    }\n",
        "    h = fnv1a64_append(h,&x,sizeof(x));\n",
        "    idx += stride; if(idx >= total) idx -= total;\n",
        "  }\n",
        "  return h;\n",
        "}\n",
        "\n",
        "// ====== main ======\n",
        "int main(int argc, char** argv){\n",
        "  ios::sync_with_stdio(false); cin.tie(nullptr);\n",
        "  Args a; parse(argc, argv, a);\n",
        "\n",
        "  int P = max(1, min(a.primes, (int)(sizeof(PRIMETBL)/sizeof(PRIMETBL[0]))));\n",
        "  vector<int> primes(P); for(int i=0;i<P;i++) primes[i]=PRIMETBL[i];\n",
        "\n",
        "  const int M=a.M, N=a.N, K=a.K;\n",
        "  vector<int32_t> Ah((size_t)M*K), Bh((size_t)K*N);\n",
        "  fill_rand_int32(Ah, M, K, a.seed+1);\n",
        "  fill_rand_int32(Bh, K, N, a.seed+2);\n",
        "\n",
        "  int8_t *dA=nullptr, *dB=nullptr; int32_t *dC=nullptr;\n",
        "  CUDA_OK(cudaMalloc(&dA, (size_t)M*K), \"cudaMalloc dA\");\n",
        "  CUDA_OK(cudaMalloc(&dB, (size_t)K*N), \"cudaMalloc dB\");\n",
        "  CUDA_OK(cudaMalloc(&dC, (size_t)M*N*sizeof(int32_t)), \"cudaMalloc dC\");\n",
        "\n",
        "  dim3 block(BLK_X, BLK_Y);                    // 32×16 = 512 threads\n",
        "  dim3 grid( (N + TN - 1)/TN, (M + TM - 1)/TM );\n",
        "  size_t smem_bytes = (size_t)(TM*TK + TK*TN)*2; // 32768\n",
        "  // (Optional) limit registers if ever needed:\n",
        "  // cudaFuncSetAttribute(gemm_dp4a_mod_tiler, cudaFuncAttributeMaxDynamicSharedMemorySize, smem_bytes);\n",
        "\n",
        "  auto t0 = clk::now(); int iters=0;\n",
        "  vector<vector<int32_t>> Cmods(P); for(int i=0;i<P;i++) Cmods[i].resize((size_t)M*N);\n",
        "\n",
        "  double wall_ms=0.0;\n",
        "  do{\n",
        "    for(int pi=0; pi<P; ++pi){\n",
        "      int p = primes[pi];\n",
        "      vector<int8_t> A8, B8;\n",
        "      pack_mod_int8(Ah, A8, M, K, p);\n",
        "      pack_mod_int8(Bh, B8, K, N, p);\n",
        "      CUDA_OK(cudaMemcpy(dA, A8.data(), (size_t)M*K, cudaMemcpyHostToDevice), \"H2D A\");\n",
        "      CUDA_OK(cudaMemcpy(dB, B8.data(), (size_t)K*N, cudaMemcpyHostToDevice), \"H2D B\");\n",
        "\n",
        "      gemm_dp4a_mod_tiler<<<grid, block, smem_bytes>>>(dA, dB, dC, M, N, K, p);\n",
        "      CUDA_OK(cudaPeekAtLastError(), \"kernel launch\");\n",
        "      CUDA_OK(cudaDeviceSynchronize(), \"kernel sync\");\n",
        "\n",
        "      CUDA_OK(cudaMemcpy(Cmods[pi].data(), dC, (size_t)M*N*sizeof(int32_t), cudaMemcpyDeviceToHost), \"D2H C\");\n",
        "    }\n",
        "    iters++;\n",
        "    wall_ms = chrono::duration<double, std::milli>(clk::now()-t0).count();\n",
        "  } while (wall_ms < a.ms_min);\n",
        "\n",
        "  const double secs = wall_ms/1000.0;\n",
        "  const double logical_macs = (double)M * (double)N * (double)K;\n",
        "  const double modular_macs = logical_macs * (double)P;\n",
        "  const double dp4a_inst_per_sec = (modular_macs * iters / secs) / 4.0;\n",
        "\n",
        "  uint64_t h=0;\n",
        "  if(a.verify){\n",
        "    h = crt_reconstruct_hash_strided(Cmods, M, N, a.recon_K, primes, a.cert_bound);\n",
        "  }\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [G009e_REPLACE3_DP4A_RNS_GEMM_TILER] M=%d N=%d K=%d  primes=%d  iters=%d  time=%.2f ms\\n\", M,N,K,P,iters,wall_ms);\n",
        "  printf(\"  Logical MACs/s:        %.3f G-mac/s   (per real GEMM)\\n\", (logical_macs*iters)/secs/1e9);\n",
        "  printf(\"  Modular MACs/s:        %.3f G-mac/s   (× primes)\\n\", (modular_macs*iters)/secs/1e9);\n",
        "  printf(\"  Effective dp4a instr/s %.3f G-inst/s  (~ MACs/4)\\n\", dp4a_inst_per_sec/1e9);\n",
        "  if(a.verify){\n",
        "    printf(\"  CRT (strided) hash (K=%d): 0x%016llx\\n\", a.recon_K, (unsigned long long)h);\n",
        "  }\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  cudaDeviceReset();\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# Build for T4\n",
        "nvcc -O3 -std=c++17 -arch=sm_75 -Xptxas -dlcm=ca -lineinfo g009e_dp4a_rns_gemm_tiler.cu -o g009e_dp4a_rns_gemm_tiler\n",
        "\n",
        "echo \"=== G009e_REPLACE3: quick sanity (512^3, 5 primes) ===\"\n",
        "./g009e_dp4a_rns_gemm_tiler --M 512 --N 512 --K 512 --primes 5 --ms 300 --reconK 4096 --cert 1000000\n",
        "\n",
        "echo\n",
        "echo \"=== G009e_REPLACE3: big (1024x2048x1024, 9 primes) ===\"\n",
        "./g009e_dp4a_rns_gemm_tiler --M 1024 --N 1024 --K 2048 --primes 9 --ms 500 --reconK 8192 --cert 1600000000\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAP6WtFObwXu",
        "outputId": "e845ca16-b47e-4fda-aa2c-04b97f5f8cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== G009e_REPLACE3: quick sanity (512^3, 5 primes) ===\n",
            "CRT certificate: Mprod=17239698439  vs  2*bound=2000000  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G009e_REPLACE3_DP4A_RNS_GEMM_TILER] M=512 N=512 K=512  primes=5  iters=6  time=313.48 ms\n",
            "  Logical MACs/s:        2.569 G-mac/s   (per real GEMM)\n",
            "  Modular MACs/s:        12.845 G-mac/s   (× primes)\n",
            "  Effective dp4a instr/s 3.211 G-inst/s  (~ MACs/4)\n",
            "  CRT (strided) hash (K=4096): 0xf5a19c58932025e5\n",
            "============================================================================\n",
            "\n",
            "=== G009e_REPLACE3: big (1024x2048x1024, 9 primes) ===\n",
            "CRT certificate: Mprod=1247644544258044721  vs  2*bound=3200000000  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G009e_REPLACE3_DP4A_RNS_GEMM_TILER] M=1024 N=1024 K=2048  primes=9  iters=1  time=757.86 ms\n",
            "  Logical MACs/s:        2.834 G-mac/s   (per real GEMM)\n",
            "  Modular MACs/s:        25.503 G-mac/s   (× primes)\n",
            "  Effective dp4a instr/s 6.376 G-inst/s  (~ MACs/4)\n",
            "  CRT (strided) hash (K=8192): 0xf77b7ceff20a50f4\n",
            "============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# =====================================================================\n",
        "# ████████████  MODULE G009f_fix_v5 :: DP4A RNS GEMM (aligned)  ██████\n",
        "#   - Exact RNS int8 (__dp4a), 128x128x64 tiling, 32x16=512 thr\n",
        "#   - FASTPATH (no bounds) uses true int4 cooperative copies\n",
        "#   - SAFE path guards edges; no int4 from stack\n",
        "#   - PAD_A=16, PAD_B=16 → 16B-aligned shared row strides (80 & 144)\n",
        "#   - splitK supported; strided CRT certificate; ops accounting\n",
        "# =====================================================================\n",
        "\n",
        "cat > g009f_fix_v5_dp4a_rns_gemm_fast.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "using namespace std; using clk = chrono::high_resolution_clock;\n",
        "\n",
        "struct Args {\n",
        "  int M=1024,N=1024,K=2048,primes=9,ms_min=500,verify=1,recon_K=8192,splitK=1;\n",
        "  long long cert_bound=200000000; unsigned seed=12345u;\n",
        "};\n",
        "static void parse(int argc,char**argv,Args&a){\n",
        "  for(int i=1;i<argc;i++){ string s=argv[i]; auto need=[&]{ if(i+1>=argc){fprintf(stderr,\"Missing %s\\n\",s.c_str()); exit(1);} };\n",
        "    if(s==\"--M\"){need();a.M=atoi(argv[++i]);}\n",
        "    else if(s==\"--N\"){need();a.N=atoi(argv[++i]);}\n",
        "    else if(s==\"--K\"){need();a.K=atoi(argv[++i]);}\n",
        "    else if(s==\"--primes\"){need();a.primes=atoi(argv[++i]);}\n",
        "    else if(s==\"--ms\"){need();a.ms_min=atoi(argv[++i]);}\n",
        "    else if(s==\"--verify\"){a.verify=1;}\n",
        "    else if(s==\"--noverify\"){a.verify=0;}\n",
        "    else if(s==\"--reconK\"){need();a.recon_K=atoi(argv[++i]);}\n",
        "    else if(s==\"--cert\"){need();a.cert_bound=atoll(argv[++i]);}\n",
        "    else if(s==\"--seed\"){need();a.seed=(unsigned)strtoul(argv[++i],nullptr,10);}\n",
        "    else if(s==\"--splitK\"){need();a.splitK=atoi(argv[++i]);}\n",
        "  }\n",
        "}\n",
        "static const int PRIMETBL[16]={127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53};\n",
        "\n",
        "static inline void CUDA_OK(cudaError_t e,const char*w){ if(e!=cudaSuccess){fprintf(stderr,\"CUDA ERROR @%s: %s\\n\",w,cudaGetErrorString(e)); exit(1);} }\n",
        "static inline uint64_t fnv1a64_append(uint64_t h,const void*p,size_t n){ const uint8_t*b=(const uint8_t*)p; const uint64_t P=1099511628211ull; for(size_t i=0;i<n;i++){h^=b[i]; h*=P;} return h; }\n",
        "static uint64_t invmod_u64(uint64_t a,uint64_t mod){ int64_t t=0,n=1,r=(int64_t)mod,m=(int64_t)a; while(m){ int64_t q=r/m; int64_t tt=n; n=t-q*n; t=tt; int64_t rr=m; m=r-q*m; r=rr;} if(r>1) return 0; if(t<0) t+=mod; return (uint64_t)t;}\n",
        "static void fill_rand_int32(vector<int32_t>&A,int R,int C,unsigned seed,int maxAbs=700){ mt19937 rng(seed); uniform_int_distribution<int>d(-maxAbs,maxAbs); A.resize((size_t)R*C); for(auto&x:A)x=d(rng);}\n",
        "static void pack_mod_int8(const vector<int32_t>&X, vector<int8_t>&Y, int, int, int p){ Y.resize(X.size()); for(size_t i=0;i<X.size();++i){ long long v=X[i]%p; if(v<0)v+=p; if(v>p/2)v-=p; Y[i]=(int8_t)v; } }\n",
        "\n",
        "__device__ __forceinline__ int pack_char4_i32_strict(char4 v){ union{int i; signed char b[4];}u; u.b[0]=v.x; u.b[1]=v.y; u.b[2]=v.z; u.b[3]=v.w; return u.i; }\n",
        "__device__ __forceinline__ int dp4a_i32_safe(int ai,int bi,int acc){\n",
        "#if __CUDA_ARCH__ >= 610\n",
        "  return __dp4a(ai,bi,acc);\n",
        "#else\n",
        "  union{int i; signed char b[4];}A{ai},B{bi};\n",
        "  acc += (int)A.b[0]*(int)B.b[0]; acc += (int)A.b[1]*(int)B.b[1];\n",
        "  acc += (int)A.b[2]*(int)B.b[2]; acc += (int)A.b[3]*(int)B.b[3]; return acc;\n",
        "#endif\n",
        "}\n",
        "\n",
        "constexpr int TM=128, TN=128, TK=64;\n",
        "constexpr int BLK_X=32, BLK_Y=16;          // 512 thr\n",
        "constexpr int RM=8,  CN=4;                 // 16*8 × 32*4 → 128×128\n",
        "constexpr int PAD_A=16, PAD_B=16;          // 16B-aligned rows\n",
        "\n",
        "__device__ __forceinline__ void vec_copy_16B(const void* __restrict__ g, void* __restrict__ s){\n",
        "  *reinterpret_cast<int4*>(s) = *reinterpret_cast<const int4*>(g);\n",
        "}\n",
        "\n",
        "extern \"C\" __global__\n",
        "void gemm_dp4a_tiler_fast(const int8_t* __restrict__ A, const int8_t* __restrict__ B, int32_t* __restrict__ C,\n",
        "                          int M,int N,int K,int p,int splitK)\n",
        "{\n",
        "  extern __shared__ __align__(16) int8_t smem[];\n",
        "  int8_t* As0=smem;\n",
        "  int8_t* Bs0=As0 + TM*(TK+PAD_A);\n",
        "  int8_t* As1=Bs0 + TK*(TN+PAD_B);\n",
        "  int8_t* Bs1=As1 + TM*(TK+PAD_A);\n",
        "\n",
        "  const int tx=threadIdx.x, ty=threadIdx.y;\n",
        "  const int slice=blockIdx.z;\n",
        "  const int Kslice=(K+splitK-1)/splitK;\n",
        "  const int k_begin=slice*Kslice, k_end=min(K,k_begin+Kslice);\n",
        "\n",
        "  const int rowBlock=blockIdx.y*TM, colBlock=blockIdx.x*TN;\n",
        "  const int rowBase=rowBlock+ty*RM, colBase=colBlock+tx*CN;\n",
        "\n",
        "  int acc[RM][CN];\n",
        "  #pragma unroll\n",
        "  for(int i=0;i<RM;i++){\n",
        "    #pragma unroll\n",
        "    for(int j=0;j<CN;j++) acc[i][j]=0;\n",
        "  }\n",
        "\n",
        "  auto loadA=[&](int8_t* As,int kk){\n",
        "    int chunk = ty*BLK_X + tx;                 // 0..511\n",
        "    for(; chunk < (TM*TK)/16; chunk += BLK_X*BLK_Y){\n",
        "      int off = chunk*16;\n",
        "      int a_r = off / TK;                      // 0..127\n",
        "      int a_k = off % TK;                      // 0,16,32,48\n",
        "      const void* gp = A + (size_t)(rowBlock + a_r)*K + (kk + a_k);\n",
        "      void*       sp = As + a_r*(TK+PAD_A) + a_k;    // row stride 80\n",
        "      vec_copy_16B(gp, sp);\n",
        "    }\n",
        "  };\n",
        "  auto loadB=[&](int8_t* Bs,int kk){\n",
        "    int chunk = ty*BLK_X + tx;\n",
        "    for(; chunk < (TK*TN)/16; chunk += BLK_X*BLK_Y){\n",
        "      int off = chunk*16;\n",
        "      int b_k = off / TN;                      // 0..63\n",
        "      int b_c = off % TN;                      // 0..112 step 16\n",
        "      const void* gp = B + (size_t)(kk + b_k)*N + (colBlock + b_c);\n",
        "      void*       sp = Bs + b_k*(TN+PAD_B) + b_c;    // row stride 144\n",
        "      vec_copy_16B(gp, sp);\n",
        "    }\n",
        "  };\n",
        "\n",
        "  int kk=k_begin;\n",
        "  loadA(As0,kk); loadB(Bs0,kk);\n",
        "  __syncthreads();\n",
        "\n",
        "  for(; kk<k_end; kk+=TK){\n",
        "    int nextk=kk+TK;\n",
        "    if(nextk<k_end){\n",
        "      if(((kk/TK)&1)==0){ loadA(As1,nextk); loadB(Bs1,nextk); }\n",
        "      else               { loadA(As0,nextk); loadB(Bs0,nextk); }\n",
        "    }\n",
        "    int8_t* As = ((kk/TK)&1)? As1:As0;\n",
        "    int8_t* Bs = ((kk/TK)&1)? Bs1:Bs0;\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    #pragma unroll\n",
        "    for(int k4=0;k4<TK;k4+=4){\n",
        "      char4 a4[RM], b4[CN];\n",
        "      #pragma unroll\n",
        "      for(int i=0;i<RM;i++){\n",
        "        int ar=ty*RM+i; int aoff=ar*(TK+PAD_A)+k4;\n",
        "        a4[i]=make_char4(As[aoff+0],As[aoff+1],As[aoff+2],As[aoff+3]);\n",
        "      }\n",
        "      #pragma unroll\n",
        "      for(int j=0;j<CN;j++){\n",
        "        int c=tx*CN+j;\n",
        "        int b0=(k4+0)*(TN+PAD_B)+c, b1=(k4+1)*(TN+PAD_B)+c, b2=(k4+2)*(TN+PAD_B)+c, b3=(k4+3)*(TN+PAD_B)+c;\n",
        "        b4[j]=make_char4(Bs[b0],Bs[b1],Bs[b2],Bs[b3]);\n",
        "      }\n",
        "      int ai[RM], bi[CN];\n",
        "      #pragma unroll\n",
        "      for(int i=0;i<RM;i++) ai[i]=pack_char4_i32_strict(a4[i]);\n",
        "      #pragma unroll\n",
        "      for(int j=0;j<CN;j++) bi[j]=pack_char4_i32_strict(b4[j]);\n",
        "      #pragma unroll\n",
        "      for(int i=0;i<RM;i++){\n",
        "        #pragma unroll\n",
        "        for(int j=0;j<CN;j++){\n",
        "          acc[i][j]=dp4a_i32_safe(ai[i],bi[j],acc[i][j]);\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "\n",
        "  #pragma unroll\n",
        "  for(int i=0;i<RM;i++){\n",
        "    int r=rowBase+i;\n",
        "    #pragma unroll\n",
        "    for(int j=0;j<CN;j++){\n",
        "      int c=colBase+j; int v=acc[i][j]%p; if(v<0)v+=p;\n",
        "      C[(size_t)(r*N+c) + (size_t)slice*(size_t)M*(size_t)N] = v;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "extern \"C\" __global__\n",
        "void gemm_dp4a_tiler_safe(const int8_t* __restrict__ A,const int8_t* __restrict__ B,int32_t* __restrict__ C,\n",
        "                          int M,int N,int K,int p,int splitK)\n",
        "{\n",
        "  extern __shared__ __align__(16) int8_t smem[];\n",
        "  int8_t* As0=smem;\n",
        "  int8_t* Bs0=As0 + TM*(TK+PAD_A);\n",
        "  int8_t* As1=Bs0 + TK*(TN+PAD_B);\n",
        "  int8_t* Bs1=As1 + TM*(TK+PAD_A);\n",
        "\n",
        "  const int tx=threadIdx.x, ty=threadIdx.y;\n",
        "  const int slice=blockIdx.z;\n",
        "  const int Kslice=(K+splitK-1)/splitK;\n",
        "  const int k_begin=slice*Kslice, k_end=min(K,k_begin+Kslice);\n",
        "\n",
        "  const int rowBlock=blockIdx.y*TM, colBlock=blockIdx.x*TN;\n",
        "  const int rowBase=rowBlock+ty*RM, colBase=colBlock+tx*CN;\n",
        "\n",
        "  int acc[RM][CN];\n",
        "  #pragma unroll\n",
        "  for(int i=0;i<RM;i++){\n",
        "    #pragma unroll\n",
        "    for(int j=0;j<CN;j++) acc[i][j]=0;\n",
        "  }\n",
        "\n",
        "  auto loadA=[&](int8_t* As,int kk){\n",
        "    int chunk=ty*BLK_X+tx;\n",
        "    for(; chunk<(TM*TK)/16; chunk+=BLK_X*BLK_Y){\n",
        "      int off=chunk*16, a_r=off/TK, a_k=off%TK, g_r=rowBlock+a_r, g_k=kk+a_k;\n",
        "      // scalar 16B copy (safe for stack-backed)\n",
        "      int8_t* sp = As + a_r*(TK+PAD_A)+a_k;\n",
        "      #pragma unroll\n",
        "      for(int t=0;t<16;t++){\n",
        "        int gk=g_k+t;\n",
        "        sp[t] = (g_r<M && gk>=k_begin && gk<k_end) ? A[(size_t)g_r*K+gk] : 0;\n",
        "      }\n",
        "    }\n",
        "  };\n",
        "  auto loadB=[&](int8_t* Bs,int kk){\n",
        "    int chunk=ty*BLK_X+tx;\n",
        "    for(; chunk<(TK*TN)/16; chunk+=BLK_X*BLK_Y){\n",
        "      int off=chunk*16, b_k=off/TN, b_c=off%TN, g_k=kk+b_k, g_c=colBlock+b_c;\n",
        "      int8_t* sp = Bs + b_k*(TN+PAD_B)+b_c;\n",
        "      #pragma unroll\n",
        "      for(int t=0;t<16;t++){\n",
        "        int gc=g_c+t;\n",
        "        sp[t] = (g_k>=k_begin && g_k<k_end && gc<N) ? B[(size_t)g_k*N+gc] : 0;\n",
        "      }\n",
        "    }\n",
        "  };\n",
        "\n",
        "  int kk=k_begin; loadA(As0,kk); loadB(Bs0,kk); __syncthreads();\n",
        "\n",
        "  for(; kk<k_end; kk+=TK){\n",
        "    int nextk=kk+TK;\n",
        "    if(nextk<k_end){\n",
        "      if(((kk/TK)&1)==0){ loadA(As1,nextk); loadB(Bs1,nextk); }\n",
        "      else               { loadA(As0,nextk); loadB(Bs0,nextk); }\n",
        "    }\n",
        "    int8_t* As=((kk/TK)&1)? As1:As0; int8_t* Bs=((kk/TK)&1)? Bs1:Bs0;\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    #pragma unroll\n",
        "    for(int k4=0;k4<TK;k4+=4){\n",
        "      char4 a4[RM], b4[CN];\n",
        "      #pragma unroll\n",
        "      for(int i=0;i<RM;i++){ int ar=ty*RM+i; int aoff=ar*(TK+PAD_A)+k4; a4[i]=make_char4(As[aoff+0],As[aoff+1],As[aoff+2],As[aoff+3]); }\n",
        "      #pragma unroll\n",
        "      for(int j=0;j<CN;j++){ int c=tx*CN+j; int b0=(k4+0)*(TN+PAD_B)+c, b1=(k4+1)*(TN+PAD_B)+c, b2=(k4+2)*(TN+PAD_B)+c, b3=(k4+3)*(TN+PAD_B)+c;\n",
        "                             b4[j]=make_char4(Bs[b0],Bs[b1],Bs[b2],Bs[b3]); }\n",
        "      int ai[RM], bi[CN];\n",
        "      #pragma unroll\n",
        "      for(int i=0;i<RM;i++) ai[i]=pack_char4_i32_strict(a4[i]);\n",
        "      #pragma unroll\n",
        "      for(int j=0;j<CN;j++) bi[j]=pack_char4_i32_strict(b4[j]);\n",
        "      #pragma unroll\n",
        "      for(int i=0;i<RM;i++){\n",
        "        #pragma unroll\n",
        "        for(int j=0;j<CN;j++){\n",
        "          acc[i][j]=dp4a_i32_safe(ai[i],bi[j],acc[i][j]);\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "\n",
        "  #pragma unroll\n",
        "  for(int i=0;i<RM;i++){ int r=rowBase+i; if(r>=M) break;\n",
        "    #pragma unroll\n",
        "    for(int j=0;j<CN;j++){ int c=colBase+j; if(c>=N) break; int v=acc[i][j]%p; if(v<0)v+=p; C[(size_t)(r*N+c)+(size_t)slice*(size_t)M*(size_t)N]=v; }\n",
        "  }\n",
        "}\n",
        "\n",
        "static uint64_t crt_hash(const vector<vector<int32_t>>&Cmods,int M,int N,int reconK,const vector<int>&primes,long long cert){\n",
        "  int P=(int)primes.size(); uint64_t Mprod=1; for(int i=0;i<P;i++) Mprod*=(uint64_t)primes[i];\n",
        "  if(cert>0) printf(\"CRT certificate: Mprod=%llu  vs  2*bound=%llu  %s\\n\",(unsigned long long)Mprod,(unsigned long long)(2ull*(uint64_t)cert),(Mprod>2ull*(uint64_t)cert?\"(UNIQUE RECON OK)\":\"(INSUFFICIENT)\"));\n",
        "  vector<uint64_t> Mi(P), yi(P); uint64_t Mtot=1; for(int i=0;i<P;i++) Mtot*=(uint64_t)primes[i];\n",
        "  for(int i=0;i<P;i++){ Mi[i]=Mtot/(uint64_t)primes[i]; yi[i]=invmod_u64(Mi[i]%primes[i],primes[i]); }\n",
        "  int total=M*N; int K=min(reconK,total); int stride = 1315423911u % max(1,total); int idx=0; uint64_t h=0;\n",
        "  for(int t=0;t<K;++t){ uint64_t x=0; for(int i=0;i<P;i++){ uint64_t ai=((uint64_t)Cmods[i][idx]%primes[i]+primes[i])%primes[i]; x=(x + ai*Mi[i]%Mtot*yi[i]%Mtot)%Mtot; } h=fnv1a64_append(h,&x,sizeof(x)); idx+=stride; if(idx>=total) idx-=total; }\n",
        "  return h;\n",
        "}\n",
        "\n",
        "int main(int argc,char**argv){\n",
        "  ios::sync_with_stdio(false); cin.tie(nullptr);\n",
        "  Args a; parse(argc,argv,a);\n",
        "  const int M=a.M,N=a.N,K=a.K,splitK=max(1,a.splitK);\n",
        "  int P=max(1,min(a.primes,(int)(sizeof(PRIMETBL)/sizeof(PRIMETBL[0])))); vector<int> primes(P); for(int i=0;i<P;i++) primes[i]=PRIMETBL[i];\n",
        "\n",
        "  vector<int32_t> Ah((size_t)M*K), Bh((size_t)K*N); fill_rand_int32(Ah,M,K,a.seed+1); fill_rand_int32(Bh,K,N,a.seed+2);\n",
        "  int8_t *dA=nullptr,*dB=nullptr; int32_t *dC=nullptr;\n",
        "  CUDA_OK(cudaMalloc(&dA,(size_t)M*K),\"malloc dA\"); CUDA_OK(cudaMalloc(&dB,(size_t)K*N),\"malloc dB\");\n",
        "  CUDA_OK(cudaMalloc(&dC,(size_t)M*N*splitK*sizeof(int32_t)),\"malloc dC\");\n",
        "\n",
        "  dim3 block(BLK_X,BLK_Y), grid((N+TN-1)/TN,(M+TM-1)/TM,splitK);\n",
        "  // SMEM usage: 2*( TM*(TK+PAD_A) + TK*(TN+PAD_B) ) bytes = 2*(128*80 + 64*144) = 2*(10240+9216)=38912 B\n",
        "  size_t smem_bytes = (size_t)( TM*(TK+PAD_A)*2 + TK*(TN+PAD_B)*2 );\n",
        "\n",
        "  auto t0=clk::now(); int iters=0; vector<vector<int32_t>> Cmods(P); for(int i=0;i<P;i++) Cmods[i].assign((size_t)M*N,0);\n",
        "  const bool fast_ok=(M%TM)==0 && (N%TN)==0 && (K%TK)==0;\n",
        "  double wall_ms=0.0;\n",
        "\n",
        "  do{\n",
        "    for(int pi=0;pi<P;++pi){\n",
        "      int p=primes[pi]; vector<int8_t>A8,B8; pack_mod_int8(Ah,A8,M,K,p); pack_mod_int8(Bh,B8,K,N,p);\n",
        "      CUDA_OK(cudaMemcpy(dA,A8.data(),(size_t)M*K,cudaMemcpyHostToDevice),\"H2D A\");\n",
        "      CUDA_OK(cudaMemcpy(dB,B8.data(),(size_t)K*N,cudaMemcpyHostToDevice),\"H2D B\");\n",
        "      CUDA_OK(cudaMemset(dC,0,(size_t)M*N*splitK*sizeof(int32_t)),\"memset C\");\n",
        "\n",
        "      if(fast_ok) gemm_dp4a_tiler_fast<<<grid,block,smem_bytes>>>(dA,dB,dC,M,N,K,p,splitK);\n",
        "      else        gemm_dp4a_tiler_safe<<<grid,block,smem_bytes>>>(dA,dB,dC,M,N,K,p,splitK);\n",
        "\n",
        "      CUDA_OK(cudaPeekAtLastError(),\"kernel launch\");\n",
        "      CUDA_OK(cudaDeviceSynchronize(),\"kernel sync\");\n",
        "\n",
        "      vector<int32_t> tmp((size_t)M*N*splitK);\n",
        "      CUDA_OK(cudaMemcpy(tmp.data(),dC,tmp.size()*sizeof(int32_t),cudaMemcpyDeviceToHost),\"D2H C\");\n",
        "      for(size_t idx=0; idx<(size_t)M*N; ++idx){\n",
        "        long long v=0; for(int s=0;s<splitK;s++) v += tmp[idx + (size_t)s*(size_t)M*(size_t)N];\n",
        "        int r=(int)(v%p); if(r<0) r+=p; Cmods[pi][idx]=r;\n",
        "      }\n",
        "    }\n",
        "    iters++; wall_ms = chrono::duration<double, milli>(clk::now()-t0).count();\n",
        "  } while (wall_ms < a.ms_min);\n",
        "\n",
        "  double secs=wall_ms/1000.0; double logical_macs=(double)M*N*K; double modular_macs=logical_macs*P; double dp4a_inst=(modular_macs*iters/secs)/4.0;\n",
        "  uint64_t h=0; if(a.verify){ h=crt_hash(Cmods,M,N,a.recon_K,primes,a.cert_bound); }\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [G009f_fix_v5_DP4A_RNS_GEMM_FAST] M=%d N=%d K=%d primes=%d splitK=%d iters=%d time=%.2f ms (fast=%s)\\n\",\n",
        "         M,N,K,P,splitK,iters,wall_ms, fast_ok?\"yes\":\"no\");\n",
        "  printf(\"  Logical MACs/s:        %.3f G-mac/s   (per real GEMM)\\n\",(logical_macs*iters)/secs/1e9);\n",
        "  printf(\"  Modular MACs/s:        %.3f G-mac/s   (× primes)\\n\",(modular_macs*iters)/secs/1e9);\n",
        "  printf(\"  Effective dp4a instr/s %.3f G-inst/s  (~ MACs/4)\\n\",dp4a_inst/1e9);\n",
        "  if(a.verify) printf(\"  CRT (strided) hash (K=%d): 0x%016llx\\n\",a.recon_K,(unsigned long long)h);\n",
        "  printf(\"============================================================================\\n\");\n",
        "  cudaDeviceReset(); return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# Build\n",
        "nvcc -O3 -std=c++17 -arch=sm_75 -Xptxas -dlcm=ca -lineinfo g009f_fix_v5_dp4a_rns_gemm_fast.cu -o g009f_fix_v5_dp4a_rns_gemm_fast\n",
        "\n",
        "echo \"=== G009f_fix_v5: quick sanity (512^3, 5 primes, splitK=1) ===\"\n",
        "./g009f_fix_v5_dp4a_rns_gemm_fast --M 512 --N 512 --K 512 --primes 5 --ms 300 --reconK 4096 --cert 1000000 --splitK 1\n",
        "\n",
        "echo\n",
        "echo \"=== G009f_fix_v5: big (1024x2048x1024, 9 primes, splitK=2) ===\"\n",
        "./g009f_fix_v5_dp4a_rns_gemm_fast --M 1024 --N 1024 --K 2048 --primes 9 --ms 500 --reconK 8192 --cert 3200000000 --splitK 2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kb91k2yvrRU",
        "outputId": "e45b29c9-478a-4487-9612-2c1bd02c998a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== G009f_fix_v5: quick sanity (512^3, 5 primes, splitK=1) ===\n",
            "CRT certificate: Mprod=17239698439  vs  2*bound=2000000  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G009f_fix_v5_DP4A_RNS_GEMM_FAST] M=512 N=512 K=512 primes=5 splitK=1 iters=7 time=319.06 ms (fast=yes)\n",
            "  Logical MACs/s:        2.945 G-mac/s   (per real GEMM)\n",
            "  Modular MACs/s:        14.723 G-mac/s   (× primes)\n",
            "  Effective dp4a instr/s 3.681 G-inst/s  (~ MACs/4)\n",
            "  CRT (strided) hash (K=4096): 0x5123bcd46b575343\n",
            "============================================================================\n",
            "\n",
            "=== G009f_fix_v5: big (1024x2048x1024, 9 primes, splitK=2) ===\n",
            "CRT certificate: Mprod=1247644544258044721  vs  2*bound=6400000000  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G009f_fix_v5_DP4A_RNS_GEMM_FAST] M=1024 N=1024 K=2048 primes=9 splitK=2 iters=1 time=586.83 ms (fast=yes)\n",
            "  Logical MACs/s:        3.659 G-mac/s   (per real GEMM)\n",
            "  Modular MACs/s:        32.935 G-mac/s   (× primes)\n",
            "  Effective dp4a instr/s 8.234 G-inst/s  (~ MACs/4)\n",
            "  CRT (strided) hash (K=8192): 0x28891db410407126\n",
            "============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# =============================================================================\n",
        "# ████████████████  MODULE G009h :: WARPIPE AUTOTUNE + ROOFLINE  ████████████\n",
        "#   - Re-implements G009g_fix kernel (CN=4) so it's self-contained\n",
        "#   - Adds: full parameter sweep, best-config selection, roofline-ish counters:\n",
        "#       * Bytes moved (H2D/D2H/GMEM loads) per prime\n",
        "#       * Effective arithmetic intensity (modular MACs per global byte)\n",
        "#       * dp4a instruction rate estimate\n",
        "#   - Exact RNS math with CRT strided certificate & hash\n",
        "# =============================================================================\n",
        "\n",
        "cat > g009h_warppipe_autotune.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "using namespace std; using clk = chrono::high_resolution_clock;\n",
        "\n",
        "struct Args {\n",
        "  int M=1024,N=1024,K=2048,primes=9;\n",
        "  int ms_min=400, recon_K=8192, verify=1;\n",
        "  long long cert_bound=0;              // set >0 to print unique recon bound\n",
        "  unsigned seed=12345u;\n",
        "};\n",
        "static void parse(int argc,char**argv,Args&a){\n",
        "  for(int i=1;i<argc;i++){ string s=argv[i]; auto need=[&]{ if(i+1>=argc){fprintf(stderr,\"Missing %s\\n\",s.c_str()); exit(1);} };\n",
        "    if(s==\"--M\"){need();a.M=atoi(argv[++i]);} else if(s==\"--N\"){need();a.N=atoi(argv[++i]);}\n",
        "    else if(s==\"--K\"){need();a.K=atoi(argv[++i]);} else if(s==\"--primes\"){need();a.primes=atoi(argv[++i]);}\n",
        "    else if(s==\"--ms\"){need();a.ms_min=atoi(argv[++i]);} else if(s==\"--reconK\"){need();a.recon_K=atoi(argv[++i]);}\n",
        "    else if(s==\"--seed\"){need();a.seed=(unsigned)strtoul(argv[++i],nullptr,10);} else if(s==\"--cert\"){need();a.cert_bound=atoll(argv[++i]);}\n",
        "    else if(s==\"--noverify\"){a.verify=0;} else if(s==\"--verify\"){a.verify=1;}\n",
        "  }\n",
        "}\n",
        "static const int PRIMES_TBL[16]={127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53};\n",
        "\n",
        "static inline void CUDA_OK(cudaError_t e,const char*w){ if(e!=cudaSuccess){fprintf(stderr,\"CUDA ERROR @%s: %s\\n\",w,cudaGetErrorString(e)); exit(1);} }\n",
        "static inline uint64_t fnv1a64_append(uint64_t h,const void*p,size_t n){ const uint8_t*b=(const uint8_t*)p; const uint64_t P=1099511628211ull; for(size_t i=0;i<n;i++){h^=b[i]; h*=P;} return h; }\n",
        "static uint64_t invmod_u64(uint64_t a,uint64_t mod){ int64_t t=0,n=1,r=(int64_t)mod,m=(int64_t)a; while(m){ int64_t q=r/m; int64_t tt=n; n=t-q*n; t=tt; int64_t rr=m; m=r-q*m; r=rr;} if(r>1) return 0; if(t<0) t+=mod; return (uint64_t)t;}\n",
        "static void pack_mod_s8_from_i32(const vector<int32_t>&X, vector<int8_t>&Y, int p){\n",
        "  Y.resize(X.size());\n",
        "  for(size_t i=0;i<X.size();++i){ long long v=X[i]%p; if(v<0) v+=p; if(v>p/2) v-=p; Y[i]=(int8_t)v; }\n",
        "}\n",
        "\n",
        "// ====== dp4a helpers ======\n",
        "__device__ __forceinline__ int dp4a_i32(int a,int b,int c){\n",
        "#if __CUDA_ARCH__ >= 610\n",
        "  return __dp4a(a,b,c);\n",
        "#else\n",
        "  union{int i; signed char b[4];}A{a},B{b};\n",
        "  c += (int)A.b[0]*(int)B.b[0]; c += (int)A.b[1]*(int)B.b[1];\n",
        "  c += (int)A.b[2]*(int)B.b[2]; c += (int)A.b[3]*(int)B.b[3]; return c;\n",
        "#endif\n",
        "}\n",
        "__device__ __forceinline__ int pack_char4_i32(char4 v){\n",
        "  union{int i; signed char b[4];}u; u.b[0]=v.x; u.b[1]=v.y; u.b[2]=v.z; u.b[3]=v.w; return u.i;\n",
        "}\n",
        "__device__ __forceinline__ void vcopy16(const void* __restrict__ g, void* __restrict__ s){\n",
        "  *reinterpret_cast<int4*>(s) = *reinterpret_cast<const int4*>(g);\n",
        "}\n",
        "\n",
        "// ====== Kernel config (CN=4; TN=32*4=128, TM=16*8=128) ======\n",
        "template<int TM, int TN, int TK, int PAD_A=16, int PAD_B=16>\n",
        "struct Tiler {\n",
        "  static constexpr int BLK_X=32, BLK_Y=16, RM=8, CN=4;\n",
        "  static_assert(TM==BLK_Y*RM && TN==BLK_X*CN, \"tile/threads mismatch\");\n",
        "  static constexpr int SMEM_BYTES = ( TM*(TK+PAD_A)*2 + TK*(TN+PAD_B)*2 );\n",
        "};\n",
        "\n",
        "// ====== FAST kernel ======\n",
        "template<int TM,int TN,int TK>\n",
        "__global__ void gemm_dp4a_fast(const int8_t* __restrict__ A, const int8_t* __restrict__ B,\n",
        "                               int32_t* __restrict__ C, int M, int N, int K, int p, int splitK)\n",
        "{\n",
        "  extern __shared__ __align__(16) int8_t sm[];\n",
        "  constexpr int PAD_A=16, PAD_B=16;\n",
        "  int8_t* As0 = sm;\n",
        "  int8_t* Bs0 = As0 + TM*(TK+PAD_A);\n",
        "  int8_t* As1 = Bs0 + TK*(TN+PAD_B);\n",
        "  int8_t* Bs1 = As1 + TM*(TK+PAD_A);\n",
        "\n",
        "  const int tx=threadIdx.x, ty=threadIdx.y;\n",
        "  const int slice=blockIdx.z;\n",
        "  const int Kslice=(K+splitK-1)/splitK;\n",
        "  const int k0 = slice*Kslice, kend = min(K, k0+Kslice);\n",
        "\n",
        "  const int m0=blockIdx.y*TM, n0=blockIdx.x*TN;\n",
        "  const int rowBase = m0 + ty*Tiler<TM,TN,TK>::RM;\n",
        "  const int colBase = n0 + tx*Tiler<TM,TN,TK>::CN;\n",
        "\n",
        "  int acc[Tiler<TM,TN,TK>::RM][Tiler<TM,TN,TK>::CN];\n",
        "  #pragma unroll\n",
        "  for(int i=0;i<Tiler<TM,TN,TK>::RM;i++){\n",
        "    #pragma unroll\n",
        "    for(int j=0;j<Tiler<TM,TN,TK>::CN;j++) acc[i][j]=0;\n",
        "  }\n",
        "\n",
        "  auto loadA = [&](int8_t* As, int kk){\n",
        "    int chunk = ty*Tiler<TM,TN,TK>::BLK_X + tx;\n",
        "    for(; chunk < (TM*TK)/16; chunk += Tiler<TM,TN,TK>::BLK_X * Tiler<TM,TN,TK>::BLK_Y){\n",
        "      int off = chunk*16, ar = off / TK, ak = off % TK;\n",
        "      const void* gp = A + (size_t)(m0 + ar)*K + (kk + ak);\n",
        "      void*       sp = As + ar*(TK+PAD_A) + ak;\n",
        "      vcopy16(gp, sp);\n",
        "    }\n",
        "  };\n",
        "  auto loadB = [&](int8_t* Bs, int kk){\n",
        "    int chunk = ty*Tiler<TM,TN,TK>::BLK_X + tx;\n",
        "    for(; chunk < (TK*TN)/16; chunk += Tiler<TM,TN,TK>::BLK_X * Tiler<TM,TN,TK>::BLK_Y){\n",
        "      int off = chunk*16, bk = off / TN, bc = off % TN;\n",
        "      const void* gp = B + (size_t)(kk + bk)*N + (n0 + bc);\n",
        "      void*       sp = Bs + bk*(TN+PAD_B) + bc;\n",
        "      vcopy16(gp, sp);\n",
        "    }\n",
        "  };\n",
        "\n",
        "  int kk=k0; loadA(As0,kk); loadB(Bs0,kk); __syncthreads();\n",
        "\n",
        "  for(; kk<kend; kk+=TK){\n",
        "    int nextk=kk+TK;\n",
        "    if(nextk<kend){\n",
        "      if(((kk/TK)&1)==0){ loadA(As1,nextk); loadB(Bs1,nextk); }\n",
        "      else               { loadA(As0,nextk); loadB(Bs0,nextk); }\n",
        "    }\n",
        "    int8_t* As = ((kk/TK)&1)? As1:As0;\n",
        "    int8_t* Bs = ((kk/TK)&1)? Bs1:Bs0;\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    #pragma unroll\n",
        "    for(int k4=0;k4<TK;k4+=4){\n",
        "      char4 a4[Tiler<TM,TN,TK>::RM], b4[Tiler<TM,TN,TK>::CN];\n",
        "      #pragma unroll\n",
        "      for(int i=0;i<Tiler<TM,TN,TK>::RM;i++){\n",
        "        int ar = ty*Tiler<TM,TN,TK>::RM + i;\n",
        "        int aoff = ar*(TK+16) + k4;\n",
        "        a4[i] = make_char4(As[aoff+0],As[aoff+1],As[aoff+2],As[aoff+3]);\n",
        "      }\n",
        "      #pragma unroll\n",
        "      for(int j=0;j<Tiler<TM,TN,TK>::CN;j++){\n",
        "        int c = tx*Tiler<TM,TN,TK>::CN + j;\n",
        "        int b0 = (k4+0)*(TN+16) + c;\n",
        "        int b1 = (k4+1)*(TN+16) + c;\n",
        "        int b2 = (k4+2)*(TN+16) + c;\n",
        "        int b3 = (k4+3)*(TN+16) + c;\n",
        "        b4[j] = make_char4(Bs[b0],Bs[b1],Bs[b2],Bs[b3]);\n",
        "      }\n",
        "      int ai[Tiler<TM,TN,TK>::RM], bi[Tiler<TM,TN,TK>::CN];\n",
        "      #pragma unroll\n",
        "      for(int i=0;i<Tiler<TM,TN,TK>::RM;i++) ai[i]=pack_char4_i32(a4[i]);\n",
        "      #pragma unroll\n",
        "      for(int j=0;j<Tiler<TM,TN,TK>::CN;j++) bi[j]=pack_char4_i32(b4[j]);\n",
        "      #pragma unroll\n",
        "      for(int i=0;i<Tiler<TM,TN,TK>::RM;i++){\n",
        "        #pragma unroll\n",
        "        for(int j=0;j<Tiler<TM,TN,TK>::CN;j++){\n",
        "          acc[i][j] = dp4a_i32(ai[i], bi[j], acc[i][j]);\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "\n",
        "  #pragma unroll\n",
        "  for(int i=0;i<Tiler<TM,TN,TK>::RM;i++){\n",
        "    int r = m0 + ty*Tiler<TM,TN,TK>::RM + i;\n",
        "    #pragma unroll\n",
        "    for(int j=0;j<Tiler<TM,TN,TK>::CN;j++){\n",
        "      int c = n0 + tx*Tiler<TM,TN,TK>::CN + j;\n",
        "      int v = acc[i][j] % p; if(v<0) v += p;\n",
        "      C[(size_t)(r*N + c) + (size_t)blockIdx.z*(size_t)M*(size_t)N] = v;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "// ====== SAFE kernel (ragged edges) ======\n",
        "template<int TM,int TN,int TK>\n",
        "__global__ void gemm_dp4a_safe(const int8_t* __restrict__ A, const int8_t* __restrict__ B,\n",
        "                               int32_t* __restrict__ C, int M, int N, int K, int p, int splitK)\n",
        "{\n",
        "  extern __shared__ __align__(16) int8_t sm[];\n",
        "  constexpr int PAD_A=16, PAD_B=16;\n",
        "  int8_t* As0 = sm;\n",
        "  int8_t* Bs0 = As0 + TM*(TK+PAD_A);\n",
        "  int8_t* As1 = Bs0 + TK*(TN+PAD_B);\n",
        "  int8_t* Bs1 = As1 + TM*(TK+PAD_A);\n",
        "\n",
        "  const int tx=threadIdx.x, ty=threadIdx.y;\n",
        "  const int slice=blockIdx.z;\n",
        "  const int Kslice=(K+splitK-1)/splitK;\n",
        "  const int k0 = slice*Kslice, kend = min(K, k0+Kslice);\n",
        "\n",
        "  const int m0=blockIdx.y*TM, n0=blockIdx.x*TN;\n",
        "  const int rowBase = m0 + ty*Tiler<TM,TN,TK>::RM;\n",
        "  const int colBase = n0 + tx*Tiler<TM,TN,TK>::CN;\n",
        "\n",
        "  int acc[Tiler<TM,TN,TK>::RM][Tiler<TM,TN,TK>::CN];\n",
        "  #pragma unroll\n",
        "  for(int i=0;i<Tiler<TM,TN,TK>::RM;i++){\n",
        "    #pragma unroll\n",
        "    for(int j=0;j<Tiler<TM,TN,TK>::CN;j++) acc[i][j]=0;\n",
        "  }\n",
        "\n",
        "  auto loadA = [&](int8_t* As, int kk){\n",
        "    int chunk = ty*Tiler<TM,TN,TK>::BLK_X + tx;\n",
        "    for(; chunk < (TM*TK)/16; chunk += Tiler<TM,TN,TK>::BLK_X * Tiler<TM,TN,TK>::BLK_Y){\n",
        "      int off = chunk*16, ar = off / TK, ak = off % TK;\n",
        "      int gr = m0 + ar, gk = kk + ak;\n",
        "      int8_t* s = As + ar*(TK+PAD_A) + ak;\n",
        "      #pragma unroll\n",
        "      for(int t=0;t<16;t++){ int gkk=gk+t; s[t] = (gr<M && gkk>=k0 && gkk<kend) ? A[(size_t)gr*K + gkk] : 0; }\n",
        "    }\n",
        "  };\n",
        "  auto loadB = [&](int8_t* Bs, int kk){\n",
        "    int chunk = ty*Tiler<TM,TN,TK>::BLK_X + tx;\n",
        "    for(; chunk < (TK*TN)/16; chunk += Tiler<TM,TN,TK>::BLK_X * Tiler<TM,TN,TK>::BLK_Y){\n",
        "      int off = chunk*16, bk = off / TN, bc = off % TN;\n",
        "      int gk = kk + bk, gc = n0 + bc;\n",
        "      int8_t* s = Bs + bk*(TN+PAD_B) + bc;\n",
        "      #pragma unroll\n",
        "      for(int t=0;t<16;t++){ int gcc=gc+t; s[t] = (gk>=k0 && gk<kend && gcc<N) ? B[(size_t)gk*N + gcc] : 0; }\n",
        "    }\n",
        "  };\n",
        "\n",
        "  int kk=k0; loadA(As0,kk); loadB(Bs0,kk); __syncthreads();\n",
        "\n",
        "  for(; kk<kend; kk+=TK){\n",
        "    int nextk=kk+TK;\n",
        "    if(nextk<kend){\n",
        "      if(((kk/TK)&1)==0){ loadA(As1,nextk); loadB(Bs1,nextk); }\n",
        "      else               { loadA(As0,nextk); loadB(Bs0,nextk); }\n",
        "    }\n",
        "    int8_t* As = ((kk/TK)&1)? As1:As0;\n",
        "    int8_t* Bs = ((kk/TK)&1)? Bs1:Bs0;\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    #pragma unroll\n",
        "    for(int k4=0;k4<TK;k4+=4){\n",
        "      char4 a4[Tiler<TM,TN,TK>::RM], b4[Tiler<TM,TN,TK>::CN];\n",
        "      #pragma unroll\n",
        "      for(int i=0;i<Tiler<TM,TN,TK>::RM;i++){\n",
        "        int ar = ty*Tiler<TM,TN,TK>::RM + i;\n",
        "        int aoff = ar*(TK+16) + k4;\n",
        "        a4[i] = make_char4(As[aoff+0],As[aoff+1],As[aoff+2],As[aoff+3]);\n",
        "      }\n",
        "      #pragma unroll\n",
        "      for(int j=0;j<Tiler<TM,TN,TK>::CN;j++){\n",
        "        int c = tx*Tiler<TM,TN,TK>::CN + j;\n",
        "        int b0 = (k4+0)*(TN+16) + c;\n",
        "        int b1 = (k4+1)*(TN+16) + c;\n",
        "        int b2 = (k4+2)*(TN+16) + c;\n",
        "        int b3 = (k4+3)*(TN+16) + c;\n",
        "        b4[j] = make_char4(Bs[b0],Bs[b1],Bs[b2],Bs[b3]);\n",
        "      }\n",
        "      int ai[Tiler<TM,TN,TK>::RM], bi[Tiler<TM,TN,TK>::CN];\n",
        "      #pragma unroll\n",
        "      for(int i=0;i<Tiler<TM,TN,TK>::RM;i++) ai[i]=pack_char4_i32(a4[i]);\n",
        "      #pragma unroll\n",
        "      for(int j=0;j<Tiler<TM,TN,TK>::CN;j++) bi[j]=pack_char4_i32(b4[j]);\n",
        "      #pragma unroll\n",
        "      for(int i=0;i<Tiler<TM,TN,TK>::RM;i++){\n",
        "        #pragma unroll\n",
        "        for(int j=0;j<Tiler<TM,TN,TK>::CN;j++){\n",
        "          acc[i][j] = dp4a_i32(ai[i], bi[j], acc[i][j]);\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "\n",
        "  #pragma unroll\n",
        "  for(int i=0;i<Tiler<TM,TN,TK>::RM;i++){\n",
        "    int r = rowBase + i; if(r>=M) break;\n",
        "    #pragma unroll\n",
        "    for(int j=0;j<Tiler<TM,TN,TK>::CN;j++){\n",
        "      int c = colBase + j; if(c>=N) break;\n",
        "      int v = acc[i][j] % p; if(v<0) v += p;\n",
        "      C[(size_t)(r*N + c) + (size_t)blockIdx.z*(size_t)M*(size_t)N] = v;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "// ====== CRT (strided) ======\n",
        "static uint64_t crt_hash(const vector<vector<int32_t>>& Cmods, int M, int N, int reconK, const vector<int>& primes, long long cert){\n",
        "  int P=(int)primes.size(); uint64_t Mprod=1; for(int i=0;i<P;i++) Mprod*=(uint64_t)primes[i];\n",
        "  if(cert>0) printf(\"CRT certificate: Mprod=%llu  vs  2*bound=%llu  %s\\n\",\n",
        "                    (unsigned long long)Mprod, (unsigned long long)(2ull*(uint64_t)cert),\n",
        "                    (Mprod>2ull*(uint64_t)cert? \"(UNIQUE RECON OK)\":\"(INSUFFICIENT)\"));\n",
        "  vector<uint64_t> Mi(P), yi(P); uint64_t Mtot=1; for(int i=0;i<P;i++) Mtot*=(uint64_t)primes[i];\n",
        "  for(int i=0;i<P;i++){ Mi[i]=Mtot/(uint64_t)primes[i]; yi[i]=invmod_u64(Mi[i]%primes[i],primes[i]); }\n",
        "  const int total=M*N; const int K=min(reconK,total); int stride = 1315423911u % max(1,total); int idx=0; uint64_t h=0;\n",
        "  for(int t=0;t<K;++t){ uint64_t x=0; for(int i=0;i<P;i++){ uint64_t ai=((uint64_t)Cmods[i][idx]%primes[i]+primes[i])%primes[i];\n",
        "    x=(x + ai*Mi[i]%Mtot*yi[i]%Mtot)%Mtot; } h=fnv1a64_append(h,&x,sizeof(x)); idx+=stride; if(idx>=total) idx-=total; }\n",
        "  return h;\n",
        "}\n",
        "\n",
        "// ====== One run (returns metrics) ======\n",
        "struct Metrics {\n",
        "  double gmac_logical=0, gmac_modular=0, ginst_dp4a=0;\n",
        "  double wall_ms=0; uint64_t hash=0; int tk=0, thr=0, splitK=0;\n",
        "};\n",
        "template<int TM,int TN,int TK>\n",
        "static Metrics run_case(const vector<int32_t>& Ah, const vector<int32_t>& Bh, int M,int N,int K,const vector<int>&primes, int splitK, int thrblk, int ms_min){\n",
        "  size_t Asz=(size_t)M*K, Bsz=(size_t)K*N, Csz=(size_t)M*N*splitK;\n",
        "  int8_t *dA=nullptr,*dB=nullptr; int32_t *dC=nullptr;\n",
        "  CUDA_OK(cudaMalloc(&dA,Asz),\"malloc dA\"); CUDA_OK(cudaMalloc(&dB,Bsz),\"malloc dB\"); CUDA_OK(cudaMalloc(&dC,Csz*sizeof(int32_t)),\"malloc dC\");\n",
        "  dim3 block( 32, (thrblk==512?16:8) );\n",
        "  dim3 grid( (N+TN-1)/TN, (M+TM-1)/TM, splitK );\n",
        "  size_t smem = Tiler<TM,TN,TK>::SMEM_BYTES;\n",
        "\n",
        "  vector<vector<int32_t>> Cmods(primes.size()); for(auto&v:Cmods) v.assign((size_t)M*N,0);\n",
        "  auto t0=clk::now(); int iters=0; double wall_ms=0.0;\n",
        "\n",
        "  do{\n",
        "    for(size_t pi=0; pi<primes.size(); ++pi){\n",
        "      int p=primes[pi]; vector<int8_t>A8,B8; pack_mod_s8_from_i32(Ah,A8,p); pack_mod_s8_from_i32(Bh,B8,p);\n",
        "      CUDA_OK(cudaMemcpy(dA,A8.data(),Asz,cudaMemcpyHostToDevice),\"H2D A\");\n",
        "      CUDA_OK(cudaMemcpy(dB,B8.data(),Bsz,cudaMemcpyHostToDevice),\"H2D B\");\n",
        "      CUDA_OK(cudaMemset(dC,0,Csz*sizeof(int32_t)),\"memset C\");\n",
        "\n",
        "      bool fast = (M%TM)==0 && (N%TN)==0 && (K%TK)==0;\n",
        "      if(fast)\n",
        "        gemm_dp4a_fast<TM,TN,TK><<<grid,block,smem>>>(dA,dB,dC,M,N,K,p,splitK);\n",
        "      else\n",
        "        gemm_dp4a_safe<TM,TN,TK><<<grid,block,smem>>>(dA,dB,dC,M,N,K,p,splitK);\n",
        "      CUDA_OK(cudaPeekAtLastError(),\"kernel launch\"); CUDA_OK(cudaDeviceSynchronize(),\"kernel sync\");\n",
        "\n",
        "      vector<int32_t> tmp(Csz);\n",
        "      CUDA_OK(cudaMemcpy(tmp.data(),dC,tmp.size()*sizeof(int32_t),cudaMemcpyDeviceToHost),\"D2H C\");\n",
        "      for(size_t idx=0; idx<(size_t)M*N; ++idx){\n",
        "        long long v=0; for(int s=0;s<splitK;s++) v += tmp[idx + (size_t)s*(size_t)M*(size_t)N];\n",
        "        int r=(int)(v%p); if(r<0) r+=p; Cmods[pi][idx]=r;\n",
        "      }\n",
        "    }\n",
        "    iters++;\n",
        "    wall_ms = chrono::duration<double,milli>(clk::now()-t0).count();\n",
        "  } while (wall_ms < ms_min);\n",
        "\n",
        "  double secs=wall_ms/1000.0; double logical=(double)M*N*K; double modular=logical* (double)primes.size(); double dp4a = (modular*iters/secs)/4.0;\n",
        "  uint64_t h = crt_hash(Cmods,M,N,8192,primes,0);\n",
        "  printf(\"  [CASE] TK=%d thr=%d splitK=%d | iters=%d  time=%.2f ms  Logical=%.3f  Modular=%.3f  dp4a=%.3f  hash=0x%016llx\\n\",\n",
        "         TK,thrblk,splitK,iters,wall_ms, (logical*iters)/secs/1e9, (modular*iters)/secs/1e9, dp4a/1e9, (unsigned long long)h);\n",
        "\n",
        "  cudaFree(dA); cudaFree(dB); cudaFree(dC);\n",
        "  Metrics m; m.gmac_logical=(logical*iters)/secs/1e9; m.gmac_modular=(modular*iters)/secs/1e9; m.ginst_dp4a=dp4a/1e9; m.wall_ms=wall_ms; m.hash=h; m.tk=TK; m.thr=thrblk; m.splitK=splitK; return m;\n",
        "}\n",
        "\n",
        "// ====== Roofline helpers (estimates) ======\n",
        "static void roofline_report(const Args&a, const Metrics&m){\n",
        "  // Per prime, global bytes (A: M*K, B: K*N, C: M*N) in int8/int8/int32 (writeback once).\n",
        "  double bytes_A = (double)a.M*a.K;           // int8\n",
        "  double bytes_B = (double)a.K*a.N;           // int8\n",
        "  double bytes_C = (double)a.M*a.N*4.0;       // int32\n",
        "  // Effective, per prime, per iteration → multiply by primes and iters/second\n",
        "  // We convert to GiB/s using 1e9 for simplicity (engineer’s GB).\n",
        "  printf(\"  [ROOFLINE] per-prime bytes A=%.3f MB  B=%.3f MB  C=%.3f MB (est. write)\\n\",\n",
        "         bytes_A/1e6, bytes_B/1e6, bytes_C/1e6);\n",
        "  // Arithmetic intensity ≈ modular MACs / (A+B+C bytes)\n",
        "  double macs = (double)a.M*a.N*a.K; // per prime\n",
        "  double bytes_total = bytes_A + bytes_B + bytes_C;\n",
        "  double intensity = macs / bytes_total;\n",
        "  printf(\"  [ROOFLINE] arithmetic intensity ≈ %.3f MAC/byte (per prime)\\n\", intensity);\n",
        "}\n",
        "\n",
        "int main(int argc,char**argv){\n",
        "  ios::sync_with_stdio(false); cin.tie(nullptr);\n",
        "  Args a; parse(argc,argv,a);\n",
        "\n",
        "  int P=max(1,min(a.primes,(int)(sizeof(PRIMES_TBL)/sizeof(PRIMES_TBL[0]))));\n",
        "  vector<int> primes(P); for(int i=0;i<P;i++) primes[i]=PRIMES_TBL[i];\n",
        "\n",
        "  const int M=a.M,N=a.N,K=a.K;\n",
        "  vector<int32_t> Ah((size_t)M*K), Bh((size_t)K*N);\n",
        "  mt19937 rng(a.seed); uniform_int_distribution<int> d(-700,700);\n",
        "  for(auto&x:Ah) x=d(rng); for(auto&x:Bh) x=d(rng);\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" AUTOTUNE WARPIPE  M=%d N=%d K=%d primes=%d  ms_min=%d  seed=%u\\n\",M,N,K,P,a.ms_min,a.seed);\n",
        "  printf(\" sweep: TK in {64,32} × thr in {512,256} × splitK in {1,2,4}\\n\");\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  vector<Metrics> all;\n",
        "  for(int TK: {64,32}){\n",
        "    for(int thr: {512,256}){\n",
        "      for(int splitK: {1,2,4}){\n",
        "        Metrics m;\n",
        "        if(TK==64) m = run_case<128,128,64>(Ah,Bh,M,N,K,primes,splitK,thr,a.ms_min);\n",
        "        else       m = run_case<128,128,32>(Ah,Bh,M,N,K,primes,splitK,thr,a.ms_min);\n",
        "        all.push_back(m);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // pick best by modular G-mac/s\n",
        "  auto best = max_element(all.begin(), all.end(), [](const Metrics&x,const Metrics&y){ return x.gmac_modular < y.gmac_modular; });\n",
        "\n",
        "  printf(\"=== AUTOTUNE BEST ===\\n\");\n",
        "  printf(\"  TK=%d thr=%d splitK=%d | Modular=%.3f G-mac/s  Logical=%.3f  dp4a=%.3f  time=%.2f ms  hash=0x%016llx\\n\",\n",
        "         best->tk, best->thr, best->splitK, best->gmac_modular, best->gmac_logical, best->ginst_dp4a, best->wall_ms, (unsigned long long)best->hash);\n",
        "\n",
        "  roofline_report(a, *best);\n",
        "\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# Build (T4 sm_75)\n",
        "nvcc -O3 -std=c++17 -arch=sm_75 -Xptxas -dlcm=ca -lineinfo g009h_warppipe_autotune.cu -o g009h_warppipe_autotune\n",
        "\n",
        "echo \"=== G009h: quick sweep (512^3, 5 primes) ===\"\n",
        "./g009h_warppipe_autotune --M 512 --N 512 --K 512 --primes 5 --ms 250\n",
        "\n",
        "echo\n",
        "echo \"=== G009h: big sweep (1024x2048x1024, 9 primes) ===\"\n",
        "./g009h_warppipe_autotune --M 1024 --N 1024 --K 2048 --primes 9 --ms 400\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_lTxD9WyniL",
        "outputId": "a4a6d9e5-92df-4f54-a85f-1344ca364f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== G009h: quick sweep (512^3, 5 primes) ===\n",
            "============================================================================\n",
            " AUTOTUNE WARPIPE  M=512 N=512 K=512 primes=5  ms_min=250  seed=12345\n",
            " sweep: TK in {64,32} × thr in {512,256} × splitK in {1,2,4}\n",
            "============================================================================\n",
            "  [CASE] TK=64 thr=512 splitK=1 | iters=6  time=281.01 ms  Logical=2.866  Modular=14.329  dp4a=3.582  hash=0x2bc55347937641a0\n",
            "  [CASE] TK=64 thr=512 splitK=2 | iters=6  time=292.94 ms  Logical=2.749  Modular=13.745  dp4a=3.436  hash=0x2bc55347937641a0\n",
            "  [CASE] TK=64 thr=512 splitK=4 | iters=5  time=261.38 ms  Logical=2.567  Modular=12.837  dp4a=3.209  hash=0x2bc55347937641a0\n",
            "  [CASE] TK=64 thr=256 splitK=1 | iters=6  time=273.63 ms  Logical=2.943  Modular=14.715  dp4a=3.679  hash=0x8dd82cbee7341f63\n",
            "  [CASE] TK=64 thr=256 splitK=2 | iters=6  time=291.86 ms  Logical=2.759  Modular=13.796  dp4a=3.449  hash=0xc8be2c2b56cebfd3\n",
            "  [CASE] TK=64 thr=256 splitK=4 | iters=5  time=258.19 ms  Logical=2.599  Modular=12.996  dp4a=3.249  hash=0x619c32eee93cae7b\n",
            "  [CASE] TK=32 thr=512 splitK=1 | iters=6  time=276.95 ms  Logical=2.908  Modular=14.539  dp4a=3.635  hash=0x2bc55347937641a0\n",
            "  [CASE] TK=32 thr=512 splitK=2 | iters=6  time=284.75 ms  Logical=2.828  Modular=14.140  dp4a=3.535  hash=0x2bc55347937641a0\n",
            "  [CASE] TK=32 thr=512 splitK=4 | iters=5  time=262.83 ms  Logical=2.553  Modular=12.766  dp4a=3.192  hash=0x2bc55347937641a0\n",
            "  [CASE] TK=32 thr=256 splitK=1 | iters=6  time=270.49 ms  Logical=2.977  Modular=14.886  dp4a=3.721  hash=0x1edaedf5c3e4b6ee\n",
            "  [CASE] TK=32 thr=256 splitK=2 | iters=6  time=281.25 ms  Logical=2.863  Modular=14.317  dp4a=3.579  hash=0x1edaedf5c3e4b6ee\n",
            "  [CASE] TK=32 thr=256 splitK=4 | iters=5  time=254.89 ms  Logical=2.633  Modular=13.164  dp4a=3.291  hash=0x1edaedf5c3e4b6ee\n",
            "=== AUTOTUNE BEST ===\n",
            "  TK=32 thr=256 splitK=1 | Modular=14.886 G-mac/s  Logical=2.977  dp4a=3.721  time=270.49 ms  hash=0x1edaedf5c3e4b6ee\n",
            "  [ROOFLINE] per-prime bytes A=0.262 MB  B=0.262 MB  C=1.049 MB (est. write)\n",
            "  [ROOFLINE] arithmetic intensity ≈ 85.333 MAC/byte (per prime)\n",
            "\n",
            "=== G009h: big sweep (1024x2048x1024, 9 primes) ===\n",
            "============================================================================\n",
            " AUTOTUNE WARPIPE  M=1024 N=1024 K=2048 primes=9  ms_min=400  seed=12345\n",
            " sweep: TK in {64,32} × thr in {512,256} × splitK in {1,2,4}\n",
            "============================================================================\n",
            "  [CASE] TK=64 thr=512 splitK=1 | iters=1  time=550.90 ms  Logical=3.898  Modular=35.083  dp4a=8.771  hash=0x1d38185025d77118\n",
            "  [CASE] TK=64 thr=512 splitK=2 | iters=1  time=583.76 ms  Logical=3.679  Modular=33.108  dp4a=8.277  hash=0x1d38185025d77118\n",
            "  [CASE] TK=64 thr=512 splitK=4 | iters=1  time=661.63 ms  Logical=3.246  Modular=29.212  dp4a=7.303  hash=0x1d38185025d77118\n",
            "  [CASE] TK=64 thr=256 splitK=1 | iters=1  time=566.08 ms  Logical=3.794  Modular=34.143  dp4a=8.536  hash=0xbd9f74a75c4a5527\n",
            "  [CASE] TK=64 thr=256 splitK=2 | iters=1  time=698.95 ms  Logical=3.072  Modular=27.652  dp4a=6.913  hash=0x19e22ff459ed9fd5\n",
            "  [CASE] TK=64 thr=256 splitK=4 | iters=1  time=747.83 ms  Logical=2.872  Modular=25.844  dp4a=6.461  hash=0xb37826cbcbbc2c76\n",
            "  [CASE] TK=32 thr=512 splitK=1 | iters=1  time=716.88 ms  Logical=2.996  Modular=26.960  dp4a=6.740  hash=0x1d38185025d77118\n",
            "  [CASE] TK=32 thr=512 splitK=2 | iters=1  time=594.54 ms  Logical=3.612  Modular=32.508  dp4a=8.127  hash=0x1d38185025d77118\n",
            "  [CASE] TK=32 thr=512 splitK=4 | iters=1  time=617.60 ms  Logical=3.477  Modular=31.294  dp4a=7.824  hash=0x1d38185025d77118\n",
            "  [CASE] TK=32 thr=256 splitK=1 | iters=1  time=548.71 ms  Logical=3.914  Modular=35.223  dp4a=8.806  hash=0xff38d2280c1e5d92\n",
            "  [CASE] TK=32 thr=256 splitK=2 | iters=1  time=564.40 ms  Logical=3.805  Modular=34.244  dp4a=8.561  hash=0xff38d2280c1e5d92\n",
            "  [CASE] TK=32 thr=256 splitK=4 | iters=1  time=607.25 ms  Logical=3.536  Modular=31.828  dp4a=7.957  hash=0xff38d2280c1e5d92\n",
            "=== AUTOTUNE BEST ===\n",
            "  TK=32 thr=256 splitK=1 | Modular=35.223 G-mac/s  Logical=3.914  dp4a=8.806  time=548.71 ms  hash=0xff38d2280c1e5d92\n",
            "  [ROOFLINE] per-prime bytes A=2.097 MB  B=2.097 MB  C=4.194 MB (est. write)\n",
            "  [ROOFLINE] arithmetic intensity ≈ 256.000 MAC/byte (per prime)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# =============================================================================\n",
        "# █████████████  MODULE G010a_FIX :: TENSOR-CORE RNS GEMM (cuBLAS INT8)  ██████\n",
        "#   FIXES:\n",
        "#     • alpha/beta are int32 (required for s8 GEMM), not int8  ✅\n",
        "#     • graceful fallback if tensor-op algo isn't supported\n",
        "#   Exact RNS math (≤127 primes), CRT certificate + ops meters.\n",
        "# =============================================================================\n",
        "\n",
        "cat > g010a_fix_tc_rns_gemm_cublas.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "using namespace std; using clk = chrono::high_resolution_clock;\n",
        "\n",
        "// ---------- CLI ----------\n",
        "struct Args {\n",
        "  int M=1024, N=1024, K=2048;\n",
        "  int primes=9, ms_min=500, verify=1, recon_K=8192;\n",
        "  long long cert_bound=0; unsigned seed=12345u;\n",
        "};\n",
        "static void parse(int argc,char**argv,Args&a){\n",
        "  for(int i=1;i<argc;i++){ string s=argv[i]; auto need=[&]{ if(i+1>=argc){fprintf(stderr,\"Missing %s\\n\",s.c_str()); exit(1);} };\n",
        "    if(s==\"--M\"){need();a.M=atoi(argv[++i]);} else if(s==\"--N\"){need();a.N=atoi(argv[++i]);}\n",
        "    else if(s==\"--K\"){need();a.K=atoi(argv[++i]);} else if(s==\"--primes\"){need();a.primes=atoi(argv[++i]);}\n",
        "    else if(s==\"--ms\"){need();a.ms_min=atoi(argv[++i]);} else if(s==\"--seed\"){need();a.seed=(unsigned)strtoul(argv[++i],nullptr,10);}\n",
        "    else if(s==\"--reconK\"){need();a.recon_K=atoi(argv[++i]);} else if(s==\"--cert\"){need();a.cert_bound=atoll(argv[++i]);}\n",
        "    else if(s==\"--noverify\"){a.verify=0;} else if(s==\"--verify\"){a.verify=1;}\n",
        "  }\n",
        "}\n",
        "static const int PRIMES_TBL[16]={127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53};\n",
        "\n",
        "// ---------- utils ----------\n",
        "static inline void CUDA_OK(cudaError_t e,const char*w){ if(e!=cudaSuccess){fprintf(stderr,\"CUDA ERROR @%s: %s\\n\",w,cudaGetErrorString(e)); exit(1);} }\n",
        "static inline void CUBLAS_OK(cublasStatus_t s,const char*w){ if(s!=CUBLAS_STATUS_SUCCESS){fprintf(stderr,\"CUBLAS ERROR @%s: %d\\n\",w,(int)s); exit(1);} }\n",
        "static inline uint64_t fnv1a64_append(uint64_t h,const void*p,size_t n){ const uint8_t*b=(const uint8_t*)p; const uint64_t P=1099511628211ull; for(size_t i=0;i<n;i++){h^=b[i]; h*=P;} return h; }\n",
        "static uint64_t invmod_u64(uint64_t a,uint64_t mod){ int64_t t=0,n=1,r=(int64_t)mod,m=(int64_t)a; while(m){ int64_t q=r/m; int64_t T=n; n=t-q*n; t=T; int64_t R=m; m=r-q*m; r=R; } if(r>1) return 0; if(t<0) t+=mod; return (uint64_t)t; }\n",
        "static void pack_mod_s8_from_i32(const vector<int32_t>&X, vector<int8_t>&Y, int p){ Y.resize(X.size()); for(size_t i=0;i<X.size();++i){ long long v=X[i]%p; if(v<0)v+=p; if(v>p/2)v-=p; Y[i]=(int8_t)v; } }\n",
        "static uint64_t crt_hash(const vector<vector<int32_t>>& Cmods, int M, int N, int reconK, const vector<int>& primes, long long cert){\n",
        "  int P=(int)primes.size(); uint64_t Mprod=1; for(int i=0;i<P;i++) Mprod*=(uint64_t)primes[i];\n",
        "  if(cert>0) printf(\"CRT certificate: Mprod=%llu  vs  2*bound=%llu  %s\\n\",\n",
        "    (unsigned long long)Mprod, (unsigned long long)(2ull*(uint64_t)cert),\n",
        "    (Mprod>2ull*(uint64_t)cert? \"(UNIQUE RECON OK)\":\"(INSUFFICIENT)\"));\n",
        "  vector<uint64_t> Mi(P), yi(P); uint64_t Mtot=1; for(int i=0;i<P;i++) Mtot*=(uint64_t)primes[i];\n",
        "  for(int i=0;i<P;i++){ Mi[i]=Mtot/(uint64_t)primes[i]; yi[i]=invmod_u64(Mi[i]%primes[i],primes[i]); }\n",
        "  const int total=M*N; const int K=min(reconK,total); int stride = 2654435761u % max(1,total); int idx=0; uint64_t h=0;\n",
        "  for(int t=0;t<K;++t){ uint64_t x=0; for(int i=0;i<P;i++){ uint64_t ai=((uint64_t)Cmods[i][idx]%primes[i]+primes[i])%primes[i];\n",
        "    x=(x + ai*Mi[i]%Mtot*yi[i]%Mtot)%Mtot; } h=fnv1a64_append(h,&x,sizeof(x)); idx+=stride; if(idx>=total) idx-=total; }\n",
        "  return h;\n",
        "}\n",
        "\n",
        "// attempt GEMM with a chosen algo, return cublasStatus\n",
        "static cublasStatus_t gemm_int8_try(cublasHandle_t h,\n",
        "  int m,int n,int k,\n",
        "  const int8_t* dB,int lda,  // column-major B^T (N x K)\n",
        "  const int8_t* dA,int ldb,  // column-major A^T (K x M)\n",
        "  int32_t* dC,int ldc,       // column-major C^T (N x M)\n",
        "  int algo_selector           // 0: DEFAULT_TENSOR_OP, 1: DEFAULT\n",
        "){\n",
        "  // IMPORTANT: alpha/beta must be int32 pointers for integer GEMM\n",
        "  int32_t alpha = 1, beta = 0;\n",
        "\n",
        "  // computeType juggling for different toolkits\n",
        "  // try CUDA_R_32I first (works across many versions)\n",
        "  cublasStatus_t s = cublasGemmEx(\n",
        "    h, CUBLAS_OP_N, CUBLAS_OP_N,\n",
        "    m,n,k,\n",
        "    &alpha,\n",
        "    dB, CUDA_R_8I, lda,\n",
        "    dA, CUDA_R_8I, ldb,\n",
        "    &beta,\n",
        "    dC, CUDA_R_32I, ldc,\n",
        "    CUDA_R_32I,\n",
        "    algo_selector==0 ? CUBLAS_GEMM_DEFAULT_TENSOR_OP : CUBLAS_GEMM_DEFAULT\n",
        "  );\n",
        "#if defined(CUBLAS_COMPUTE_32I)\n",
        "  if(s==CUBLAS_STATUS_NOT_SUPPORTED){\n",
        "    // second try with cublasComputeType_t path\n",
        "    s = cublasGemmEx(\n",
        "      h, CUBLAS_OP_N, CUBLAS_OP_N,\n",
        "      m,n,k,\n",
        "      &alpha,\n",
        "      dB, CUDA_R_8I, lda,\n",
        "      dA, CUDA_R_8I, ldb,\n",
        "      &beta,\n",
        "      dC, CUDA_R_32I, ldc,\n",
        "      CUBLAS_COMPUTE_32I,\n",
        "      algo_selector==0 ? CUBLAS_GEMM_DEFAULT_TENSOR_OP : CUBLAS_GEMM_DEFAULT\n",
        "    );\n",
        "  }\n",
        "#endif\n",
        "  return s;\n",
        "}\n",
        "\n",
        "int main(int argc,char**argv){\n",
        "  ios::sync_with_stdio(false); cin.tie(nullptr);\n",
        "  Args a; parse(argc,argv,a);\n",
        "  int P=max(1,min(a.primes,(int)(sizeof(PRIMES_TBL)/sizeof(PRIMES_TBL[0]))));\n",
        "  vector<int> primes(P); for(int i=0;i<P;i++) primes[i]=PRIMES_TBL[i];\n",
        "\n",
        "  const int M=a.M,N=a.N,K=a.K;\n",
        "  vector<int32_t> Ah((size_t)M*K), Bh((size_t)K*N);\n",
        "  mt19937 rng(a.seed); uniform_int_distribution<int> d(-700,700);\n",
        "  for(auto&x:Ah) x=d(rng); for(auto&x:Bh) x=d(rng);\n",
        "\n",
        "  int8_t *dA=nullptr,*dB=nullptr; int32_t *dC=nullptr;\n",
        "  size_t Asz=(size_t)M*K, Bsz=(size_t)K*N, Csz=(size_t)M*N;\n",
        "  CUDA_OK(cudaMalloc(&dA,Asz),\"malloc dA\");\n",
        "  CUDA_OK(cudaMalloc(&dB,Bsz),\"malloc dB\");\n",
        "  CUDA_OK(cudaMalloc(&dC,Csz*sizeof(int32_t)),\"malloc dC\");\n",
        "\n",
        "  cublasHandle_t h; CUBLAS_OK(cublasCreate(&h),\"cublasCreate\");\n",
        "  // (math mode may be ignored on recent toolkits, but harmless to set)\n",
        "  cublasStatus_t mathS = cublasSetMathMode(h, CUBLAS_TENSOR_OP_MATH);\n",
        "\n",
        "  vector<vector<int32_t>> Cmods(P); for(auto&v:Cmods) v.assign(Csz,0);\n",
        "\n",
        "  auto t0=clk::now(); int iters=0; double wall_ms=0.0;\n",
        "  do{\n",
        "    for(int pi=0; pi<P; ++pi){\n",
        "      const int p = primes[pi];\n",
        "      vector<int8_t> A8,B8; pack_mod_s8_from_i32(Ah,A8,p); pack_mod_s8_from_i32(Bh,B8,p);\n",
        "      CUDA_OK(cudaMemcpy(dA,A8.data(),Asz,cudaMemcpyHostToDevice),\"H2D A8\");\n",
        "      CUDA_OK(cudaMemcpy(dB,B8.data(),Bsz,cudaMemcpyHostToDevice),\"H2D B8\");\n",
        "      CUDA_OK(cudaMemset(dC,0,Csz*sizeof(int32_t)),\"memset C\");\n",
        "\n",
        "      // C^T = B^T · A^T (column-major call)\n",
        "      const int m=N, n=M, k=K;       // result is (N x M)\n",
        "      const int lda=N, ldb=K, ldc=N; // leading dims for column-major\n",
        "\n",
        "      // try tensor-op algo first, then fall back to default if needed\n",
        "      cublasStatus_t s = gemm_int8_try(h,m,n,k,dB,lda,dA,ldb,dC,ldc,0);\n",
        "      if(s==CUBLAS_STATUS_NOT_SUPPORTED){\n",
        "        s = gemm_int8_try(h,m,n,k,dB,lda,dA,ldb,dC,ldc,1);\n",
        "      }\n",
        "      if(s!=CUBLAS_STATUS_SUCCESS){\n",
        "        fprintf(stderr,\"CUBLAS final error: %d\\n\",(int)s);\n",
        "        exit(1);\n",
        "      }\n",
        "\n",
        "      vector<int32_t> Ct(Csz);\n",
        "      CUDA_OK(cudaMemcpy(Ct.data(), dC, Csz*sizeof(int32_t), cudaMemcpyDeviceToHost), \"D2H C\");\n",
        "      for(size_t i=0;i<Csz;i++){ int v=Ct[i]%p; if(v<0) v+=p; Cmods[pi][i]=v; }\n",
        "    }\n",
        "    iters++;\n",
        "    wall_ms = chrono::duration<double,milli>(clk::now()-t0).count();\n",
        "  } while (wall_ms < a.ms_min);\n",
        "\n",
        "  double secs = wall_ms/1000.0;\n",
        "  double logical = (double)M*N*K;\n",
        "  double modular = logical * (double)P;\n",
        "  uint64_t hcrt = a.verify? crt_hash(Cmods,M,N,a.recon_K,primes,a.cert_bound):0;\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [G010a_FIX_TC_RNS] M=%d N=%d K=%d  primes=%d  iters=%d  time=%.2f ms\\n\", M,N,K,P,iters,wall_ms);\n",
        "  printf(\"  Logical MACs/s:        %.3f G-mac/s\\n\", (logical*iters)/secs/1e9);\n",
        "  printf(\"  Modular MACs/s:        %.3f G-mac/s   (× primes)\\n\", (modular*iters)/secs/1e9);\n",
        "  if(a.verify) printf(\"  CRT (strided) hash:    0x%016llx\\n\", (unsigned long long)hcrt);\n",
        "  printf(\"  cuBLAS int8 path:      tensor-op try, fallback to default if needed\\n\");\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  cublasDestroy(h); cudaFree(dA); cudaFree(dB); cudaFree(dC); return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# Build\n",
        "nvcc -O3 -std=c++17 -arch=sm_75 -lcublas -lineinfo g010a_fix_tc_rns_gemm_cublas.cu -o g010a_fix_tc_rns_gemm_cublas\n",
        "\n",
        "echo \"=== G010a_FIX: quick (512^3, 5 primes) ===\"\n",
        "./g010a_fix_tc_rns_gemm_cublas --M 512 --N 512 --K 512 --primes 5 --ms 300 --reconK 4096 --cert 2000000\n",
        "\n",
        "echo\n",
        "echo \"=== G010a_FIX: big (1024x2048x1024, 9 primes) ===\"\n",
        "./g010a_fix_tc_rns_gemm_cublas --M 1024 --N 1024 --K 2048 --primes 9 --ms 400 --reconK 8192 --cert 3200000000\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvAbzp7zyqds",
        "outputId": "35f668df-7145-4fcf-b640-a2f204f15d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== G010a_FIX: quick (512^3, 5 primes) ===\n",
            "CRT certificate: Mprod=17239698439  vs  2*bound=4000000  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G010a_FIX_TC_RNS] M=512 N=512 K=512  primes=5  iters=7  time=338.24 ms\n",
            "  Logical MACs/s:        2.778 G-mac/s\n",
            "  Modular MACs/s:        13.889 G-mac/s   (× primes)\n",
            "  CRT (strided) hash:    0xf2cbf60ba180a186\n",
            "  cuBLAS int8 path:      tensor-op try, fallback to default if needed\n",
            "============================================================================\n",
            "\n",
            "=== G010a_FIX: big (1024x2048x1024, 9 primes) ===\n",
            "CRT certificate: Mprod=1247644544258044721  vs  2*bound=6400000000  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G010a_FIX_TC_RNS] M=1024 N=1024 K=2048  primes=9  iters=1  time=535.60 ms\n",
            "  Logical MACs/s:        4.009 G-mac/s\n",
            "  Modular MACs/s:        36.085 G-mac/s   (× primes)\n",
            "  CRT (strided) hash:    0xc3e69078fa3369c5\n",
            "  cuBLAS int8 path:      tensor-op try, fallback to default if needed\n",
            "============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# =============================================================================\n",
        "# █████████████  MODULE G010b_FIX2 :: cuBLASLt INT8 RNS AUTOTUNE  ████████████\n",
        "#   FIXES:\n",
        "#     • Proper row-major shapes: A(M×K, ld=K), B(K×N, ld=N), C/D(M×N, ld=N)\n",
        "#     • opA/opB = NON_TRANS (no transpose tricks)\n",
        "#     • Heuristic retry with 0-workspace on failure\n",
        "#   FEATURES:\n",
        "#     • Exact RNS (primes ≤127), CRT strided certificate + hash\n",
        "#     • Lt heuristic sweep, prints best algo + ops meters\n",
        "# =============================================================================\n",
        "\n",
        "cat > g010b_fix2_lt_int8_rns_autotune.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "#include <cublasLt.h>\n",
        "using namespace std; using clk = chrono::high_resolution_clock;\n",
        "\n",
        "// ---------- CLI ----------\n",
        "struct Args {\n",
        "  int M=1024, N=1024, K=2048;\n",
        "  int primes=9, ms_min=400, verify=1, recon_K=8192;\n",
        "  long long cert_bound=0; unsigned seed=12345u;\n",
        "  size_t workspace_mb=64;          // Lt workspace cap\n",
        "};\n",
        "static void parse(int argc,char**argv,Args&a){\n",
        "  for(int i=1;i<argc;i++){\n",
        "    string s=argv[i]; auto need=[&]{ if(i+1>=argc){ fprintf(stderr,\"Missing %s\\n\", s.c_str()); exit(1);} };\n",
        "    if(s==\"--M\"){need();a.M=atoi(argv[++i]);} else if(s==\"--N\"){need();a.N=atoi(argv[++i]);}\n",
        "    else if(s==\"--K\"){need();a.K=atoi(argv[++i]);} else if(s==\"--primes\"){need();a.primes=atoi(argv[++i]);}\n",
        "    else if(s==\"--ms\"){need();a.ms_min=atoi(argv[++i]);} else if(s==\"--seed\"){need();a.seed=(unsigned)strtoul(argv[++i],nullptr,10);}\n",
        "    else if(s==\"--reconK\"){need();a.recon_K=atoi(argv[++i]);} else if(s==\"--cert\"){need();a.cert_bound=atoll(argv[++i]);}\n",
        "    else if(s==\"--noverify\"){a.verify=0;} else if(s==\"--verify\"){a.verify=1;}\n",
        "    else if(s==\"--wsMB\"){need();a.workspace_mb=(size_t)strtoull(argv[++i],nullptr,10);}\n",
        "  }\n",
        "}\n",
        "static const int PRIMES_TBL[16]={127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53};\n",
        "\n",
        "// ---------- utils ----------\n",
        "static inline void CUDA_OK(cudaError_t e,const char*w){ if(e!=cudaSuccess){fprintf(stderr,\"CUDA ERROR @%s: %s\\n\",w,cudaGetErrorString(e)); exit(1);} }\n",
        "static inline void LT_REQ(cublasStatus_t s,const char*w){ if(s!=CUBLAS_STATUS_SUCCESS){fprintf(stderr,\"cuBLAS/Lt ERROR @%s: %d\\n\",w,(int)s); exit(1);} }\n",
        "static inline bool LT_TRY(cublasStatus_t s){ return s==CUBLAS_STATUS_SUCCESS; }\n",
        "static inline uint64_t fnv1a64_append(uint64_t h,const void*p,size_t n){ const uint8_t*b=(const uint8_t*)p; const uint64_t P=1099511628211ull; for(size_t i=0;i<n;i++){h^=b[i]; h*=P;} return h; }\n",
        "static uint64_t invmod_u64(uint64_t a,uint64_t mod){ int64_t t=0,n=1,r=(int64_t)mod,m=(int64_t)a; while(m){ int64_t q=r/m; int64_t T=n; n=t-q*n; t=T; int64_t R=m; m=r-q*m; r=R; } if(r>1) return 0; if(t<0) t+=mod; return (uint64_t)t; }\n",
        "static void pack_mod_s8_from_i32(const vector<int32_t>&X, vector<int8_t>&Y, int p){\n",
        "  Y.resize(X.size());\n",
        "  for(size_t i=0;i<X.size();++i){ long long v=X[i]%p; if(v<0)v+=p; if(v>p/2)v-=p; Y[i]=(int8_t)v; }\n",
        "}\n",
        "static uint64_t crt_hash(const vector<vector<int32_t>>& Cmods, int M, int N, int reconK, const vector<int>& primes, long long cert){\n",
        "  int P=(int)primes.size(); uint64_t Mprod=1; for(int i=0;i<P;i++) Mprod*=(uint64_t)primes[i];\n",
        "  if(cert>0) printf(\"CRT certificate: Mprod=%llu  vs  2*bound=%llu  %s\\n\",\n",
        "    (unsigned long long)Mprod, (unsigned long long)(2ull*(uint64_t)cert),\n",
        "    (Mprod>2ull*(uint64_t)cert? \"(UNIQUE RECON OK)\":\"(INSUFFICIENT)\"));\n",
        "  vector<uint64_t> Mi(P), yi(P); uint64_t Mtot=1; for(int i=0;i<P;i++) Mtot*=(uint64_t)primes[i];\n",
        "  for(int i=0;i<P;i++){ Mi[i]=Mtot/(uint64_t)primes[i]; yi[i]=invmod_u64(Mi[i]%primes[i],primes[i]); }\n",
        "  const int total=M*N; const int K=min(reconK,total); int stride = 11400714819323198485ull % max(1,total); int idx=0; uint64_t h=0;\n",
        "  for(int t=0;t<K;++t){ uint64_t x=0; for(int i=0;i<P;i++){ uint64_t ai=((uint64_t)Cmods[i][idx]%primes[i]+primes[i])%primes[i];\n",
        "    x=(x + ai*Mi[i]%Mtot*yi[i]%Mtot)%Mtot; } h=fnv1a64_append(h,&x,sizeof(x)); idx+=stride; if(idx>=total) idx-=total; }\n",
        "  return h;\n",
        "}\n",
        "\n",
        "// ---------- Lt wrapper ----------\n",
        "struct LtGemm {\n",
        "  cublasLtHandle_t lt{};\n",
        "  cublasLtMatmulDesc_t op{};\n",
        "  cublasLtMatrixLayout_t Adesc{}, Bdesc{}, Cdesc{}, Ddesc{};\n",
        "  cublasLtMatmulPreference_t pref{};\n",
        "  void* workspace=nullptr; size_t ws_bytes=0;\n",
        "\n",
        "  LtGemm(int M,int N,int K,size_t ws_mb){\n",
        "    LT_REQ(cublasLtCreate(&lt), \"ltCreate\");\n",
        "\n",
        "    // Matmul descriptor: compute=int32, scale=int32; NON_TRANS for row-major layouts\n",
        "    LT_REQ(cublasLtMatmulDescCreate(&op, CUBLAS_COMPUTE_32I, CUDA_R_32I), \"MatmulDescCreate\");\n",
        "    cublasOperation_t nt = CUBLAS_OP_N;\n",
        "    LT_REQ(cublasLtMatmulDescSetAttribute(op, CUBLASLT_MATMUL_DESC_TRANSA, &nt, sizeof(nt)), \"set transA\");\n",
        "    LT_REQ(cublasLtMatmulDescSetAttribute(op, CUBLASLT_MATMUL_DESC_TRANSB, &nt, sizeof(nt)), \"set transB\");\n",
        "\n",
        "    // Layouts: ROW order, leading dim = number of columns\n",
        "    cublasLtOrder_t row = CUBLASLT_ORDER_ROW;\n",
        "\n",
        "    // A: (M x K), ld=K\n",
        "    LT_REQ(cublasLtMatrixLayoutCreate(&Adesc, CUDA_R_8I, /*rows*/M, /*cols*/K, /*ld*/K), \"Adesc\");\n",
        "    LT_REQ(cublasLtMatrixLayoutSetAttribute(Adesc, CUBLASLT_MATRIX_LAYOUT_ORDER, &row, sizeof(row)), \"A row\");\n",
        "\n",
        "    // B: (K x N), ld=N\n",
        "    LT_REQ(cublasLtMatrixLayoutCreate(&Bdesc, CUDA_R_8I, /*rows*/K, /*cols*/N, /*ld*/N), \"Bdesc\");\n",
        "    LT_REQ(cublasLtMatrixLayoutSetAttribute(Bdesc, CUBLASLT_MATRIX_LAYOUT_ORDER, &row, sizeof(row)), \"B row\");\n",
        "\n",
        "    // C/D: (M x N), ld=N\n",
        "    LT_REQ(cublasLtMatrixLayoutCreate(&Cdesc, CUDA_R_32I, /*rows*/M, /*cols*/N, /*ld*/N), \"Cdesc\");\n",
        "    LT_REQ(cublasLtMatrixLayoutSetAttribute(Cdesc, CUBLASLT_MATRIX_LAYOUT_ORDER, &row, sizeof(row)), \"C row\");\n",
        "    LT_REQ(cublasLtMatrixLayoutCreate(&Ddesc, CUDA_R_32I, /*rows*/M, /*cols*/N, /*ld*/N), \"Ddesc\");\n",
        "    LT_REQ(cublasLtMatrixLayoutSetAttribute(Ddesc, CUBLASLT_MATRIX_LAYOUT_ORDER, &row, sizeof(row)), \"D row\");\n",
        "\n",
        "    // preference + workspace\n",
        "    LT_REQ(cublasLtMatmulPreferenceCreate(&pref), \"prefCreate\");\n",
        "    ws_bytes = ws_mb * (size_t)1024*1024;\n",
        "    if(ws_bytes){\n",
        "      CUDA_OK(cudaMalloc(&workspace, ws_bytes), \"wsAlloc\");\n",
        "      LT_REQ(cublasLtMatmulPreferenceSetAttribute(pref, CUBLASLT_MATMUL_PREF_MAX_WORKSPACE_BYTES, &ws_bytes, sizeof(ws_bytes)), \"prefWS\");\n",
        "    }\n",
        "  }\n",
        "  void setZeroWorkspace(){\n",
        "    if(workspace){ cudaFree(workspace); workspace=nullptr; }\n",
        "    ws_bytes = 0;\n",
        "    LT_REQ(cublasLtMatmulPreferenceSetAttribute(pref, CUBLASLT_MATMUL_PREF_MAX_WORKSPACE_BYTES, &ws_bytes, sizeof(ws_bytes)), \"prefWS0\");\n",
        "  }\n",
        "  ~LtGemm(){\n",
        "    if(workspace) cudaFree(workspace);\n",
        "    if(Adesc) cublasLtMatrixLayoutDestroy(Adesc);\n",
        "    if(Bdesc) cublasLtMatrixLayoutDestroy(Bdesc);\n",
        "    if(Cdesc) cublasLtMatrixLayoutDestroy(Cdesc);\n",
        "    if(Ddesc) cublasLtMatrixLayoutDestroy(Ddesc);\n",
        "    if(pref)  cublasLtMatmulPreferenceDestroy(pref);\n",
        "    if(op)    cublasLtMatmulDescDestroy(op);\n",
        "    if(lt)    cublasLtDestroy(lt);\n",
        "  }\n",
        "};\n",
        "\n",
        "static float run_lt_once(LtGemm& L,\n",
        "                         const int8_t* dA, const int8_t* dB, int32_t* dC,\n",
        "                         const cublasLtMatmulAlgo_t& algo)\n",
        "{\n",
        "  int32_t alpha=1, beta=0;\n",
        "  cudaEvent_t s,t; cudaEventCreate(&s); cudaEventCreate(&t);\n",
        "  cudaEventRecord(s);\n",
        "  cublasStatus_t st = cublasLtMatmul(L.lt, L.op,\n",
        "                                     &alpha,\n",
        "                                     dA, L.Adesc,\n",
        "                                     dB, L.Bdesc,\n",
        "                                     &beta,\n",
        "                                     dC, L.Cdesc,\n",
        "                                     dC, L.Ddesc,\n",
        "                                     &algo,\n",
        "                                     L.workspace, L.ws_bytes,\n",
        "                                     0 /*stream*/);\n",
        "  cudaEventRecord(t); cudaEventSynchronize(t);\n",
        "  float ms=INFINITY; if(st==CUBLAS_STATUS_SUCCESS) cudaEventElapsedTime(&ms, s, t);\n",
        "  cudaEventDestroy(s); cudaEventDestroy(t);\n",
        "  return ms;\n",
        "}\n",
        "\n",
        "int main(int argc,char**argv){\n",
        "  ios::sync_with_stdio(false); cin.tie(nullptr);\n",
        "  Args a; parse(argc,argv,a);\n",
        "  int P=max(1,min(a.primes,(int)(sizeof(PRIMES_TBL)/sizeof(PRIMES_TBL[0]))));\n",
        "  vector<int> primes(P); for(int i=0;i<P;i++) primes[i]=PRIMES_TBL[i];\n",
        "\n",
        "  const int M=a.M, N=a.N, K=a.K;\n",
        "  vector<int32_t> Ah((size_t)M*K), Bh((size_t)K*N);\n",
        "  mt19937 rng(a.seed); uniform_int_distribution<int> d(-700,700);\n",
        "  for(auto&x:Ah) x=d(rng); for(auto&x:Bh) x=d(rng);\n",
        "\n",
        "  // device buffers\n",
        "  int8_t *dA=nullptr,*dB=nullptr; int32_t *dC=nullptr;\n",
        "  size_t Asz=(size_t)M*K, Bsz=(size_t)K*N, Csz=(size_t)M*N;\n",
        "  CUDA_OK(cudaMalloc(&dA,Asz),\"malloc dA\");\n",
        "  CUDA_OK(cudaMalloc(&dB,Bsz),\"malloc dB\");\n",
        "  CUDA_OK(cudaMalloc(&dC,Csz*sizeof(int32_t)),\"malloc dC\");\n",
        "\n",
        "  // Lt setup\n",
        "  LtGemm L(M,N,K,a.workspace_mb);\n",
        "\n",
        "  // Heuristic algos (try with requested ws, else fallback to 0 ws)\n",
        "  const int maxAlgos=64;\n",
        "  cublasLtMatmulHeuristicResult_t results[maxAlgos]; int returned=0;\n",
        "  cublasStatus_t hs = cublasLtMatmulAlgoGetHeuristic(L.lt, L.op, L.Adesc, L.Bdesc, L.Cdesc, L.Ddesc,\n",
        "                                                     L.pref, maxAlgos, results, &returned);\n",
        "  if(!LT_TRY(hs) || returned==0){\n",
        "    fprintf(stderr,\"[Lt] heuristic with %zu MB failed (status=%d). Retrying with ws=0.\\n\",\n",
        "            (size_t)(L.ws_bytes/1024/1024), (int)hs);\n",
        "    L.setZeroWorkspace();\n",
        "    LT_REQ(cublasLtMatmulAlgoGetHeuristic(L.lt, L.op, L.Adesc, L.Bdesc, L.Cdesc, L.Ddesc,\n",
        "                                          L.pref, maxAlgos, results, &returned),\n",
        "           \"heuristic(ws=0)\");\n",
        "    if(returned==0){ fprintf(stderr,\"No Lt algos even with ws=0.\\n\"); return 1; }\n",
        "  }\n",
        "\n",
        "  // per-prime loop; autotune on first prime\n",
        "  int best=-1; float bestMs=INFINITY; bool tuned=false;\n",
        "  vector<vector<int32_t>> Cmods(P); for(auto&v:Cmods) v.assign(Csz,0);\n",
        "\n",
        "  auto t0=clk::now(); int iters=0; double wall_ms=0.0;\n",
        "  do{\n",
        "    for(int pi=0; pi<P; ++pi){\n",
        "      int p=primes[pi];\n",
        "      vector<int8_t> A8,B8; pack_mod_s8_from_i32(Ah,A8,p); pack_mod_s8_from_i32(Bh,B8,p);\n",
        "      CUDA_OK(cudaMemcpy(dA,A8.data(),Asz,cudaMemcpyHostToDevice),\"H2D A8\");\n",
        "      CUDA_OK(cudaMemcpy(dB,B8.data(),Bsz,cudaMemcpyHostToDevice),\"H2D B8\");\n",
        "      CUDA_OK(cudaMemset(dC,0,Csz*sizeof(int32_t)),\"memset C\");\n",
        "\n",
        "      if(!tuned){\n",
        "        for(int i=0;i<returned;i++){\n",
        "          float ms = run_lt_once(L,dA,dB,dC,results[i].algo);\n",
        "          if(ms<bestMs){ bestMs=ms; best=i; }\n",
        "        }\n",
        "        tuned=true;\n",
        "        printf(\"=== cuBLASLt pick: algoIndex=%d  time=%.2f ms (single)\\n\", best, bestMs);\n",
        "      }\n",
        "      (void)run_lt_once(L,dA,dB,dC,results[best].algo);\n",
        "\n",
        "      vector<int32_t> C32(Csz);\n",
        "      CUDA_OK(cudaMemcpy(C32.data(), dC, Csz*sizeof(int32_t), cudaMemcpyDeviceToHost), \"D2H C\");\n",
        "      for(size_t i=0;i<Csz;i++){ int v=C32[i]%p; if(v<0) v+=p; Cmods[pi][i]=v; }\n",
        "    }\n",
        "    iters++;\n",
        "    wall_ms = chrono::duration<double,milli>(clk::now()-t0).count();\n",
        "  } while (wall_ms < a.ms_min);\n",
        "\n",
        "  double secs=wall_ms/1000.0;\n",
        "  double logical=(double)M*N*K, modular=logical*(double)P;\n",
        "  uint64_t hcrt = a.verify? crt_hash(Cmods,M,N,a.recon_K,primes,a.cert_bound) : 0;\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [G010b_FIX2_LT_RNS] M=%d N=%d K=%d primes=%d iters=%d time=%.2f ms\\n\",M,N,K,P,iters,wall_ms);\n",
        "  printf(\"  Logical MACs/s:        %.3f G-mac/s\\n\", (logical*iters)/secs/1e9);\n",
        "  printf(\"  Modular MACs/s:        %.3f G-mac/s   (× primes)\\n\", (modular*iters)/secs/1e9);\n",
        "  printf(\"  dp4a-equiv inst/s:     %.3f G-inst/s  (~ modular/4)\\n\", ((modular*iters)/secs)/4.0/1e9);\n",
        "  if(hcrt) printf(\"  CRT (strided) hash:    0x%016llx\\n\", (unsigned long long)hcrt);\n",
        "  printf(\"  cuBLASLt workspace:    %zu MB\\n\", (size_t)(L.ws_bytes/1024/1024));\n",
        "  printf(\"============================================================================\\n\");\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# Build\n",
        "nvcc -O3 -std=c++17 -arch=sm_75 -lcublas -lcublasLt -lineinfo g010b_fix2_lt_int8_rns_autotune.cu -o g010b_fix2_lt_int8_rns_autotune\n",
        "\n",
        "echo \"=== G010b_FIX2: quick autotune (512^3, 5 primes) ===\"\n",
        "./g010b_fix2_lt_int8_rns_autotune --M 512 --N 512 --K 512 --primes 5 --ms 300 --reconK 4096 --cert 8000000 --wsMB 64\n",
        "\n",
        "echo\n",
        "echo \"=== G010b_FIX2: big autotune (1024x2048x1024, 9 primes) ===\"\n",
        "./g010b_fix2_lt_int8_rns_autotune --M 1024 --N 1024 --K 2048 --primes 9 --ms 400 --reconK 8192 --cert 6400000000 --wsMB 64\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iapvv2yS23gd",
        "outputId": "f01ea885-f2d0-4a60-d450-2eb57b3a6089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== G010b_FIX2: quick autotune (512^3, 5 primes) ===\n",
            "=== cuBLASLt pick: algoIndex=1  time=0.46 ms (single)\n",
            "CRT certificate: Mprod=17239698439  vs  2*bound=16000000  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G010b_FIX2_LT_RNS] M=512 N=512 K=512 primes=5 iters=6 time=330.63 ms\n",
            "  Logical MACs/s:        2.436 G-mac/s\n",
            "  Modular MACs/s:        12.178 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     3.045 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0xbd3d31fa812bbf66\n",
            "  cuBLASLt workspace:    64 MB\n",
            "============================================================================\n",
            "\n",
            "=== G010b_FIX2: big autotune (1024x2048x1024, 9 primes) ===\n",
            "=== cuBLASLt pick: algoIndex=1  time=1.06 ms (single)\n",
            "CRT certificate: Mprod=1247644544258044721  vs  2*bound=12800000000  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G010b_FIX2_LT_RNS] M=1024 N=1024 K=2048 primes=9 iters=1 time=654.34 ms\n",
            "  Logical MACs/s:        3.282 G-mac/s\n",
            "  Modular MACs/s:        29.537 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     7.384 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x06c66daa1aee737f\n",
            "  cuBLASLt workspace:    64 MB\n",
            "============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# =============================================================================\n",
        "# ███████████  MODULE G010c_FIX5 :: cuBLAS INT8 RNS (BATCHED, NO GPU XPOSE) ███\n",
        "#   • Critical fix: ldb = K (rows of Bop = A[K×N] in column-major)\n",
        "#   • lda = N, ldb = K, ldc = N; strides unchanged\n",
        "#   • Exact RNS int8 on Tensor Cores (T4), CRT certificate + ops meters\n",
        "#   • LEGO: single self-contained module, loud banners, safe to overwrite\n",
        "# =============================================================================\n",
        "\n",
        "cat > g010c_fix5_cublas_int8_rns_batched.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "using namespace std; using clk = chrono::high_resolution_clock;\n",
        "\n",
        "struct Args{ int M=1024,N=1024,K=2048,primes=9,ms_min=400,verify=1,recon_K=8192; long long cert_bound=0; unsigned seed=12345u; };\n",
        "static void parse(int argc,char**argv,Args&a){ for(int i=1;i<argc;i++){ string s=argv[i]; auto need=[&]{ if(i+1>=argc){fprintf(stderr,\"Missing %s\\n\",s.c_str()); exit(1);} };\n",
        "  if(s==\"--M\"){need();a.M=atoi(argv[++i]);} else if(s==\"--N\"){need();a.N=atoi(argv[++i]);}\n",
        "  else if(s==\"--K\"){need();a.K=atoi(argv[++i]);} else if(s==\"--primes\"){need();a.primes=atoi(argv[++i]);}\n",
        "  else if(s==\"--ms\"){need();a.ms_min=atoi(argv[++i]);} else if(s==\"--seed\"){need();a.seed=(unsigned)strtoul(argv[++i],nullptr,10);}\n",
        "  else if(s==\"--reconK\"){need();a.recon_K=atoi(argv[++i]);} else if(s==\"--cert\"){need();a.cert_bound=atoll(argv[++i]);}\n",
        "  else if(s==\"--noverify\"){a.verify=0;} else if(s==\"--verify\"){a.verify=1;}\n",
        "}}\n",
        "\n",
        "static const int PRIMES_TBL[16]={127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53};\n",
        "\n",
        "static inline void CUDA_OK(cudaError_t e,const char*w){ if(e!=cudaSuccess){fprintf(stderr,\"CUDA ERROR @%s: %s\\n\",w,cudaGetErrorString(e)); exit(1);} }\n",
        "static inline void CUBLAS_OK(cublasStatus_t s,const char*w){ if(s!=CUBLAS_STATUS_SUCCESS){fprintf(stderr,\"CUBLAS ERROR @%s: %d\\n\",w,(int)s); exit(1);} }\n",
        "static inline uint64_t fnv1a64_append(uint64_t h,const void*p,size_t n){ const uint8_t*b=(const uint8_t*)p; const uint64_t P=1099511628211ull; for(size_t i=0;i<n;i++){h^=b[i]; h*=P;} return h; }\n",
        "static uint64_t invmod_u64(uint64_t a,uint64_t mod){ int64_t t=0,n=1,r=(int64_t)mod,m=(int64_t)a; while(m){ int64_t q=r/m; int64_t T=n; n=t-q*n; t=T; int64_t R=m; m=r-q*m; r=R;} if(r>1) return 0; if(t<0) t+=mod; return (uint64_t)t; }\n",
        "\n",
        "static uint64_t crt_hash(const vector<vector<int32_t>>& Cmods,int M,int N,int reconK,const vector<int>&pr,long long cert){\n",
        "  int P=(int)pr.size(); uint64_t Mprod=1; for(int i=0;i<P;i++) Mprod*=(uint64_t)pr[i];\n",
        "  if(cert>0) printf(\"CRT certificate: Mprod=%llu  vs  2*bound=%llu  %s\\n\",\n",
        "    (unsigned long long)Mprod,(unsigned long long)(2ull*(uint64_t)cert),\n",
        "    (Mprod>2ull*(uint64_t)cert? \"(UNIQUE RECON OK)\":\"(INSUFFICIENT)\"));\n",
        "  vector<uint64_t> Mi(P), yi(P); uint64_t Mtot=1; for(int i=0;i<P;i++) Mtot*=(uint64_t)pr[i];\n",
        "  for(int i=0;i<P;i++){ Mi[i]=Mtot/(uint64_t)pr[i]; yi[i]=invmod_u64(Mi[i]%pr[i],pr[i]); }\n",
        "  const size_t total=(size_t)M*(size_t)N; const int K=min((int)reconK,(int)total);\n",
        "  size_t stride = (size_t)11400714819323198485ull % max<size_t>(1,total);\n",
        "  size_t idx=0; uint64_t h=0;\n",
        "  for(int t=0;t<K;++t){ uint64_t x=0; for(int i=0;i<P;i++){ uint64_t ai=((uint64_t)Cmods[i][idx]%pr[i]+pr[i])%pr[i];\n",
        "    x=(x + ai*Mi[i]%Mtot*yi[i]%Mtot)%Mtot; } h=fnv1a64_append(h,&x,sizeof(x)); idx+=stride; if(idx>=total) idx-=total; }\n",
        "  return h;\n",
        "}\n",
        "\n",
        "// int32 -> int8 residues, batched via stride\n",
        "__global__ void pack_mod_s8_strided(const int32_t* __restrict__ X, int8_t* __restrict__ Y,\n",
        "                                    int rows,int cols, size_t strideY,\n",
        "                                    const int* __restrict__ primes,int P)\n",
        "{\n",
        "  size_t t = (size_t)blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  size_t total = (size_t)rows * (size_t)cols;\n",
        "  if(t >= total) return;\n",
        "  int x = X[t];\n",
        "  #pragma unroll 1\n",
        "  for(int pidx=0;pidx<P;++pidx){\n",
        "    int p=primes[pidx];\n",
        "    int v = x % p; if(v<0) v+=p; if(v>p/2) v-=p; // balanced [-p/2, p/2]\n",
        "    size_t off = (size_t)pidx * strideY + t;\n",
        "    Y[off] = (int8_t)v;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc,char**argv){\n",
        "  ios::sync_with_stdio(false); cin.tie(nullptr);\n",
        "  Args a; parse(argc,argv,a);\n",
        "  const int P = max(1,min(a.primes,(int)(sizeof(PRIMES_TBL)/sizeof(PRIMES_TBL[0]))));\n",
        "  vector<int> primes(P); for(int i=0;i<P;i++) primes[i]=PRIMES_TBL[i];\n",
        "  const int M=a.M,N=a.N,K=a.K;\n",
        "  const size_t AszI=(size_t)M*(size_t)K, BszI=(size_t)K*(size_t)N, CszI=(size_t)M*(size_t)N;\n",
        "\n",
        "  // host data\n",
        "  vector<int32_t> Ah(AszI), Bh(BszI);\n",
        "  mt19937 rng(a.seed); uniform_int_distribution<int>d(-700,700);\n",
        "  for(auto&x:Ah) x=d(rng); for(auto&x:Bh) x=d(rng);\n",
        "\n",
        "  // device buffers\n",
        "  int32_t *dAh=nullptr,*dBh=nullptr; int8_t *dA8=nullptr,*dB8=nullptr; int32_t *dCT=nullptr;\n",
        "  CUDA_OK(cudaMalloc(&dAh, AszI*sizeof(int32_t)),\"dAh\");\n",
        "  CUDA_OK(cudaMalloc(&dBh, BszI*sizeof(int32_t)),\"dBh\");\n",
        "  CUDA_OK(cudaMemcpy(dAh,Ah.data(),AszI*sizeof(int32_t),cudaMemcpyHostToDevice),\"H2D Ah\");\n",
        "  CUDA_OK(cudaMemcpy(dBh,Bh.data(),BszI*sizeof(int32_t),cudaMemcpyHostToDevice),\"H2D Bh\");\n",
        "  CUDA_OK(cudaMalloc(&dA8, AszI*P*sizeof(int8_t)),\"dA8\");\n",
        "  CUDA_OK(cudaMalloc(&dB8, BszI*P*sizeof(int8_t)),\"dB8\");\n",
        "  CUDA_OK(cudaMalloc(&dCT,(size_t)N*(size_t)M*P*sizeof(int32_t)),\"dCT\");\n",
        "  int *dPr=nullptr; CUDA_OK(cudaMalloc(&dPr,P*sizeof(int)),\"dPr\");\n",
        "  CUDA_OK(cudaMemcpy(dPr,primes.data(),P*sizeof(int),cudaMemcpyHostToDevice),\"H2D primes\");\n",
        "\n",
        "  // pack configs\n",
        "  const int t=256;\n",
        "  int blocksA = (int)((AszI + t - 1)/t);\n",
        "  int blocksB = (int)((BszI + t - 1)/t);\n",
        "  size_t aStrideElems = AszI;\n",
        "  size_t bStrideElems = BszI;\n",
        "\n",
        "  // cuBLAS\n",
        "  cublasHandle_t h; CUBLAS_OK(cublasCreate(&h),\"create\");\n",
        "  CUBLAS_OK(cublasSetMathMode(h, CUBLAS_TENSOR_OP_MATH), \"set math\");\n",
        "\n",
        "  // GEMM Cᵗ = Bᵗ·Aᵗ (column-major)\n",
        "  const int m=N, n=M, k=K;\n",
        "  const int lda = m;   // rows of Aop (=N)\n",
        "  const int ldb = k;   // FIX: rows of Bop (=K)\n",
        "  const int ldc = m;   // rows of Cᵗ (=N)\n",
        "  const long long strideA = (long long)K * (long long)N;  // Aop batch stride (N×K)\n",
        "  const long long strideB = (long long)K * (long long)M;  // Bop batch stride (K×M)\n",
        "  const long long strideC = (long long)N * (long long)M;  // Cᵗ batch stride (N×M)\n",
        "  const int batchCount = P;\n",
        "  int32_t alpha=1, beta=0;\n",
        "\n",
        "  auto t0=clk::now(); int iters=0; double wall_ms=0.0;\n",
        "  do{\n",
        "    pack_mod_s8_strided<<<blocksA,t>>>(dAh,dA8,M,K,aStrideElems,dPr,P);\n",
        "    pack_mod_s8_strided<<<blocksB,t>>>(dBh,dB8,K,N,bStrideElems,dPr,P);\n",
        "    CUDA_OK(cudaGetLastError(),\"pack launch\");\n",
        "    CUDA_OK(cudaDeviceSynchronize(),\"pack sync\");\n",
        "\n",
        "    CUBLAS_OK(cublasGemmStridedBatchedEx(\n",
        "      h, CUBLAS_OP_N, CUBLAS_OP_N,\n",
        "      m,n,k,\n",
        "      &alpha,\n",
        "      dB8, CUDA_R_8I, lda, strideA,   // Aop = B (N×K)\n",
        "      dA8, CUDA_R_8I, ldb, strideB,   // Bop = A (K×M)  <<< ldb = K\n",
        "      &beta,\n",
        "      dCT, CUDA_R_32I, ldc, strideC,  // Cᵗ (N×M)\n",
        "      batchCount,\n",
        "      CUBLAS_COMPUTE_32I,\n",
        "      CUBLAS_GEMM_DEFAULT_TENSOR_OP\n",
        "    ), \"GemmStridedBatchedEx\");\n",
        "\n",
        "    CUDA_OK(cudaGetLastError(),\"post-GEMM\");\n",
        "    CUDA_OK(cudaDeviceSynchronize(),\"gemm sync\");\n",
        "\n",
        "    iters++;\n",
        "    wall_ms = chrono::duration<double,milli>(clk::now()-t0).count();\n",
        "  }while(wall_ms < a.ms_min);\n",
        "\n",
        "  // D2H + host remap Cᵗ(N×M col-major) → C(M×N row-major) + mod\n",
        "  vector<int32_t> CT_all((size_t)N*(size_t)M*P);\n",
        "  CUDA_OK(cudaMemcpy(CT_all.data(), dCT, CT_all.size()*sizeof(int32_t), cudaMemcpyDeviceToHost),\"D2H Cᵗ\");\n",
        "  vector<vector<int32_t>> Cmods(P); for(int pi=0;pi<P;++pi) Cmods[pi].assign(CszI,0);\n",
        "  for(int pi=0; pi<P; ++pi){\n",
        "    const int p=primes[pi]; const int32_t* src=&CT_all[(size_t)pi*(size_t)N*(size_t)M];\n",
        "    for(int i=0;i<M;i++) for(int j=0;j<N;j++){\n",
        "      size_t in  = (size_t)j + (size_t)i*(size_t)N; // Cᵗ col-major\n",
        "      size_t out = (size_t)i*(size_t)N + (size_t)j; // C row-major\n",
        "      int v = (int)src[in] % p; if(v<0)v+=p; Cmods[pi][out]=v;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  double secs=wall_ms/1000.0;\n",
        "  double logical=(double)M*N*K, modular=logical*(double)P;\n",
        "  uint64_t hcrt=0;\n",
        "  if(a.verify){\n",
        "    int Pn=(int)primes.size(); uint64_t Mprod=1; for(int i=0;i<Pn;i++) Mprod*=(uint64_t)primes[i];\n",
        "    if(a.cert_bound>0) printf(\"CRT certificate: Mprod=%llu  vs  2*bound=%llu  %s\\n\",\n",
        "      (unsigned long long)Mprod,(unsigned long long)(2ull*(uint64_t)a.cert_bound),\n",
        "      (Mprod>2ull*(uint64_t)a.cert_bound? \"(UNIQUE RECON OK)\":\"(INSUFFICIENT)\"));\n",
        "    hcrt = crt_hash(Cmods,M,N,a.recon_K,primes,a.cert_bound);\n",
        "  }\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [G010c_FIX5_CUBLAS_RNS_BATCH] M=%d N=%d K=%d primes=%d iters=%d time=%.2f ms\\n\",M,N,K,P,iters,wall_ms);\n",
        "  printf(\"  Logical MACs/s:        %.3f G-mac/s\\n\", (logical*iters)/secs/1e9);\n",
        "  printf(\"  Modular MACs/s:        %.3f G-mac/s   (× primes, batched)\\n\", (modular*iters)/secs/1e9);\n",
        "  printf(\"  dp4a-equiv inst/s:     %.3f G-inst/s  (~ modular/4)\\n\", ((modular*iters)/secs)/4.0/1e9);\n",
        "  if(hcrt) printf(\"  CRT (strided) hash:    0x%016llx\\n\", (unsigned long long)hcrt);\n",
        "  printf(\"  cuBLAS math mode:      TensorOp (GemmStridedBatchedEx)\\n\");\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  cublasDestroy(h);\n",
        "  cudaFree(dAh); cudaFree(dBh); cudaFree(dA8); cudaFree(dB8); cudaFree(dCT); cudaFree(dPr);\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# Build\n",
        "nvcc -O3 -std=c++17 -arch=sm_75 -lcublas -lineinfo g010c_fix5_cublas_int8_rns_batched.cu -o g010c_fix5_cublas_int8_rns_batched\n",
        "\n",
        "echo \"=== G010c_FIX5: quick (512^3, 5 primes, batched) ===\"\n",
        "./g010c_fix5_cublas_int8_rns_batched --M 512 --N 512 --K 512 --primes 5 --ms 280 --reconK 4096 --cert 128000000\n",
        "\n",
        "echo\n",
        "echo \"=== G010c_FIX5: big (1024x2048x1024, 9 primes, batched) ===\"\n",
        "./g010c_fix5_cublas_int8_rns_batched --M 1024 --N 1024 --K 2048 --primes 9 --ms 400 --reconK 8192 --cert 12800000000\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mfWrZFVAG11",
        "outputId": "65bcbfe4-7b98-4005-c028-12a11a0e9d19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== G010c_FIX5: quick (512^3, 5 primes, batched) ===\n",
            "CRT certificate: Mprod=17239698439  vs  2*bound=256000000  (UNIQUE RECON OK)\n",
            "CRT certificate: Mprod=17239698439  vs  2*bound=256000000  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G010c_FIX5_CUBLAS_RNS_BATCH] M=512 N=512 K=512 primes=5 iters=1574 time=280.11 ms\n",
            "  Logical MACs/s:        754.191 G-mac/s\n",
            "  Modular MACs/s:        3770.957 G-mac/s   (× primes, batched)\n",
            "  dp4a-equiv inst/s:     942.739 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0xbd3d31fa812bbf66\n",
            "  cuBLAS math mode:      TensorOp (GemmStridedBatchedEx)\n",
            "============================================================================\n",
            "\n",
            "=== G010c_FIX5: big (1024x2048x1024, 9 primes, batched) ===\n",
            "CRT certificate: Mprod=1247644544258044721  vs  2*bound=25600000000  (UNIQUE RECON OK)\n",
            "CRT certificate: Mprod=1247644544258044721  vs  2*bound=25600000000  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G010c_FIX5_CUBLAS_RNS_BATCH] M=1024 N=1024 K=2048 primes=9 iters=159 time=400.20 ms\n",
            "  Logical MACs/s:        853.203 G-mac/s\n",
            "  Modular MACs/s:        7678.831 G-mac/s   (× primes, batched)\n",
            "  dp4a-equiv inst/s:     1919.708 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x06c66daa1aee737f\n",
            "  cuBLAS math mode:      TensorOp (GemmStridedBatchedEx)\n",
            "============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# =============================================================================\n",
        "# █████████  MODULE G010d_PIPE :: cuBLAS INT8 RNS (2-stream pipe + groups) ████\n",
        "#   • Exact RNS int8 on Tensor Cores (T4, sm_75) using cublasGemmStridedBatchedEx\n",
        "#   • Two CUDA streams: PACK (residue int32→int8) overlapped with GEMM (TC)\n",
        "#   • Prime grouping (default --pg=3): launch smaller batched GEMMs for better TC\n",
        "#   • Ping-pong staging buffers for A8/B8; writes directly into final dCT_all\n",
        "#   • Row-major host; compute Cᵗ = Bᵗ·Aᵗ (column-major) as before (lda=N, ldb=K, ldc=N)\n",
        "#   • Loud meters + CRT strided uniqueness certificate\n",
        "#   • Drop-in: self-contained, safe to append anywhere in your monolith\n",
        "# =============================================================================\n",
        "\n",
        "cat > g010d_pipe_cublas_int8_rns_batched.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "using namespace std; using clk = chrono::high_resolution_clock;\n",
        "\n",
        "struct Args{\n",
        "  int M=1024,N=1024,K=2048,primes=9;\n",
        "  int ms_min=400, verify=1, recon_K=8192;\n",
        "  long long cert_bound=0;\n",
        "  unsigned seed=12345u;\n",
        "  int pg=3;                 // primes per batch group (try 2..4 on T4)\n",
        "};\n",
        "static void parse(int argc,char**argv,Args&a){\n",
        "  for(int i=1;i<argc;i++){\n",
        "    string s=argv[i]; auto need=[&]{ if(i+1>=argc){fprintf(stderr,\"Missing %s\\n\",s.c_str()); exit(1);} };\n",
        "    if(s==\"--M\"){need(); a.M=atoi(argv[++i]);}\n",
        "    else if(s==\"--N\"){need(); a.N=atoi(argv[++i]);}\n",
        "    else if(s==\"--K\"){need(); a.K=atoi(argv[++i]);}\n",
        "    else if(s==\"--primes\"){need(); a.primes=atoi(argv[++i]);}\n",
        "    else if(s==\"--ms\"){need(); a.ms_min=atoi(argv[++i]);}\n",
        "    else if(s==\"--seed\"){need(); a.seed=(unsigned)strtoul(argv[++i],nullptr,10);}\n",
        "    else if(s==\"--reconK\"){need(); a.recon_K=atoi(argv[++i]);}\n",
        "    else if(s==\"--cert\"){need(); a.cert_bound=atoll(argv[++i]);}\n",
        "    else if(s==\"--pg\"){need(); a.pg=atoi(argv[++i]);}\n",
        "    else if(s==\"--noverify\"){a.verify=0;}\n",
        "    else if(s==\"--verify\"){a.verify=1;}\n",
        "  }\n",
        "}\n",
        "\n",
        "static const int PRIMES_TBL[16]={127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53};\n",
        "\n",
        "static inline void CUDA_OK(cudaError_t e,const char*w){ if(e!=cudaSuccess){fprintf(stderr,\"CUDA ERROR @%s: %s\\n\",w,cudaGetErrorString(e)); exit(1);} }\n",
        "static inline void CUBLAS_OK(cublasStatus_t s,const char*w){ if(s!=CUBLAS_STATUS_SUCCESS){fprintf(stderr,\"CUBLAS ERROR @%s: %d\\n\",w,(int)s); exit(1);} }\n",
        "\n",
        "static inline uint64_t fnv1a64_append(uint64_t h,const void*p,size_t n){ const uint8_t*b=(const uint8_t*)p; const uint64_t P=1099511628211ull; for(size_t i=0;i<n;i++){ h^=b[i]; h*=P; } return h; }\n",
        "static uint64_t invmod_u64(uint64_t a,uint64_t mod){ int64_t t=0,n=1,r=(int64_t)mod,m=(int64_t)a; while(m){ int64_t q=r/m; int64_t T=n; n=t-q*n; t=T; int64_t R=m; m=r-q*m; r=R;} if(r>1) return 0; if(t<0) t+=mod; return (uint64_t)t; }\n",
        "\n",
        "static uint64_t crt_hash(const vector<vector<int32_t>>& Cmods,int M,int N,int reconK,const vector<int>&pr,long long cert){\n",
        "  int P=(int)pr.size(); uint64_t Mprod=1; for(int i=0;i<P;i++) Mprod*=(uint64_t)pr[i];\n",
        "  if(cert>0) printf(\"CRT certificate: Mprod=%llu  vs  2*bound=%llu  %s\\n\",\n",
        "    (unsigned long long)Mprod,(unsigned long long)(2ull*(uint64_t)cert),\n",
        "    (Mprod>2ull*(uint64_t)cert? \"(UNIQUE RECON OK)\":\"(INSUFFICIENT)\"));\n",
        "  vector<uint64_t> Mi(P), yi(P); uint64_t Mtot=1; for(int i=0;i<P;i++) Mtot*=(uint64_t)pr[i];\n",
        "  for(int i=0;i<P;i++){ Mi[i]=Mtot/(uint64_t)pr[i]; yi[i]=invmod_u64(Mi[i]%pr[i],pr[i]); }\n",
        "  const size_t total=(size_t)M*(size_t)N; const int K=min((int)reconK,(int)total);\n",
        "  size_t stride=(size_t)11400714819323198485ull % max<size_t>(1,total);\n",
        "  size_t idx=0; uint64_t h=0;\n",
        "  for(int t=0;t<K;++t){ uint64_t x=0; for(int i=0;i<P;i++){ uint64_t ai=((uint64_t)Cmods[i][idx]%pr[i]+pr[i])%pr[i];\n",
        "    x=(x + ai*Mi[i]%Mtot*yi[i]%Mtot)%Mtot; } h=fnv1a64_append(h,&x,sizeof(x)); idx+=stride; if(idx>=total) idx-=total; }\n",
        "  return h;\n",
        "}\n",
        "\n",
        "// int32 -> int8 residues for a GROUP of primes (contiguous planes), with striding\n",
        "__global__ void pack_group_s8(const int32_t* __restrict__ X, int8_t* __restrict__ Y,\n",
        "                              size_t elems, const int* __restrict__ primes,\n",
        "                              int base_pi, int G, size_t strideY)\n",
        "{\n",
        "  size_t t = (size_t)blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if(t >= elems) return;\n",
        "  int x = X[t];\n",
        "  #pragma unroll 1\n",
        "  for(int g=0; g<G; ++g){\n",
        "    int p = primes[base_pi+g];\n",
        "    int v = x % p; if(v<0) v+=p; if(v>p/2) v-=p; // balanced for dp4a symmetry\n",
        "    Y[(size_t)g*strideY + t] = (int8_t)v;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc,char**argv){\n",
        "  ios::sync_with_stdio(false); cin.tie(nullptr);\n",
        "  Args a; parse(argc,argv,a);\n",
        "  const int P = max(1,min(a.primes,(int)(sizeof(PRIMES_TBL)/sizeof(PRIMES_TBL[0]))));\n",
        "  const int PG = max(1,min(a.pg,P));\n",
        "  vector<int> primes(P); for(int i=0;i<P;i++) primes[i]=PRIMES_TBL[i];\n",
        "\n",
        "  const int M=a.M,N=a.N,K=a.K;\n",
        "  const size_t AszI=(size_t)M*(size_t)K, BszI=(size_t)K*(size_t)N, CszI=(size_t)M*(size_t)N;\n",
        "\n",
        "  // host sources\n",
        "  vector<int32_t> Ah(AszI), Bh(BszI);\n",
        "  mt19937 rng(a.seed); uniform_int_distribution<int>d(-700,700);\n",
        "  for(auto&x:Ah) x=d(rng); for(auto&x:Bh) x=d(rng);\n",
        "\n",
        "  // device primelist\n",
        "  int *dPr=nullptr; CUDA_OK(cudaMalloc(&dPr,P*sizeof(int)),\"dPr\");\n",
        "  CUDA_OK(cudaMemcpy(dPr,primes.data(),P*sizeof(int),cudaMemcpyHostToDevice),\"H2D primes\");\n",
        "\n",
        "  // device int32 sources\n",
        "  int32_t *dAh=nullptr,*dBh=nullptr;\n",
        "  CUDA_OK(cudaMalloc(&dAh, AszI*sizeof(int32_t)),\"dAh\");\n",
        "  CUDA_OK(cudaMalloc(&dBh, BszI*sizeof(int32_t)),\"dBh\");\n",
        "  CUDA_OK(cudaMemcpy(dAh,Ah.data(),AszI*sizeof(int32_t),cudaMemcpyHostToDevice),\"H2D Ah\");\n",
        "  CUDA_OK(cudaMemcpy(dBh,Bh.data(),BszI*sizeof(int32_t),cudaMemcpyHostToDevice),\"H2D Bh\");\n",
        "\n",
        "  // ping-pong staging for packed residues\n",
        "  int8_t *dA8[2]={nullptr,nullptr}, *dB8[2]={nullptr,nullptr};\n",
        "  for(int i=0;i<2;i++){\n",
        "    CUDA_OK(cudaMalloc(&dA8[i], AszI*PG*sizeof(int8_t)), \"A8 buf\");\n",
        "    CUDA_OK(cudaMalloc(&dB8[i], BszI*PG*sizeof(int8_t)), \"B8 buf\");\n",
        "  }\n",
        "  // final output Cᵗ for all primes (column-major N×M per batch plane)\n",
        "  int32_t *dCT_all=nullptr;\n",
        "  CUDA_OK(cudaMalloc(&dCT_all, (size_t)N*(size_t)M*P*sizeof(int32_t)), \"dCT_all\");\n",
        "\n",
        "  // cuBLAS handle + streams\n",
        "  cublasHandle_t h; CUBLAS_OK(cublasCreate(&h),\"create\");\n",
        "  CUBLAS_OK(cublasSetMathMode(h, CUBLAS_TENSOR_OP_MATH), \"set math\");\n",
        "  cudaStream_t s_pack, s_gemm; CUDA_OK(cudaStreamCreateWithFlags(&s_pack,cudaStreamNonBlocking),\"s_pack\");\n",
        "  CUDA_OK(cudaStreamCreateWithFlags(&s_gemm,cudaStreamNonBlocking),\"s_gemm\");\n",
        "  cublasSetStream(h, s_gemm);\n",
        "  cudaEvent_t ev_pp[2]; CUDA_OK(cudaEventCreateWithFlags(&ev_pp[0], cudaEventDisableTiming),\"ev0\");\n",
        "  CUDA_OK(cudaEventCreateWithFlags(&ev_pp[1], cudaEventDisableTiming),\"ev1\");\n",
        "\n",
        "  // GEMM params: Cᵗ = Bᵗ·Aᵗ\n",
        "  const int m=N, n=M, k=K;\n",
        "  const int lda = m;                // rows of Aop (=N)\n",
        "  const int ldb = k;                // rows of Bop (=K)  **critical**\n",
        "  const int ldc = m;                // rows of Cᵗ (=N)\n",
        "  const long long strideA_plane = (long long)K * (long long)N; // N×K\n",
        "  const long long strideB_plane = (long long)K * (long long)M; // K×M\n",
        "  const long long strideC_plane = (long long)N * (long long)M; // N×M\n",
        "  const int tpb=256;\n",
        "  const int blocksA=(int)((AszI + tpb - 1)/tpb);\n",
        "  const int blocksB=(int)((BszI + tpb - 1)/tpb);\n",
        "\n",
        "  auto t0=clk::now(); int iters=0; double wall_ms=0.0;\n",
        "  do{\n",
        "    int buf=0;\n",
        "    for(int base=0; base<P; base+=PG, buf^=1){\n",
        "      const int G = min(PG, P-base);\n",
        "      // PACK group -> ping-pong buffer on s_pack\n",
        "      pack_group_s8<<<blocksA,tpb,0,s_pack>>>(dAh, dA8[buf], AszI, dPr, base, G, AszI);\n",
        "      pack_group_s8<<<blocksB,tpb,0,s_pack>>>(dBh, dB8[buf], BszI, dPr, base, G, BszI);\n",
        "      CUDA_OK(cudaGetLastError(),\"pack_group launch\");\n",
        "      CUDA_OK(cudaEventRecord(ev_pp[buf], s_pack),\"record ev\");\n",
        "\n",
        "      // When previous buffer ready, launch GEMM to final offsets\n",
        "      if(base>0){\n",
        "        int prev_base = base - PG;\n",
        "        int prev_G = min(PG, P - prev_base);\n",
        "        int use = 1-buf;\n",
        "        CUDA_OK(cudaStreamWaitEvent(s_gemm, ev_pp[use], 0), \"gemm wait\");\n",
        "        // destination offset for this group in Cᵗ slab\n",
        "        int32_t* dCT = dCT_all + (size_t)prev_base * (size_t)strideC_plane;\n",
        "        int32_t alpha=1, beta=0;\n",
        "        CUBLAS_OK(cublasGemmStridedBatchedEx(\n",
        "          h, CUBLAS_OP_N, CUBLAS_OP_N,\n",
        "          m, n, k,\n",
        "          &alpha,\n",
        "          dB8[use], CUDA_R_8I, lda, strideA_plane,   // Aop = B\n",
        "          dA8[use], CUDA_R_8I, ldb, strideB_plane,   // Bop = A\n",
        "          &beta,\n",
        "          dCT,  CUDA_R_32I, ldc, strideC_plane,     // Cᵗ destination window\n",
        "          prev_G,\n",
        "          CUBLAS_COMPUTE_32I,\n",
        "          CUBLAS_GEMM_DEFAULT_TENSOR_OP\n",
        "        ), \"GemmStridedBatchedEx\");\n",
        "      }\n",
        "    }\n",
        "    // flush last packed group\n",
        "    {\n",
        "      int tail_base = ((P-1)/PG)*PG;\n",
        "      int tail_G = min(PG, P-tail_base);\n",
        "      int use = ((P/PG)%2==0)? 1:0; // inverse of last buf toggle after loop\n",
        "      CUDA_OK(cudaStreamWaitEvent(s_gemm, ev_pp[use], 0), \"tail wait\");\n",
        "      int32_t* dCT = dCT_all + (size_t)tail_base * (size_t)strideC_plane;\n",
        "      int32_t alpha=1, beta=0;\n",
        "      CUBLAS_OK(cublasGemmStridedBatchedEx(\n",
        "        h, CUBLAS_OP_N, CUBLAS_OP_N,\n",
        "        m, n, k,\n",
        "        &alpha,\n",
        "        dB8[use], CUDA_R_8I, lda, strideA_plane,\n",
        "        dA8[use], CUDA_R_8I, ldb, strideB_plane,\n",
        "        &beta,\n",
        "        dCT,  CUDA_R_32I, ldc, strideC_plane,\n",
        "        tail_G,\n",
        "        CUBLAS_COMPUTE_32I,\n",
        "        CUBLAS_GEMM_DEFAULT_TENSOR_OP\n",
        "      ), \"GemmStridedBatchedEx tail\");\n",
        "    }\n",
        "\n",
        "    CUDA_OK(cudaStreamSynchronize(s_gemm),\"gemm sync\");\n",
        "    iters++;\n",
        "    wall_ms = chrono::duration<double,milli>(clk::now()-t0).count();\n",
        "  }while(wall_ms < a.ms_min);\n",
        "\n",
        "  // D2H and reduce (Cᵗ → C row-major) + mod-p per prime\n",
        "  vector<int32_t> CT_all((size_t)N*(size_t)M*P);\n",
        "  CUDA_OK(cudaMemcpy(CT_all.data(), dCT_all, CT_all.size()*sizeof(int32_t), cudaMemcpyDeviceToHost),\"D2H Cᵗ\");\n",
        "  vector<vector<int32_t>> Cmods(P); for(int pi=0;pi<P; ++pi) Cmods[pi].assign(CszI,0);\n",
        "  for(int pi=0; pi<P; ++pi){\n",
        "    const int p=primes[pi];\n",
        "    const int32_t* src=&CT_all[(size_t)pi*(size_t)N*(size_t)M];\n",
        "    for(int i=0;i<M;i++) for(int j=0;j<N;j++){\n",
        "      size_t in  = (size_t)j + (size_t)i*(size_t)N; // Cᵗ col-major\n",
        "      size_t out = (size_t)i*(size_t)N + (size_t)j; // C row-major\n",
        "      int v = (int)src[in] % p; if(v<0) v+=p; Cmods[pi][out]=v;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // meters\n",
        "  double secs = wall_ms/1000.0;\n",
        "  double logical = (double)M*N*K;\n",
        "  double modular = logical * (double)P;\n",
        "\n",
        "  uint64_t hcrt=0;\n",
        "  if(a.verify){\n",
        "    printf(\"CRT certificate: Mprod=\"); // two-line print to mirror your style\n",
        "    uint64_t Mprod=1; for(int i=0;i<P;i++) Mprod*=(uint64_t)primes[i];\n",
        "    printf(\"%llu  vs  2*bound=%llu  %s\\n\",\n",
        "      (unsigned long long)Mprod,(unsigned long long)(2ull*(uint64_t)a.cert_bound),\n",
        "      (a.cert_bound>0 && Mprod>2ull*(uint64_t)a.cert_bound)? \"(UNIQUE RECON OK)\":\"(INSUFFICIENT)\");\n",
        "    hcrt = crt_hash(Cmods,M,N,a.recon_K,primes,a.cert_bound);\n",
        "  }\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [G010d_PIPE_CUBLAS_RNS] M=%d N=%d K=%d primes=%d pg=%d iters=%d time=%.2f ms\\n\",\n",
        "         M,N,K,P,PG,iters,wall_ms);\n",
        "  printf(\"  Logical MACs/s:        %.3f G-mac/s\\n\",  (logical*iters)/secs/1e9);\n",
        "  printf(\"  Modular MACs/s:        %.3f G-mac/s   (× primes, pipelined)\\n\", (modular*iters)/secs/1e9);\n",
        "  printf(\"  dp4a-equiv inst/s:     %.3f G-inst/s  (~ modular/4)\\n\", ((modular*iters)/secs)/4.0/1e9);\n",
        "  if(hcrt) printf(\"  CRT (strided) hash:    0x%016llx\\n\", (unsigned long long)hcrt);\n",
        "  printf(\"  PIPE: streams(pack+gemm)=YES, pingpong=YES, group=%d\\n\", PG);\n",
        "  printf(\"  cuBLAS math mode:      TensorOp (GemmStridedBatchedEx)\\n\");\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  // cleanup\n",
        "  cublasDestroy(h);\n",
        "  cudaEventDestroy(ev_pp[0]); cudaEventDestroy(ev_pp[1]);\n",
        "  cudaStreamDestroy(s_pack); cudaStreamDestroy(s_gemm);\n",
        "  for(int i=0;i<2;i++){ cudaFree(dA8[i]); cudaFree(dB8[i]); }\n",
        "  cudaFree(dAh); cudaFree(dBh); cudaFree(dCT_all); cudaFree(dPr);\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# Build\n",
        "nvcc -O3 -std=c++17 -arch=sm_75 -lcublas -lineinfo g010d_pipe_cublas_int8_rns_batched.cu -o g010d_pipe_cublas_int8_rns_batched\n",
        "\n",
        "echo \"=== G010d_PIPE: quick (512^3, 5 primes, pg=3) ===\"\n",
        "./g010d_pipe_cublas_int8_rns_batched --M 512 --N 512 --K 512 --primes 5 --ms 280 --reconK 4096 --cert 256000000 --pg 3\n",
        "\n",
        "echo\n",
        "echo \"=== G010d_PIPE: big (1024x2048x1024, 9 primes, pg=3) ===\"\n",
        "./g010d_pipe_cublas_int8_rns_batched --M 1024 --N 1024 --K 2048 --primes 9 --ms 400 --reconK 8192 --cert 25600000000 --pg 3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as_hPR6yAln4",
        "outputId": "6ef6adec-0c7a-44cd-b63b-af5c82ecef68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== G010d_PIPE: quick (512^3, 5 primes, pg=3) ===\n",
            "CRT certificate: Mprod=17239698439  vs  2*bound=512000000  (UNIQUE RECON OK)\n",
            "CRT certificate: Mprod=17239698439  vs  2*bound=512000000  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G010d_PIPE_CUBLAS_RNS] M=512 N=512 K=512 primes=5 pg=3 iters=961 time=280.10 ms\n",
            "  Logical MACs/s:        460.487 G-mac/s\n",
            "  Modular MACs/s:        2302.433 G-mac/s   (× primes, pipelined)\n",
            "  dp4a-equiv inst/s:     575.608 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x9f285cb069b73442\n",
            "  PIPE: streams(pack+gemm)=YES, pingpong=YES, group=3\n",
            "  cuBLAS math mode:      TensorOp (GemmStridedBatchedEx)\n",
            "============================================================================\n",
            "\n",
            "=== G010d_PIPE: big (1024x2048x1024, 9 primes, pg=3) ===\n",
            "CRT certificate: Mprod=1247644544258044721  vs  2*bound=51200000000  (UNIQUE RECON OK)\n",
            "CRT certificate: Mprod=1247644544258044721  vs  2*bound=51200000000  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G010d_PIPE_CUBLAS_RNS] M=1024 N=1024 K=2048 primes=9 pg=3 iters=144 time=401.40 ms\n",
            "  Logical MACs/s:        770.398 G-mac/s\n",
            "  Modular MACs/s:        6933.581 G-mac/s   (× primes, pipelined)\n",
            "  dp4a-equiv inst/s:     1733.395 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x06c66daa1aee737f\n",
            "  PIPE: streams(pack+gemm)=YES, pingpong=YES, group=3\n",
            "  cuBLAS math mode:      TensorOp (GemmStridedBatchedEx)\n",
            "============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# =============================================================================\n",
        "# █████████  MODULE G010e_PIPE_VPACK :: cuBLAS INT8 RNS (vec-pack + tuner) ████\n",
        "#   • Exact RNS int8 on Tensor Cores (T4, sm_75) via cublasGemmStridedBatchedEx\n",
        "#   • Two CUDA streams (PACK + GEMM) with ping-pong staging (like G010d)\n",
        "#   • NEW: 4-wide vectorized residue packer (int32→int8) with coalesced stores\n",
        "#   • NEW: tiny autotuner over (--pg in {2,3,4}, --tpb in {256,512})\n",
        "#   • Writes directly into final Cᵗ slab; host folds Cᵗ→C and mod-reduces\n",
        "#   • Loud meters + CRT strided certificate\n",
        "# =============================================================================\n",
        "\n",
        "cat > g010e_pipe_vpack_cublas_int8_rns_batched.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "using namespace std; using clk = chrono::high_resolution_clock;\n",
        "\n",
        "struct Args{\n",
        "  int M=1024,N=1024,K=2048,primes=9;\n",
        "  int ms_min=400, verify=1, recon_K=8192;\n",
        "  long long cert_bound=0;\n",
        "  unsigned seed=12345u;\n",
        "  int pg=3;               // primes per group (2..4 on T4 are sweet spots)\n",
        "  int tpb=256;            // threads per block for pack kernels (256 or 512)\n",
        "  int autotune=0;         // 1 => sweep (pg,tpb) and pick best\n",
        "};\n",
        "static void parse(int argc,char**argv,Args&a){\n",
        "  for(int i=1;i<argc;i++){\n",
        "    string s=argv[i]; auto need=[&]{ if(i+1>=argc){ fprintf(stderr,\"Missing %s\\n\",s.c_str()); exit(1);} };\n",
        "    if(s==\"--M\"){need(); a.M=atoi(argv[++i]);}\n",
        "    else if(s==\"--N\"){need(); a.N=atoi(argv[++i]);}\n",
        "    else if(s==\"--K\"){need(); a.K=atoi(argv[++i]);}\n",
        "    else if(s==\"--primes\"){need(); a.primes=atoi(argv[++i]);}\n",
        "    else if(s==\"--ms\"){need(); a.ms_min=atoi(argv[++i]);}\n",
        "    else if(s==\"--seed\"){need(); a.seed=(unsigned)strtoul(argv[++i],nullptr,10);}\n",
        "    else if(s==\"--reconK\"){need(); a.recon_K=atoi(argv[++i]);}\n",
        "    else if(s==\"--cert\"){need(); a.cert_bound=atoll(argv[++i]);}\n",
        "    else if(s==\"--pg\"){need(); a.pg=atoi(argv[++i]);}\n",
        "    else if(s==\"--tpb\"){need(); a.tpb=atoi(argv[++i]);}\n",
        "    else if(s==\"--autotune\"){a.autotune=1;}\n",
        "    else if(s==\"--verify\"){a.verify=1;}\n",
        "    else if(s==\"--noverify\"){a.verify=0;}\n",
        "  }\n",
        "}\n",
        "\n",
        "static const int PRIMES_TBL[16]={127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53};\n",
        "\n",
        "static inline void CUDA_OK(cudaError_t e,const char*w){ if(e!=cudaSuccess){ fprintf(stderr,\"CUDA ERROR @%s: %s\\n\", w, cudaGetErrorString(e)); exit(1);} }\n",
        "static inline void CUBLAS_OK(cublasStatus_t s,const char*w){ if(s!=CUBLAS_STATUS_SUCCESS){ fprintf(stderr,\"CUBLAS ERROR @%s: %d\\n\", w, (int)s); exit(1);} }\n",
        "\n",
        "static inline uint64_t fnv1a64_append(uint64_t h,const void*p,size_t n){ const uint8_t*b=(const uint8_t*)p; const uint64_t P=1099511628211ull; for(size_t i=0;i<n;i++){ h^=b[i]; h*=P; } return h; }\n",
        "static uint64_t invmod_u64(uint64_t a,uint64_t mod){ int64_t t=0,n=1,r=(int64_t)mod,m=(int64_t)a; while(m){ int64_t q=r/m; int64_t T=n; n=t-q*n; t=T; int64_t R=m; m=r-q*m; r=R;} if(r>1) return 0; if(t<0) t+=mod; return (uint64_t)t; }\n",
        "\n",
        "static uint64_t crt_hash(const vector<vector<int32_t>>& Cmods,int M,int N,int reconK,const vector<int>&pr,long long cert){\n",
        "  int P=(int)pr.size(); uint64_t Mprod=1; for(int i=0;i<P;i++) Mprod*=(uint64_t)pr[i];\n",
        "  if(cert>0) printf(\"CRT certificate: Mprod=%llu  vs  2*bound=%llu  %s\\n\",\n",
        "    (unsigned long long)Mprod,(unsigned long long)(2ull*(uint64_t)cert),\n",
        "    (Mprod>2ull*(uint64_t)cert? \"(UNIQUE RECON OK)\":\"(INSUFFICIENT)\"));\n",
        "  vector<uint64_t> Mi(P), yi(P); uint64_t Mtot=1; for(int i=0;i<P;i++) Mtot*=(uint64_t)pr[i];\n",
        "  for(int i=0;i<P;i++){ Mi[i]=Mtot/(uint64_t)pr[i]; yi[i]=invmod_u64(Mi[i]%pr[i],pr[i]); }\n",
        "  const size_t total=(size_t)M*(size_t)N; const int K=min((int)reconK,(int)total);\n",
        "  size_t stride=(size_t)11400714819323198485ull % max<size_t>(1,total);\n",
        "  size_t idx=0; uint64_t h=0;\n",
        "  for(int t=0;t<K;++t){ uint64_t x=0; for(int i=0;i<P;i++){ uint64_t ai=((uint64_t)Cmods[i][idx]%pr[i]+pr[i])%pr[i];\n",
        "    x=(x + ai*Mi[i]%Mtot*yi[i]%Mtot)%Mtot; } h=fnv1a64_append(h,&x,sizeof(x)); idx+=stride; if(idx>=total) idx-=total; }\n",
        "  return h;\n",
        "}\n",
        "\n",
        "// ----- vectorized residue pack (4 elements/thread) -----\n",
        "// X: int32[M*K] or [K*N]; Y: int8 [G planes][elems], plane stride = elems\n",
        "// We process t4 = thread handles 4 consecutive elements to enable int2/char4 IO.\n",
        "__global__ void pack_group_s8_vec4(const int32_t* __restrict__ X, int8_t* __restrict__ Y,\n",
        "                                   size_t elems, const int* __restrict__ primes,\n",
        "                                   int base_pi, int G, size_t strideY)\n",
        "{\n",
        "  size_t t4 = (size_t)blockIdx.x * blockDim.x + threadIdx.x; t4 *= 4;\n",
        "  if(t4 >= elems) return;\n",
        "  // load 4 int32 scalars (aligned since X is cudaMalloc'ed)\n",
        "  int v0 = X[t4+0];\n",
        "  int v1 = (t4+1<elems)? X[t4+1]:0;\n",
        "  int v2 = (t4+2<elems)? X[t4+2]:0;\n",
        "  int v3 = (t4+3<elems)? X[t4+3]:0;\n",
        "\n",
        "  #pragma unroll 1\n",
        "  for(int g=0; g<G; ++g){\n",
        "    const int p = primes[base_pi+g];\n",
        "    int8_t o0 = (int8_t)((v0%p + p)%p); if(o0>p/2) o0-=p;\n",
        "    int8_t o1 = (int8_t)((v1%p + p)%p); if(o1>p/2) o1-=p;\n",
        "    int8_t o2 = (int8_t)((v2%p + p)%p); if(o2>p/2) o2-=p;\n",
        "    int8_t o3 = (int8_t)((v3%p + p)%p); if(o3>p/2) o3-=p;\n",
        "    size_t base = (size_t)g*strideY + t4;\n",
        "    if(t4+3 < elems){\n",
        "      // coalesced 16B store across threads (char4)\n",
        "      reinterpret_cast<char4*>(Y + (size_t)g*strideY)[t4/4] = make_char4(o0,o1,o2,o3);\n",
        "    }else{\n",
        "      if(t4+0<elems) Y[base+0]=o0;\n",
        "      if(t4+1<elems) Y[base+1]=o1;\n",
        "      if(t4+2<elems) Y[base+2]=o2;\n",
        "      if(t4+3<elems) Y[base+3]=o3;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "struct RunCfg { int pg; int tpb; double modular_gmac_s; double ms; int iters; };\n",
        "\n",
        "static RunCfg run_once(int M,int N,int K,int P,const vector<int>&pr, int ms_min, int reconK, long long cert_bound,\n",
        "                       unsigned seed, int pg, int tpb, int verify)\n",
        "{\n",
        "  const size_t Asz=(size_t)M*(size_t)K, Bsz=(size_t)K*(size_t)N, Csz=(size_t)M*(size_t)N;\n",
        "  // host sources\n",
        "  vector<int32_t> Ah(Asz), Bh(Bsz); mt19937 rng(seed); uniform_int_distribution<int>d(-700,700);\n",
        "  for(auto&x:Ah) x=d(rng); for(auto&x:Bh) x=d(rng);\n",
        "\n",
        "  // device primelist and sources\n",
        "  int *dPr=nullptr; CUDA_OK(cudaMalloc(&dPr,P*sizeof(int)),\"dPr\");\n",
        "  CUDA_OK(cudaMemcpy(dPr,pr.data(),P*sizeof(int),cudaMemcpyHostToDevice),\"H2D primes\");\n",
        "  int32_t *dAh=nullptr,*dBh=nullptr;\n",
        "  CUDA_OK(cudaMalloc(&dAh, Asz*sizeof(int32_t)),\"dAh\");\n",
        "  CUDA_OK(cudaMalloc(&dBh, Bsz*sizeof(int32_t)),\"dBh\");\n",
        "  CUDA_OK(cudaMemcpy(dAh,Ah.data(),Asz*sizeof(int32_t),cudaMemcpyHostToDevice),\"H2D Ah\");\n",
        "  CUDA_OK(cudaMemcpy(dBh,Bh.data(),Bsz*sizeof(int32_t),cudaMemcpyHostToDevice),\"H2D Bh\");\n",
        "\n",
        "  // ping-pong packed buffers\n",
        "  int8_t *dA8[2]={nullptr,nullptr}, *dB8[2]={nullptr,nullptr};\n",
        "  const int PG = max(1,min(pg,P));\n",
        "  for(int i=0;i<2;i++){ CUDA_OK(cudaMalloc(&dA8[i], Asz*PG*sizeof(int8_t)),\"A8\"); CUDA_OK(cudaMalloc(&dB8[i], Bsz*PG*sizeof(int8_t)),\"B8\"); }\n",
        "  // final Cᵗ slab\n",
        "  int32_t *dCT=nullptr; CUDA_OK(cudaMalloc(&dCT, (size_t)N*(size_t)M*P*sizeof(int32_t)),\"dCT\");\n",
        "\n",
        "  // cuBLAS + streams\n",
        "  cublasHandle_t h; CUBLAS_OK(cublasCreate(&h),\"create\");\n",
        "  CUBLAS_OK(cublasSetMathMode(h, CUBLAS_TENSOR_OP_MATH), \"math\");\n",
        "  cudaStream_t sp, sg; CUDA_OK(cudaStreamCreateWithFlags(&sp,cudaStreamNonBlocking),\"sp\");\n",
        "  CUDA_OK(cudaStreamCreateWithFlags(&sg,cudaStreamNonBlocking),\"sg\");\n",
        "  cublasSetStream(h, sg);\n",
        "  cudaEvent_t ev[2]; CUDA_OK(cudaEventCreateWithFlags(&ev[0],cudaEventDisableTiming),\"ev0\");\n",
        "  CUDA_OK(cudaEventCreateWithFlags(&ev[1],cudaEventDisableTiming),\"ev1\");\n",
        "\n",
        "  // GEMM params: Cᵗ = Bᵗ·Aᵗ\n",
        "  const int m=N, n=M, k=K; const int lda=m, ldb=k, ldc=m;\n",
        "  const long long sA = (long long)K*(long long)N; // N×K\n",
        "  const long long sB = (long long)K*(long long)M; // K×M\n",
        "  const long long sC = (long long)N*(long long)M; // N×M\n",
        "\n",
        "  // pack launch dims (vec4)\n",
        "  const int tpb_vec = tpb;\n",
        "  const int blocksA = (int)(((Asz + 3)/4 + tpb_vec - 1)/tpb_vec);\n",
        "  const int blocksB = (int)(((Bsz + 3)/4 + tpb_vec - 1)/tpb_vec);\n",
        "\n",
        "  auto t0=clk::now(); int iters=0; double wall_ms=0.0;\n",
        "  do{\n",
        "    int buf=0;\n",
        "    for(int base=0; base<P; base+=PG, buf^=1){\n",
        "      const int G=min(PG,P-base);\n",
        "      pack_group_s8_vec4<<<blocksA,tpb_vec,0,sp>>>(dAh, dA8[buf], Asz, dPr, base, G, Asz);\n",
        "      pack_group_s8_vec4<<<blocksB,tpb_vec,0,sp>>>(dBh, dB8[buf], Bsz, dPr, base, G, Bsz);\n",
        "      CUDA_OK(cudaGetLastError(),\"pack launch\");\n",
        "      CUDA_OK(cudaEventRecord(ev[buf], sp), \"ev record\");\n",
        "      if(base>0){\n",
        "        int prev_base=base-PG, use=1-buf, prev_G=min(PG,P-prev_base);\n",
        "        CUDA_OK(cudaStreamWaitEvent(sg, ev[use], 0),\"wait\");\n",
        "        int32_t* dst = dCT + (size_t)prev_base * (size_t)sC;\n",
        "        int32_t alpha=1,beta=0;\n",
        "        CUBLAS_OK(cublasGemmStridedBatchedEx(\n",
        "          h, CUBLAS_OP_N, CUBLAS_OP_N,\n",
        "          m,n,k,\n",
        "          &alpha,\n",
        "          dB8[use], CUDA_R_8I, lda, sA,\n",
        "          dA8[use], CUDA_R_8I, ldb, sB,\n",
        "          &beta,\n",
        "          dst,     CUDA_R_32I, ldc, sC,\n",
        "          prev_G,\n",
        "          CUBLAS_COMPUTE_32I,\n",
        "          CUBLAS_GEMM_DEFAULT_TENSOR_OP\n",
        "        ), \"gemm\");\n",
        "      }\n",
        "    }\n",
        "    // tail\n",
        "    { int tail_base=((P-1)/PG)*PG; int tail_G=min(PG,P-tail_base);\n",
        "      int use=((P/PG)%2==0)?1:0;\n",
        "      CUDA_OK(cudaStreamWaitEvent(sg, ev[use], 0),\"tail wait\");\n",
        "      int32_t* dst = dCT + (size_t)tail_base * (size_t)sC;\n",
        "      int32_t alpha=1,beta=0;\n",
        "      CUBLAS_OK(cublasGemmStridedBatchedEx(\n",
        "        h, CUBLAS_OP_N, CUBLAS_OP_N,\n",
        "        m,n,k,\n",
        "        &alpha,\n",
        "        dB8[use], CUDA_R_8I, lda, sA,\n",
        "        dA8[use], CUDA_R_8I, ldb, sB,\n",
        "        &beta,\n",
        "        dst,     CUDA_R_32I, ldc, sC,\n",
        "        tail_G,\n",
        "        CUBLAS_COMPUTE_32I,\n",
        "        CUBLAS_GEMM_DEFAULT_TENSOR_OP\n",
        "      ), \"gemm tail\");\n",
        "    }\n",
        "    CUDA_OK(cudaStreamSynchronize(sg),\"sync\");\n",
        "    iters++; wall_ms = chrono::duration<double,milli>(clk::now()-t0).count();\n",
        "  }while(wall_ms < ms_min);\n",
        "\n",
        "  // D2H + fold and mod reduce for CRT/hash\n",
        "  vector<int32_t> CT((size_t)N*(size_t)M*P);\n",
        "  CUDA_OK(cudaMemcpy(CT.data(), dCT, CT.size()*sizeof(int32_t), cudaMemcpyDeviceToHost),\"D2H\");\n",
        "  vector<vector<int32_t>> Cmods(P); for(int pi=0;pi<P; ++pi) Cmods[pi].assign(Csz,0);\n",
        "  for(int pi=0;pi<P;++pi){\n",
        "    int p=pr[pi]; const int32_t* src=&CT[(size_t)pi*(size_t)N*(size_t)M];\n",
        "    for(int i=0;i<M;i++) for(int j=0;j<N;j++){\n",
        "      size_t in=(size_t)j + (size_t)i*(size_t)N; size_t out=(size_t)i*(size_t)N + (size_t)j;\n",
        "      int v=(int)src[in]%p; if(v<0) v+=p; Cmods[pi][out]=v;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  double secs=wall_ms/1000.0; double logical=(double)M*N*K; double modular=logical*P;\n",
        "  uint64_t hcrt=0; if(verify){ hcrt=crt_hash(Cmods,M,N,reconK,pr,cert_bound); }\n",
        "\n",
        "  printf(\"----------------------------------------------------------------------------\\n\");\n",
        "  printf(\"  PIPE_VPACK case: pg=%d tpb=%d | iters=%d  time=%.2f ms | Modular=%.3f  Logical=%.3f  dp4a=%.3f  hash=0x%016llx\\n\",\n",
        "         PG, tpb, iters, wall_ms, (modular*iters)/secs/1e9, (logical*iters)/secs/1e9, ((modular*iters)/secs)/4.0/1e9,\n",
        "         (unsigned long long)hcrt);\n",
        "\n",
        "  // result summary\n",
        "  RunCfg rc; rc.pg=PG; rc.tpb=tpb; rc.modular_gmac_s=(modular*iters)/secs/1e9; rc.ms=wall_ms; rc.iters=iters;\n",
        "\n",
        "  // cleanup\n",
        "  cublasDestroy(h); cudaEventDestroy(ev[0]); cudaEventDestroy(ev[1]);\n",
        "  cudaStreamDestroy(sp); cudaStreamDestroy(sg);\n",
        "  for(int i=0;i<2;i++){ cudaFree(dA8[i]); cudaFree(dB8[i]); }\n",
        "  cudaFree(dAh); cudaFree(dBh); cudaFree(dCT); cudaFree(dPr);\n",
        "  return rc;\n",
        "}\n",
        "\n",
        "int main(int argc,char**argv){\n",
        "  ios::sync_with_stdio(false); cin.tie(nullptr);\n",
        "  Args a; parse(argc,argv,a);\n",
        "  const int P=min(a.primes, (int)(sizeof(PRIMES_TBL)/sizeof(PRIMES_TBL[0])));\n",
        "  vector<int> primes(P); for(int i=0;i<P;i++) primes[i]=PRIMES_TBL[i];\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" PIPE_VPACK  M=%d N=%d K=%d primes=%d  ms_min=%d  seed=%u\\n\", a.M,a.N,a.K,P,a.ms_min,a.seed);\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  vector<pair<int,int>> cases;\n",
        "  if(a.autotune){\n",
        "    int pg_opts[3]={2,3,4}; int tpb_opts[2]={256,512};\n",
        "    for(int pg:pg_opts) for(int t:tpb_opts) if(pg<=P) cases.push_back({pg,t});\n",
        "  }else{\n",
        "    cases.push_back({max(1,min(a.pg,P)), (a.tpb==512?512:256)});\n",
        "  }\n",
        "\n",
        "  RunCfg best{0,0,0.0,0.0,0};\n",
        "  for(auto [pg,tpb]: cases){\n",
        "    RunCfg rc = run_once(a.M,a.N,a.K,P,primes,a.ms_min,a.recon_K,a.cert_bound,a.seed,pg,tpb,a.verify);\n",
        "    if(rc.modular_gmac_s > best.modular_gmac_s) best=rc;\n",
        "  }\n",
        "\n",
        "  printf(\"=== PIPE_VPACK BEST ===\\n\");\n",
        "  printf(\"  pg=%d  tpb=%d  | Modular=%.3f G-mac/s\\n\", best.pg, best.tpb, best.modular_gmac_s);\n",
        "  printf(\"  (Try: --autotune for your shapes; common wins: pg=2 or 3, tpb=512)\\n\");\n",
        "  printf(\"============================================================================\\n\");\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# Build\n",
        "nvcc -O3 -std=c++17 -arch=sm_75 -lcublas -lineinfo g010e_pipe_vpack_cublas_int8_rns_batched.cu -o g010e_pipe_vpack_cublas_int8_rns_batched\n",
        "\n",
        "echo \"=== G010e: quick (512^3, 5 primes) — autotune ===\"\n",
        "./g010e_pipe_vpack_cublas_int8_rns_batched --M 512 --N 512 --K 512 --primes 5 --ms 280 --reconK 4096 --cert 512000000 --autotune\n",
        "\n",
        "echo\n",
        "echo \"=== G010e: big (1024x2048x1024, 9 primes) — autotune ===\"\n",
        "./g010e_pipe_vpack_cublas_int8_rns_batched --M 1024 --N 1024 --K 2048 --primes 9 --ms 400 --reconK 8192 --cert 51200000000 --autotune\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Crh8n7mhOB8o",
        "outputId": "11e86346-81e9-4f6f-a269-a2e20569e7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== G010e: quick (512^3, 5 primes) — autotune ===\n",
            "============================================================================\n",
            " PIPE_VPACK  M=512 N=512 K=512 primes=5  ms_min=280  seed=12345\n",
            "============================================================================\n",
            "CRT certificate: Mprod=17239698439  vs  2*bound=1024000000  (UNIQUE RECON OK)\n",
            "----------------------------------------------------------------------------\n",
            "  PIPE_VPACK case: pg=2 tpb=256 | iters=762  time=280.01 ms | Modular=1826.279  Logical=365.256  dp4a=456.570  hash=0xca7e77973ad7612f\n",
            "CRT certificate: Mprod=17239698439  vs  2*bound=1024000000  (UNIQUE RECON OK)\n",
            "----------------------------------------------------------------------------\n",
            "  PIPE_VPACK case: pg=2 tpb=512 | iters=1439  time=280.16 ms | Modular=3446.959  Logical=689.392  dp4a=861.740  hash=0xfbc43cb40dbf0bfd\n",
            "CRT certificate: Mprod=17239698439  vs  2*bound=1024000000  (UNIQUE RECON OK)\n",
            "----------------------------------------------------------------------------\n",
            "  PIPE_VPACK case: pg=3 tpb=256 | iters=1692  time=280.02 ms | Modular=4054.986  Logical=810.997  dp4a=1013.746  hash=0x9f285cb069b73442\n",
            "CRT certificate: Mprod=17239698439  vs  2*bound=1024000000  (UNIQUE RECON OK)\n",
            "----------------------------------------------------------------------------\n",
            "  PIPE_VPACK case: pg=3 tpb=512 | iters=1721  time=280.31 ms | Modular=4120.276  Logical=824.055  dp4a=1030.069  hash=0x9f285cb069b73442\n",
            "CRT certificate: Mprod=17239698439  vs  2*bound=1024000000  (UNIQUE RECON OK)\n",
            "----------------------------------------------------------------------------\n",
            "  PIPE_VPACK case: pg=4 tpb=256 | iters=1349  time=280.12 ms | Modular=3231.879  Logical=646.376  dp4a=807.970  hash=0x59be39db89a5d61f\n",
            "CRT certificate: Mprod=17239698439  vs  2*bound=1024000000  (UNIQUE RECON OK)\n",
            "----------------------------------------------------------------------------\n",
            "  PIPE_VPACK case: pg=4 tpb=512 | iters=1717  time=280.11 ms | Modular=4113.631  Logical=822.726  dp4a=1028.408  hash=0x59be39db89a5d61f\n",
            "=== PIPE_VPACK BEST ===\n",
            "  pg=3  tpb=512  | Modular=4120.276 G-mac/s\n",
            "  (Try: --autotune for your shapes; common wins: pg=2 or 3, tpb=512)\n",
            "============================================================================\n",
            "\n",
            "=== G010e: big (1024x2048x1024, 9 primes) — autotune ===\n",
            "============================================================================\n",
            " PIPE_VPACK  M=1024 N=1024 K=2048 primes=9  ms_min=400  seed=12345\n",
            "============================================================================\n",
            "CRT certificate: Mprod=1247644544258044721  vs  2*bound=102400000000  (UNIQUE RECON OK)\n",
            "----------------------------------------------------------------------------\n",
            "  PIPE_VPACK case: pg=2 tpb=256 | iters=142  time=401.90 ms | Modular=6828.726  Logical=758.747  dp4a=1707.182  hash=0xe89ab573e96a00fd\n",
            "CRT certificate: Mprod=1247644544258044721  vs  2*bound=102400000000  (UNIQUE RECON OK)\n",
            "----------------------------------------------------------------------------\n",
            "  PIPE_VPACK case: pg=2 tpb=512 | iters=143  time=401.35 ms | Modular=6886.298  Logical=765.144  dp4a=1721.575  hash=0xe89ab573e96a00fd\n",
            "CRT certificate: Mprod=1247644544258044721  vs  2*bound=102400000000  (UNIQUE RECON OK)\n",
            "----------------------------------------------------------------------------\n",
            "  PIPE_VPACK case: pg=3 tpb=256 | iters=156  time=400.54 ms | Modular=7527.508  Logical=836.390  dp4a=1881.877  hash=0x06c66daa1aee737f\n",
            "CRT certificate: Mprod=1247644544258044721  vs  2*bound=102400000000  (UNIQUE RECON OK)\n",
            "----------------------------------------------------------------------------\n",
            "  PIPE_VPACK case: pg=3 tpb=512 | iters=155  time=402.04 ms | Modular=7451.311  Logical=827.923  dp4a=1862.828  hash=0x06c66daa1aee737f\n",
            "CRT certificate: Mprod=1247644544258044721  vs  2*bound=102400000000  (UNIQUE RECON OK)\n",
            "----------------------------------------------------------------------------\n",
            "  PIPE_VPACK case: pg=4 tpb=256 | iters=153  time=401.74 ms | Modular=7360.636  Logical=817.848  dp4a=1840.159  hash=0x92e6fa04634466cd\n",
            "CRT certificate: Mprod=1247644544258044721  vs  2*bound=102400000000  (UNIQUE RECON OK)\n",
            "----------------------------------------------------------------------------\n",
            "  PIPE_VPACK case: pg=4 tpb=512 | iters=153  time=402.55 ms | Modular=7345.943  Logical=816.216  dp4a=1836.486  hash=0x92e6fa04634466cd\n",
            "=== PIPE_VPACK BEST ===\n",
            "  pg=3  tpb=256  | Modular=7527.508 G-mac/s\n",
            "  (Try: --autotune for your shapes; common wins: pg=2 or 3, tpb=512)\n",
            "============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "cat > g010f_graph_fix4.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "using namespace std; using clk = chrono::high_resolution_clock;\n",
        "\n",
        "#define CUDA_OK(x,msg) do{ cudaError_t _e=(x); if(_e!=cudaSuccess){ \\\n",
        "  fprintf(stderr,\"CUDA ERROR @%s: %s\\n\", msg, cudaGetErrorString(_e)); exit(1);} }while(0)\n",
        "#define CUBLAS_OK(x,msg) do{ cublasStatus_t _s=(x); if(_s!=CUBLAS_STATUS_SUCCESS){ \\\n",
        "  fprintf(stderr,\"CUBLAS ERROR @%s: %d\\n\", msg, (int)_s); exit(1);} }while(0)\n",
        "\n",
        "static vector<int> primes_list(int P){\n",
        "  static const int all[] = {127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53,47,43,41,37,31,29,23,19,17,13,11,7,5,3};\n",
        "  int maxP = (int)(sizeof(all)/sizeof(all[0]));\n",
        "  P = max(1, min(P, maxP));\n",
        "  return vector<int>(all, all+P);\n",
        "}\n",
        "\n",
        "struct Args{\n",
        "  int M=1024,N=1024,K=2048,primes=9;\n",
        "  int ms_min=400, verify=1, recon_K=8192;\n",
        "  long long cert_bound=0; unsigned seed=12345u;\n",
        "  int pg=3; int tpb=512;\n",
        "};\n",
        "static void parse(int argc,char**argv,Args&a){\n",
        "  for(int i=1;i<argc;i++){\n",
        "    string s=argv[i]; auto need=[&]{ if(i+1>=argc){ fprintf(stderr,\"Missing %s\\n\", s.c_str()); exit(1);} };\n",
        "    if(s==\"--M\"){need();a.M=atoi(argv[++i]);}\n",
        "    else if(s==\"--N\"){need();a.N=atoi(argv[++i]);}\n",
        "    else if(s==\"--K\"){need();a.K=atoi(argv[++i]);}\n",
        "    else if(s==\"--primes\"){need();a.primes=atoi(argv[++i]);}\n",
        "    else if(s==\"--ms\"){need();a.ms_min=atoi(argv[++i]);}\n",
        "    else if(s==\"--seed\"){need();a.seed=(unsigned)strtoul(argv[++i],nullptr,10);}\n",
        "    else if(s==\"--pg\"){need();a.pg=atoi(argv[++i]);}\n",
        "    else if(s==\"--tpb\"){need();a.tpb=atoi(argv[++i]);}\n",
        "    else if(s==\"--verify\"){a.verify=1;}\n",
        "    else if(s==\"--noverify\"){a.verify=0;}\n",
        "    else if(s==\"--reconK\"){need();a.recon_K=atoi(argv[++i]);}\n",
        "    else if(s==\"--cert\"){need();a.cert_bound=atoll(argv[++i]);}\n",
        "  }\n",
        "}\n",
        "\n",
        "static void fill_rand_i32(vector<int32_t>&A,int R,int C,unsigned seed,int maxAbs=700){\n",
        "  mt19937 rng(seed); uniform_int_distribution<int>d(-maxAbs,maxAbs);\n",
        "  A.resize((size_t)R*C); for(auto &x:A) x = d(rng);\n",
        "}\n",
        "\n",
        "__device__ __forceinline__ int8_t mod_center_s8(int v, int p){\n",
        "  int r = v % p; if(r<0) r += p; int half = p>>1; return (r<=half)?(int8_t)r:(int8_t)(r-p);\n",
        "}\n",
        "__global__ void pack_group_A(const int32_t* __restrict__ A32, int8_t* __restrict__ A8,\n",
        "                             int M, int K, const int* __restrict__ primes,\n",
        "                             int base_g, int G, size_t Asz)\n",
        "{\n",
        "  size_t tid = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  size_t total = (size_t)G * (size_t)M * (size_t)K;\n",
        "  for(size_t t=tid; t<total; t+= (size_t)gridDim.x*blockDim.x){\n",
        "    int g = (int)(t / (size_t)(M*K));\n",
        "    size_t r = t % (size_t)(M*K);\n",
        "    int i = (int)(r / (size_t)K);\n",
        "    int k = (int)(r % (size_t)K);\n",
        "    int p = primes[base_g + g];\n",
        "    int v = A32[(size_t)i*K + k];\n",
        "    A8[(size_t)g*Asz + (size_t)i*K + k] = mod_center_s8(v,p);\n",
        "  }\n",
        "}\n",
        "__global__ void pack_group_B(const int32_t* __restrict__ B32, int8_t* __restrict__ B8,\n",
        "                             int K, int N, const int* __restrict__ primes,\n",
        "                             int base_g, int G, size_t Bsz)\n",
        "{\n",
        "  size_t tid = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  size_t total = (size_t)G * (size_t)K * (size_t)N;\n",
        "  for(size_t t=tid; t<total; t+= (size_t)gridDim.x*blockDim.x){\n",
        "    int g = (int)(t / (size_t)(K*N));\n",
        "    size_t r = t % (size_t)(K*N);\n",
        "    int k = (int)(r / (size_t)N);\n",
        "    int j = (int)(r % (size_t)N);\n",
        "    int p = primes[base_g + g];\n",
        "    int v = B32[(size_t)k*N + j];\n",
        "    B8[(size_t)g*Bsz + (size_t)k*N + j] = mod_center_s8(v,p);\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc,char**argv){\n",
        "  ios::sync_with_stdio(false); cin.tie(nullptr);\n",
        "  Args a; parse(argc,argv,a);\n",
        "  const int M=a.M,N=a.N,K=a.K,P=a.primes,PG=max(1,min(a.pg,P)),TPB=max(64,min(a.tpb,1024));\n",
        "  auto primes = primes_list(P);\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" GRAPH_PIPE  M=%d N=%d K=%d primes=%d  ms_min=%d  seed=%u\\n\",M,N,K,P,a.ms_min,a.seed);\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  vector<int32_t> Ah,Bh; fill_rand_i32(Ah,M,K,a.seed+1); fill_rand_i32(Bh,K,N,a.seed+2);\n",
        "\n",
        "  int32_t *dA=nullptr,*dB=nullptr,*dCT=nullptr; int *dPr=nullptr;\n",
        "  size_t Asz=(size_t)M*K, Bsz=(size_t)K*N, Csz=(size_t)M*N;\n",
        "  CUDA_OK(cudaMalloc(&dA,  Asz*sizeof(int32_t)),\"malloc dA\");\n",
        "  CUDA_OK(cudaMalloc(&dB,  Bsz*sizeof(int32_t)),\"malloc dB\");\n",
        "  CUDA_OK(cudaMalloc(&dCT, (size_t)P*Csz*sizeof(int32_t)),\"malloc dCT\");\n",
        "  CUDA_OK(cudaMalloc(&dPr, P*sizeof(int)),\"malloc dPr\");\n",
        "  CUDA_OK(cudaMemcpy(dA, Ah.data(), Asz*sizeof(int32_t), cudaMemcpyHostToDevice),\"H2D A\");\n",
        "  CUDA_OK(cudaMemcpy(dB, Bh.data(), Bsz*sizeof(int32_t), cudaMemcpyHostToDevice),\"H2D B\");\n",
        "  CUDA_OK(cudaMemcpy(dPr, primes.data(), P*sizeof(int), cudaMemcpyHostToDevice),\"H2D primes\");\n",
        "\n",
        "  int8_t *dA8[2]={},*dB8[2]={};\n",
        "  size_t Asz_bytes=(size_t)PG*Asz, Bsz_bytes=(size_t)PG*Bsz;\n",
        "  CUDA_OK(cudaMalloc(&dA8[0], Asz_bytes),\"malloc dA8[0]\");\n",
        "  CUDA_OK(cudaMalloc(&dA8[1], Asz_bytes),\"malloc dA8[1]\");\n",
        "  CUDA_OK(cudaMalloc(&dB8[0], Bsz_bytes),\"malloc dB8[0]\");\n",
        "  CUDA_OK(cudaMalloc(&dB8[1], Bsz_bytes),\"malloc dB8[1]\");\n",
        "\n",
        "  cublasHandle_t h; CUBLAS_OK(cublasCreate(&h),\"create\");\n",
        "  CUBLAS_OK(cublasSetMathMode(h, CUBLAS_TENSOR_OP_MATH),\"mathMode\");\n",
        "\n",
        "  // Correct column-major leading dimensions for Cᵗ = Bᵗ · Aᵗ\n",
        "  const int m=N, n=M, k=K;\n",
        "  const int lda=K;  // FIXED: underlying B is (K x N)\n",
        "  const int ldb=M;  // FIXED: underlying A is (M x K)\n",
        "  const int ldc=N;  // Cᵗ is (N x M)\n",
        "  const long long sA=(long long)K*(long long)N; // elements per batch of Bᵗ\n",
        "  const long long sB=(long long)M*(long long)K; // elements per batch of Aᵗ\n",
        "  const long long sC=(long long)N*(long long)M; // elements per batch of Cᵗ\n",
        "\n",
        "  const int blocksA=(int)((((size_t)PG*Asz)+TPB-1)/TPB);\n",
        "  const int blocksB=(int)((((size_t)PG*Bsz)+TPB-1)/TPB);\n",
        "\n",
        "  cudaStream_t s; CUDA_OK(cudaStreamCreate(&s),\"mk stream\");\n",
        "  CUBLAS_OK(cublasSetStream(h, s),\"set stream\");\n",
        "\n",
        "  cudaGraph_t graph=nullptr; cudaGraphExec_t gexec=nullptr;\n",
        "  CUDA_OK(cudaStreamBeginCapture(s, cudaStreamCaptureModeGlobal),\"begin capture\");\n",
        "\n",
        "  int buf=0;\n",
        "  for(int base=0;base<P;base+=PG, buf^=1){\n",
        "    const int G=min(PG, P-base);\n",
        "    pack_group_A<<<blocksA,TPB,0,s>>>(dA,dA8[buf],M,K,dPr,base,G,Asz);\n",
        "    pack_group_B<<<blocksB,TPB,0,s>>>(dB,dB8[buf],K,N,dPr,base,G,Bsz);\n",
        "    CUDA_OK(cudaGetLastError(),\"pack launch\");\n",
        "    if(base>0){\n",
        "      const int prev_base = base-PG;\n",
        "      const int prev_G    = min(PG, P-prev_base);\n",
        "      int32_t *dst = dCT + (size_t)prev_base*sC;\n",
        "      int32_t alpha=1,beta=0;\n",
        "      CUBLAS_OK(cublasGemmStridedBatchedEx(\n",
        "        h, CUBLAS_OP_T, CUBLAS_OP_T,\n",
        "        m,n,k,\n",
        "        &alpha,\n",
        "        dB8[1-buf], CUDA_R_8I, lda, sA,\n",
        "        dA8[1-buf], CUDA_R_8I, ldb, sB,\n",
        "        &beta,\n",
        "        dst,       CUDA_R_32I, ldc, sC,\n",
        "        prev_G,\n",
        "        CUBLAS_COMPUTE_32I,\n",
        "        CUBLAS_GEMM_DEFAULT_TENSOR_OP\n",
        "      ),\"gemm prev\");\n",
        "    }\n",
        "  }\n",
        "  { // tail GEMM\n",
        "    const int groups = (P+PG-1)/PG;\n",
        "    const int tail_base=(groups-1)*PG;\n",
        "    const int tail_G=min(PG,P-tail_base);\n",
        "    int32_t *dst=dCT + (size_t)tail_base*sC;\n",
        "    int32_t alpha=1,beta=0;\n",
        "    CUBLAS_OK(cublasGemmStridedBatchedEx(\n",
        "      h, CUBLAS_OP_T, CUBLAS_OP_T,\n",
        "      m,n,k,\n",
        "      &alpha,\n",
        "      dB8[(groups%2)?1:0], CUDA_R_8I, lda, sA,\n",
        "      dA8[(groups%2)?1:0], CUDA_R_8I, ldb, sB,\n",
        "      &beta,\n",
        "      dst,                 CUDA_R_32I, ldc, sC,\n",
        "      tail_G,\n",
        "      CUBLAS_COMPUTE_32I,\n",
        "      CUBLAS_GEMM_DEFAULT_TENSOR_OP\n",
        "    ),\"gemm tail\");\n",
        "  }\n",
        "\n",
        "  CUDA_OK(cudaStreamEndCapture(s,&graph),\"end capture\");\n",
        "  CUDA_OK(cudaGraphInstantiate(&gexec, graph, nullptr, nullptr, 0),\"instantiate\");\n",
        "\n",
        "  double wall_ms=0.0; int iters=0; auto t0=clk::now();\n",
        "  do{\n",
        "    CUDA_OK(cudaGraphLaunch(gexec, s),\"launch\"); iters++;\n",
        "    CUDA_OK(cudaStreamSynchronize(s),\"sync\");\n",
        "    wall_ms = chrono::duration<double, milli>(clk::now()-t0).count();\n",
        "  }while(wall_ms < a.ms_min);\n",
        "\n",
        "  const double secs=wall_ms/1000.0;\n",
        "  const double logical_macs=(double)M*(double)N*(double)K;\n",
        "  const double logical=(logical_macs*iters)/secs/1e9;\n",
        "  const double modular=logical*(double)P;\n",
        "  const double dp4a_eq=modular/4.0;\n",
        "\n",
        "  vector<int32_t> Ccol((size_t)P*(size_t)N*(size_t)M);\n",
        "  CUDA_OK(cudaMemcpy(Ccol.data(), dCT, Ccol.size()*sizeof(int32_t), cudaMemcpyDeviceToHost),\"D2H C\");\n",
        "  long long twoB = 2LL*(a.cert_bound>0? a.cert_bound : (long long)M*(long long)N*(long long)K);\n",
        "  __int128 Mprod=1; for(int i=0;i<P;i++){ Mprod*=primes[i]; if(Mprod>(__int128)9e18) break; }\n",
        "  printf(\"CRT certificate: Mprod~(truncated)  vs  2*bound=%lld  (UNIQUE RECON %s)\\n\",\n",
        "         twoB, (Mprod>twoB?\"OK\":\"(not guaranteed)\"));\n",
        "\n",
        "  uint64_t hsh=0;\n",
        "  if(a.verify){\n",
        "    size_t sC = (size_t)N*(size_t)M; int R=min(a.recon_K,(int)sC);\n",
        "    for(int t=0;t<R;++t){\n",
        "      for(int g=0; g<P; ++g){\n",
        "        int32_t v = Ccol[(size_t)g*sC + (size_t)t];\n",
        "        hsh = ((hsh ^ (uint64_t)v) * 1099511628211ull);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [G010f_GRAPH_FIX4] M=%d N=%d K=%d primes=%d pg=%d iters=%d time=%.2f ms (captured: 1 stream)\\n\",\n",
        "         M,N,K,P,PG,iters,wall_ms);\n",
        "  printf(\"  Logical MACs/s:        %.3f G-mac/s\\n\", logical);\n",
        "  printf(\"  Modular MACs/s:        %.3f G-mac/s   (× primes)\\n\", modular);\n",
        "  printf(\"  dp4a-equiv inst/s:     %.3f G-inst/s  (~ modular/4)\\n\", dp4a_eq);\n",
        "  if(a.verify) printf(\"  CRT (strided) hash:    0x%016llx\\n\", (unsigned long long)hsh);\n",
        "  printf(\"  GRAPH: capture=YES (single stream), pingpong=YES\\n\");\n",
        "  printf(\"  cuBLAS math mode:      TensorOp (GemmStridedBatchedEx)\\n\");\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  if(gexec) cudaGraphExecDestroy(gexec);\n",
        "  if(graph) cudaGraphDestroy(graph);\n",
        "  cudaStreamDestroy(s);\n",
        "  cublasDestroy(h);\n",
        "  cudaFree(dA8[0]); cudaFree(dA8[1]); cudaFree(dB8[0]); cudaFree(dB8[1]);\n",
        "  cudaFree(dA); cudaFree(dB); cudaFree(dCT); cudaFree(dPr);\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "nvcc -O3 -std=c++17 g010f_graph_fix4.cu -o g010f_graph_fix4 -lcublas \\\n",
        "  -gencode arch=compute_75,code=sm_75\n",
        "\n",
        "echo\n",
        "echo \"=== G010f_GRAPH_FIX4: quick (512^3, 5 primes) — captured (1 stream) ===\"\n",
        "./g010f_graph_fix4 --M 512 --N 512 --K 512 --primes 5 --ms 280 --pg 3 --tpb 512 --reconK 4096\n",
        "\n",
        "echo\n",
        "echo \"=== G010f_GRAPH_FIX4: big (1024x2048x1024, 9 primes) — captured (1 stream) ===\"\n",
        "./g010f_graph_fix4 --M 1024 --N 1024 --K 2048 --primes 9 --ms 400 --pg 3 --tpb 512 --reconK 8192\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03o7pfq9NHKj",
        "outputId": "f38558d5-ff09-4e3c-c0b6-9bf92d03954f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== G010f_GRAPH_FIX4: quick (512^3, 5 primes) — captured (1 stream) ===\n",
            "============================================================================\n",
            " GRAPH_PIPE  M=512 N=512 K=512 primes=5  ms_min=280  seed=12345\n",
            "============================================================================\n",
            "CRT certificate: Mprod~(truncated)  vs  2*bound=268435456  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G010f_GRAPH_FIX4] M=512 N=512 K=512 primes=5 pg=3 iters=847 time=280.12 ms (captured: 1 stream)\n",
            "  Logical MACs/s:        405.838 G-mac/s\n",
            "  Modular MACs/s:        2029.188 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     507.297 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x72394cfbfb03186d\n",
            "  GRAPH: capture=YES (single stream), pingpong=YES\n",
            "  cuBLAS math mode:      TensorOp (GemmStridedBatchedEx)\n",
            "============================================================================\n",
            "\n",
            "=== G010f_GRAPH_FIX4: big (1024x2048x1024, 9 primes) — captured (1 stream) ===\n",
            "============================================================================\n",
            " GRAPH_PIPE  M=1024 N=1024 K=2048 primes=9  ms_min=400  seed=12345\n",
            "============================================================================\n",
            "CRT certificate: Mprod~(truncated)  vs  2*bound=4294967296  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G010f_GRAPH_FIX4] M=1024 N=1024 K=2048 primes=9 pg=3 iters=114 time=401.81 ms (captured: 1 stream)\n",
            "  Logical MACs/s:        609.280 G-mac/s\n",
            "  Modular MACs/s:        5483.523 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     1370.881 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x90d289ac9c66124c\n",
            "  GRAPH: capture=YES (single stream), pingpong=YES\n",
            "  cuBLAS math mode:      TensorOp (GemmStridedBatchedEx)\n",
            "============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "cat > g010g_prepack_graph.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "using namespace std; using clk = chrono::high_resolution_clock;\n",
        "\n",
        "#define CUDA_OK(x,msg) do{ cudaError_t _e=(x); if(_e!=cudaSuccess){ \\\n",
        "  fprintf(stderr,\"CUDA ERROR @%s: %s\\n\", msg, cudaGetErrorString(_e)); exit(1);} }while(0)\n",
        "#define CUBLAS_OK(x,msg) do{ cublasStatus_t _s=(x); if(_s!=CUBLAS_STATUS_SUCCESS){ \\\n",
        "  fprintf(stderr,\"CUBLAS ERROR @%s: %d\\n\", msg, (int)_s); exit(1);} }while(0)\n",
        "\n",
        "static vector<int> primes_list(int P){\n",
        "  static const int all[] = {127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53,47,43,41,37,31,29,23,19,17,13,11,7,5,3};\n",
        "  int maxP = (int)(sizeof(all)/sizeof(all[0]));\n",
        "  P = max(1, min(P, maxP));\n",
        "  return vector<int>(all, all+P);\n",
        "}\n",
        "\n",
        "// ===== args =====\n",
        "struct Args{\n",
        "  int M=1024,N=1024,K=2048,primes=9;\n",
        "  int ms_min=400, verify=1, recon_K=8192;\n",
        "  long long cert_bound=0; unsigned seed=12345u;\n",
        "};\n",
        "static void parse(int argc,char**argv,Args&a){\n",
        "  for(int i=1;i<argc;i++){\n",
        "    string s=argv[i]; auto need=[&]{ if(i+1>=argc){ fprintf(stderr,\"Missing %s\\n\", s.c_str()); exit(1);} };\n",
        "    if(s==\"--M\"){need();a.M=atoi(argv[++i]);}\n",
        "    else if(s==\"--N\"){need();a.N=atoi(argv[++i]);}\n",
        "    else if(s==\"--K\"){need();a.K=atoi(argv[++i]);}\n",
        "    else if(s==\"--primes\"){need();a.primes=atoi(argv[++i]);}\n",
        "    else if(s==\"--ms\"){need();a.ms_min=atoi(argv[++i]);}\n",
        "    else if(s==\"--seed\"){need();a.seed=(unsigned)strtoul(argv[++i],nullptr,10);}\n",
        "    else if(s==\"--verify\"){a.verify=1;}\n",
        "    else if(s==\"--noverify\"){a.verify=0;}\n",
        "    else if(s==\"--reconK\"){need();a.recon_K=atoi(argv[++i]);}\n",
        "    else if(s==\"--cert\"){need();a.cert_bound=atoll(argv[++i]);}\n",
        "  }\n",
        "}\n",
        "\n",
        "static void fill_rand_i32(vector<int32_t>&A,int R,int C,unsigned seed,int maxAbs=700){\n",
        "  mt19937 rng(seed); uniform_int_distribution<int>d(-maxAbs,maxAbs);\n",
        "  A.resize((size_t)R*C); for(auto &x:A) x = d(rng);\n",
        "}\n",
        "\n",
        "// map int32 → centered int8 mod p\n",
        "__device__ __forceinline__ int8_t mod_center_s8(int v, int p){\n",
        "  int r = v % p; if(r<0) r += p; int half = p>>1; return (r<=half)?(int8_t)r:(int8_t)(r-p);\n",
        "}\n",
        "\n",
        "// pack all primes once (row-major sources)\n",
        "__global__ void pack_all_A(const int32_t* __restrict__ A32, int8_t* __restrict__ A8,\n",
        "                           int M, int K, const int* __restrict__ P, int Pcnt)\n",
        "{\n",
        "  size_t tid = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  size_t Asz = (size_t)M*K;\n",
        "  size_t total = (size_t)Pcnt * Asz;\n",
        "  for(size_t t=tid; t<total; t += (size_t)gridDim.x*blockDim.x){\n",
        "    int g = (int)(t / Asz);\n",
        "    size_t r = t % Asz;\n",
        "    int i = (int)(r / (size_t)K);\n",
        "    int k = (int)(r % (size_t)K);\n",
        "    int p = P[g];\n",
        "    int v = A32[(size_t)i*K + k];\n",
        "    A8[(size_t)g*Asz + (size_t)i*K + k] = mod_center_s8(v,p);\n",
        "  }\n",
        "}\n",
        "__global__ void pack_all_B(const int32_t* __restrict__ B32, int8_t* __restrict__ B8,\n",
        "                           int K, int N, const int* __restrict__ P, int Pcnt)\n",
        "{\n",
        "  size_t tid = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "  size_t Bsz = (size_t)K*N;\n",
        "  size_t total = (size_t)Pcnt * Bsz;\n",
        "  for(size_t t=tid; t<total; t += (size_t)gridDim.x*blockDim.x){\n",
        "    int g = (int)(t / Bsz);\n",
        "    size_t r = t % Bsz;\n",
        "    int k = (int)(r / (size_t)N);\n",
        "    int j = (int)(r % (size_t)N);\n",
        "    int p = P[g];\n",
        "    int v = B32[(size_t)k*N + j];\n",
        "    B8[(size_t)g*Bsz + (size_t)k*N + j] = mod_center_s8(v,p);\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc,char**argv){\n",
        "  ios::sync_with_stdio(false); cin.tie(nullptr);\n",
        "  Args a; parse(argc,argv,a);\n",
        "  const int M=a.M,N=a.N,K=a.K,P=a.primes;\n",
        "  auto primes = primes_list(P);\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" PREPACK_GRAPH  M=%d N=%d K=%d primes=%d  ms_min=%d  seed=%u\\n\",M,N,K,P,a.ms_min,a.seed);\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  // host data\n",
        "  vector<int32_t> Ah,Bh; fill_rand_i32(Ah,M,K,a.seed+1); fill_rand_i32(Bh,K,N,a.seed+2);\n",
        "\n",
        "  // device buffers\n",
        "  int32_t *dA=nullptr,*dB=nullptr; int *dPr=nullptr;\n",
        "  size_t Asz=(size_t)M*K, Bsz=(size_t)K*N, Csz=(size_t)M*N;\n",
        "  CUDA_OK(cudaMalloc(&dA,  Asz*sizeof(int32_t)),\"malloc dA\");\n",
        "  CUDA_OK(cudaMalloc(&dB,  Bsz*sizeof(int32_t)),\"malloc dB\");\n",
        "  CUDA_OK(cudaMalloc(&dPr, P*sizeof(int)),\"malloc dPr\");\n",
        "  CUDA_OK(cudaMemcpy(dA, Ah.data(), Asz*sizeof(int32_t), cudaMemcpyHostToDevice),\"H2D A\");\n",
        "  CUDA_OK(cudaMemcpy(dB, Bh.data(), Bsz*sizeof(int32_t), cudaMemcpyHostToDevice),\"H2D B\");\n",
        "  CUDA_OK(cudaMemcpy(dPr, primes.data(), P*sizeof(int), cudaMemcpyHostToDevice),\"H2D primes\");\n",
        "\n",
        "  int8_t *dA8_all=nullptr,*dB8_all=nullptr;\n",
        "  int32_t *dCT=nullptr;\n",
        "  CUDA_OK(cudaMalloc(&dA8_all, (size_t)P*Asz),\"malloc A8_all\");\n",
        "  CUDA_OK(cudaMalloc(&dB8_all, (size_t)P*Bsz),\"malloc B8_all\");\n",
        "  CUDA_OK(cudaMalloc(&dCT,     (size_t)P*Csz*sizeof(int32_t)),\"malloc C^T batched\");\n",
        "\n",
        "  // --- one-time pack of all primes ---\n",
        "  const int TPB=512;\n",
        "  const int blocksA=(int)((((size_t)P*Asz)+TPB-1)/TPB);\n",
        "  const int blocksB=(int)((((size_t)P*Bsz)+TPB-1)/TPB);\n",
        "  cudaStream_t s; CUDA_OK(cudaStreamCreate(&s),\"mk stream\");\n",
        "  pack_all_A<<<blocksA,TPB,0,s>>>(dA,dA8_all,M,K,dPr,P);\n",
        "  pack_all_B<<<blocksB,TPB,0,s>>>(dB,dB8_all,K,N,dPr,P);\n",
        "  CUDA_OK(cudaGetLastError(),\"pack launch\");\n",
        "  CUDA_OK(cudaStreamSynchronize(s),\"pack sync\");\n",
        "\n",
        "  // cuBLAS setup (Tensor Op math)\n",
        "  cublasHandle_t h; CUBLAS_OK(cublasCreate(&h),\"create\");\n",
        "  CUBLAS_OK(cublasSetMathMode(h, CUBLAS_TENSOR_OP_MATH),\"mathMode\");\n",
        "  CUBLAS_OK(cublasSetStream(h, s),\"set stream\");\n",
        "\n",
        "  // GEMM params for column-major trick: C^T = B^T · A^T\n",
        "  const int m=N, n=M, k=K;\n",
        "  const int lda=K;                // B^T has leading dim K\n",
        "  const int ldb=M;                // A^T has leading dim M\n",
        "  const int ldc=N;                // C^T has leading dim N\n",
        "  const long long sA=(long long)K*(long long)N; // stride between B^T batches\n",
        "  const long long sB=(long long)M*(long long)K; // stride between A^T batches\n",
        "  const long long sC=(long long)N*(long long)M; // stride between C^T batches\n",
        "  int32_t alpha=1, beta=0;\n",
        "\n",
        "  // --- capture a graph with ONLY the batched GEMM ---\n",
        "  cudaGraph_t graph=nullptr; cudaGraphExec_t gexec=nullptr;\n",
        "  CUDA_OK(cudaStreamBeginCapture(s, cudaStreamCaptureModeGlobal),\"begin capture\");\n",
        "  CUBLAS_OK(cublasGemmStridedBatchedEx(\n",
        "    h, CUBLAS_OP_T, CUBLAS_OP_T,\n",
        "    m,n,k,\n",
        "    &alpha,\n",
        "    dB8_all, CUDA_R_8I, lda, sA,\n",
        "    dA8_all, CUDA_R_8I, ldb, sB,\n",
        "    &beta,\n",
        "    dCT,     CUDA_R_32I, ldc, sC,\n",
        "    P,\n",
        "    CUBLAS_COMPUTE_32I,\n",
        "    CUBLAS_GEMM_DEFAULT_TENSOR_OP\n",
        "  ),\"gemm batched\");\n",
        "  CUDA_OK(cudaStreamEndCapture(s,&graph),\"end capture\");\n",
        "  CUDA_OK(cudaGraphInstantiate(&gexec, graph, nullptr, nullptr, 0),\"instantiate\");\n",
        "\n",
        "  // --- run until ms_min ---\n",
        "  double wall_ms=0.0; int iters=0; auto t0=clk::now();\n",
        "  do{\n",
        "    CUDA_OK(cudaGraphLaunch(gexec, s),\"launch\");\n",
        "    CUDA_OK(cudaStreamSynchronize(s),\"sync\");\n",
        "    iters++;\n",
        "    wall_ms = chrono::duration<double, milli>(clk::now()-t0).count();\n",
        "  }while(wall_ms < a.ms_min);\n",
        "\n",
        "  const double secs=wall_ms/1000.0;\n",
        "  const double logical_macs=(double)M*(double)N*(double)K;\n",
        "  const double logical=(logical_macs*iters)/secs/1e9;\n",
        "  const double modular=logical*(double)P;\n",
        "  const double dp4a_eq=modular/4.0;\n",
        "\n",
        "  // D2H + CRT cert/hash (read C^T batches as column-major blocks)\n",
        "  vector<int32_t> Ccol((size_t)P*(size_t)N*(size_t)M);\n",
        "  CUDA_OK(cudaMemcpy(Ccol.data(), dCT, Ccol.size()*sizeof(int32_t), cudaMemcpyDeviceToHost),\"D2H C\");\n",
        "  long long twoB = 2LL*(a.cert_bound>0? a.cert_bound : (long long)M*(long long)N*(long long)K);\n",
        "  __int128 Mprod=1; for(int i=0;i<P;i++){ Mprod*=primes[i]; if(Mprod>(__int128)9e18) break; }\n",
        "  printf(\"CRT certificate: Mprod~(truncated)  vs  2*bound=%lld  (UNIQUE RECON %s)\\n\",\n",
        "         twoB, (Mprod>twoB?\"OK\":\"(not guaranteed)\"));\n",
        "\n",
        "  uint64_t hsh=0;\n",
        "  if(a.verify){\n",
        "    size_t sC_elems = (size_t)N*(size_t)M;\n",
        "    int R = min(a.recon_K,(int)sC_elems);\n",
        "    for(int t=0;t<R;++t){\n",
        "      for(int g=0; g<P; ++g){\n",
        "        int32_t v = Ccol[(size_t)g*sC_elems + (size_t)t];\n",
        "        hsh = ((hsh ^ (uint64_t)v) * 1099511628211ull);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [G010g_PREPACK_GRAPH] M=%d N=%d K=%d primes=%d iters=%d time=%.2f ms (captured: GEMM only)\\n\",\n",
        "         M,N,K,P,iters,wall_ms);\n",
        "  printf(\"  Logical MACs/s:        %.3f G-mac/s\\n\", logical);\n",
        "  printf(\"  Modular MACs/s:        %.3f G-mac/s   (× primes)\\n\", modular);\n",
        "  printf(\"  dp4a-equiv inst/s:     %.3f G-inst/s  (~ modular/4)\\n\", dp4a_eq);\n",
        "  if(a.verify) printf(\"  CRT (strided) hash:    0x%016llx\\n\", (unsigned long long)hsh);\n",
        "  printf(\"  GRAPH: capture=YES (single stream), prepack=YES (once)\\n\");\n",
        "  printf(\"  cuBLAS math mode:      TensorOp (GemmStridedBatchedEx)\\n\");\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  if(gexec) cudaGraphExecDestroy(gexec);\n",
        "  if(graph) cudaGraphDestroy(graph);\n",
        "  cudaStreamDestroy(s);\n",
        "  cublasDestroy(h);\n",
        "  cudaFree(dA8_all); cudaFree(dB8_all);\n",
        "  cudaFree(dA); cudaFree(dB); cudaFree(dCT); cudaFree(dPr);\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# build for T4 (sm_75)\n",
        "nvcc -O3 -std=c++17 g010g_prepack_graph.cu -o g010g_prepack_graph -lcublas \\\n",
        "  -gencode arch=compute_75,code=sm_75\n",
        "\n",
        "echo\n",
        "echo \"=== G010g_PREPACK_GRAPH: quick (512^3, 5 primes) ===\"\n",
        "./g010g_prepack_graph --M 512 --N 512 --K 512 --primes 5 --ms 280 --reconK 4096\n",
        "\n",
        "echo\n",
        "echo \"=== G010g_PREPACK_GRAPH: big (1024x2048x1024, 9 primes) ===\"\n",
        "./g010g_prepack_graph --M 1024 --N 1024 --K 2048 --primes 9 --ms 400 --reconK 8192\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYwT4YMkY6BN",
        "outputId": "2766a8e9-ddfe-4a78-d838-5e2aae62e9a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== G010g_PREPACK_GRAPH: quick (512^3, 5 primes) ===\n",
            "============================================================================\n",
            " PREPACK_GRAPH  M=512 N=512 K=512 primes=5  ms_min=280  seed=12345\n",
            "============================================================================\n",
            "CRT certificate: Mprod~(truncated)  vs  2*bound=268435456  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G010g_PREPACK_GRAPH] M=512 N=512 K=512 primes=5 iters=2116 time=280.00 ms (captured: GEMM only)\n",
            "  Logical MACs/s:        1014.293 G-mac/s\n",
            "  Modular MACs/s:        5071.465 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     1267.866 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0xe61a9ec7964d0623\n",
            "  GRAPH: capture=YES (single stream), prepack=YES (once)\n",
            "  cuBLAS math mode:      TensorOp (GemmStridedBatchedEx)\n",
            "============================================================================\n",
            "\n",
            "=== G010g_PREPACK_GRAPH: big (1024x2048x1024, 9 primes) ===\n",
            "============================================================================\n",
            " PREPACK_GRAPH  M=1024 N=1024 K=2048 primes=9  ms_min=400  seed=12345\n",
            "============================================================================\n",
            "CRT certificate: Mprod~(truncated)  vs  2*bound=4294967296  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G010g_PREPACK_GRAPH] M=1024 N=1024 K=2048 primes=9 iters=197 time=400.47 ms (captured: GEMM only)\n",
            "  Logical MACs/s:        1056.386 G-mac/s\n",
            "  Modular MACs/s:        9507.477 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     2376.869 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x3036129692e4d195\n",
            "  GRAPH: capture=YES (single stream), prepack=YES (once)\n",
            "  cuBLAS math mode:      TensorOp (GemmStridedBatchedEx)\n",
            "============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "cat > g010h_prepack_graph_splitk_fix2.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "using namespace std; using clk = chrono::high_resolution_clock;\n",
        "\n",
        "#define CUDA_OK(x,msg) do{ cudaError_t _e=(x); if(_e!=cudaSuccess){ \\\n",
        "  fprintf(stderr,\"CUDA ERROR @%s: %s\\n\", msg, cudaGetErrorString(_e)); exit(1);} }while(0)\n",
        "#define CUBLAS_OK(x,msg) do{ cublasStatus_t _s=(x); if(_s!=CUBLAS_STATUS_SUCCESS){ \\\n",
        "  fprintf(stderr,\"CUBLAS ERROR @%s: %d\\n\", msg, (int)_s); exit(1);} }while(0)\n",
        "\n",
        "static vector<int> primes_list(int P){\n",
        "  static const int all[] = {127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53,47,43,41,37,31,29,23,19,17,13,11,7,5,3};\n",
        "  int maxP=(int)(sizeof(all)/sizeof(all[0])); P=max(1,min(P,maxP));\n",
        "  return vector<int>(all, all+P);\n",
        "}\n",
        "\n",
        "struct Args{\n",
        "  int M=1024,N=1024,K=2048,primes=9;\n",
        "  int ms_min=400, verify=1, recon_K=8192, splitK=1;\n",
        "  long long cert_bound=0; unsigned seed=12345u;\n",
        "};\n",
        "static void parse(int argc,char**argv,Args&a){\n",
        "  for(int i=1;i<argc;i++){\n",
        "    string s=argv[i]; auto need=[&]{ if(i+1>=argc){ fprintf(stderr,\"Missing %s\\n\",s.c_str()); exit(1);} };\n",
        "    if(s==\"--M\"){need();a.M=atoi(argv[++i]);}\n",
        "    else if(s==\"--N\"){need();a.N=atoi(argv[++i]);}\n",
        "    else if(s==\"--K\"){need();a.K=atoi(argv[++i]);}\n",
        "    else if(s==\"--primes\"){need();a.primes=atoi(argv[++i]);}\n",
        "    else if(s==\"--ms\"){need();a.ms_min=atoi(argv[++i]);}\n",
        "    else if(s==\"--seed\"){need();a.seed=(unsigned)strtoul(argv[++i],nullptr,10);}\n",
        "    else if(s==\"--verify\"){a.verify=1;}\n",
        "    else if(s==\"--noverify\"){a.verify=0;}\n",
        "    else if(s==\"--reconK\"){need();a.recon_K=atoi(argv[++i]);}\n",
        "    else if(s==\"--cert\"){need();a.cert_bound=atoll(argv[++i]);}\n",
        "    else if(s==\"--splitK\"){need();a.splitK=max(1,min(4,atoi(argv[++i])));}\n",
        "  }\n",
        "}\n",
        "\n",
        "static void fill_rand_i32(vector<int32_t>&A,int R,int C,unsigned seed,int maxAbs=700){\n",
        "  mt19937 rng(seed); uniform_int_distribution<int>d(-maxAbs,maxAbs);\n",
        "  A.resize((size_t)R*C); for(auto &x:A) x=d(rng);\n",
        "}\n",
        "\n",
        "__device__ __forceinline__ int8_t mod_center_s8(int v, int p){\n",
        "  int r=v%p; if(r<0) r+=p; int half=p>>1; return (r<=half)?(int8_t)r:(int8_t)(r-p);\n",
        "}\n",
        "__global__ void pack_all_A(const int32_t* __restrict__ A32, int8_t* __restrict__ A8,\n",
        "                           int M,int K,const int* __restrict__ P,int Pc){\n",
        "  size_t tid=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  size_t Asz=(size_t)M*K, total=(size_t)Pc*Asz;\n",
        "  for(size_t t=tid; t<total; t+= (size_t)gridDim.x*blockDim.x){\n",
        "    int g=(int)(t/Asz); size_t r=t%Asz; int i=(int)(r/(size_t)K), k=(int)(r%(size_t)K);\n",
        "    A8[(size_t)g*Asz + (size_t)i*K + k] = mod_center_s8(A32[(size_t)i*K + k], P[g]);\n",
        "  }\n",
        "}\n",
        "__global__ void pack_all_B(const int32_t* __restrict__ B32, int8_t* __restrict__ B8,\n",
        "                           int K,int N,const int* __restrict__ P,int Pc){\n",
        "  size_t tid=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  size_t Bsz=(size_t)K*N, total=(size_t)Pc*Bsz;\n",
        "  for(size_t t=tid; t<total; t+= (size_t)gridDim.x*blockDim.x){\n",
        "    int g=(int)(t/Bsz); size_t r=t%Bsz; int k=(int)(r/(size_t)N), j=(int)(r%(size_t)N);\n",
        "    B8[(size_t)g*Bsz + (size_t)k*N + j] = mod_center_s8(B32[(size_t)k*N + j], P[g]);\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc,char**argv){\n",
        "  ios::sync_with_stdio(false); cin.tie(nullptr);\n",
        "  Args a; parse(argc,argv,a);\n",
        "  const int M=a.M,N=a.N,K=a.K,P=a.primes,sK=a.splitK;\n",
        "  if(K%sK){ fprintf(stderr,\"ERROR: K must be divisible by splitK\\n\"); return 1; }\n",
        "  auto primes=primes_list(P);\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" PREPACK_GRAPH_SPLITK_FIX2  M=%d N=%d K=%d primes=%d  ms_min=%d  seed=%u  splitK=%d\\n\",\n",
        "         M,N,K,P,a.ms_min,a.seed,sK);\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  vector<int32_t> Ah,Bh; fill_rand_i32(Ah,M,K,a.seed+1); fill_rand_i32(Bh,K,N,a.seed+2);\n",
        "\n",
        "  int32_t *dA=nullptr,*dB=nullptr; int *dPr=nullptr;\n",
        "  size_t Asz=(size_t)M*K, Bsz=(size_t)K*N, Csz=(size_t)M*N;\n",
        "  CUDA_OK(cudaMalloc(&dA, Asz*sizeof(int32_t)),\"malloc dA\");\n",
        "  CUDA_OK(cudaMalloc(&dB, Bsz*sizeof(int32_t)),\"malloc dB\");\n",
        "  CUDA_OK(cudaMalloc(&dPr, P*sizeof(int)),\"malloc primes\");\n",
        "  CUDA_OK(cudaMemcpy(dA, Ah.data(), Asz*sizeof(int32_t), cudaMemcpyHostToDevice),\"H2D A\");\n",
        "  CUDA_OK(cudaMemcpy(dB, Bh.data(), Bsz*sizeof(int32_t), cudaMemcpyHostToDevice),\"H2D B\");\n",
        "  CUDA_OK(cudaMemcpy(dPr, primes.data(), P*sizeof(int), cudaMemcpyHostToDevice),\"H2D primes\");\n",
        "\n",
        "  int8_t *dA8=nullptr,*dB8=nullptr; int32_t *dCT=nullptr;\n",
        "  CUDA_OK(cudaMalloc(&dA8, (size_t)P*Asz),\"malloc A8\");\n",
        "  CUDA_OK(cudaMalloc(&dB8, (size_t)P*Bsz),\"malloc B8\");\n",
        "  CUDA_OK(cudaMalloc(&dCT, (size_t)P*Csz*sizeof(int32_t)),\"malloc C^T\");\n",
        "\n",
        "  const int TPB=512;\n",
        "  int blocksA=(int)((((size_t)P*Asz)+TPB-1)/TPB);\n",
        "  int blocksB=(int)((((size_t)P*Bsz)+TPB-1)/TPB);\n",
        "  cudaStream_t s; CUDA_OK(cudaStreamCreate(&s),\"mk stream\");\n",
        "  pack_all_A<<<blocksA,TPB,0,s>>>(dA,dA8,M,K,dPr,P);\n",
        "  pack_all_B<<<blocksB,TPB,0,s>>>(dB,dB8,K,N,dPr,P);\n",
        "  CUDA_OK(cudaGetLastError(),\"pack launch\");\n",
        "  CUDA_OK(cudaStreamSynchronize(s),\"pack sync\");\n",
        "\n",
        "  cublasHandle_t h; CUBLAS_OK(cublasCreate(&h),\"cublas\");\n",
        "  CUBLAS_OK(cublasSetMathMode(h, CUBLAS_TENSOR_OP_MATH),\"math\");\n",
        "  CUBLAS_OK(cublasSetStream(h, s),\"stream\");\n",
        "\n",
        "  // Column-major “NN” mapping for: C^T (N×M) = B^T (N×K) * A^T (K×M)\n",
        "  const int m = N, n = M, k_slice = K / sK;\n",
        "  const int lda = N; // B^T ld\n",
        "  const int ldb = K; // A^T ld\n",
        "  const int ldc = N; // C^T ld\n",
        "  const long long sA = (long long)N*(long long)K; // stride between primes for B^T\n",
        "  const long long sB = (long long)K*(long long)M; // stride between primes for A^T\n",
        "  const long long sC = (long long)N*(long long)M; // stride between primes for C^T\n",
        "\n",
        "  // Check LD constraints for NN:\n",
        "  if(lda < max(1,m) || ldb < max(1,k_slice) || ldc < max(1,m)){\n",
        "    fprintf(stderr,\"ERROR: lda/ldb/ldc too small (lda=%d ldb=%d ldc=%d | m=%d k_slice=%d)\\n\",lda,ldb,ldc,m,k_slice);\n",
        "    return 1;\n",
        "  }\n",
        "  // Check split offsets stay within batch strides\n",
        "  if((long long)k_slice*lda > sA || (long long)k_slice > sB){\n",
        "    fprintf(stderr,\"ERROR: splitK offsets exceed strides (k_slice=%d, lda=%d, sA=%lld, sB=%lld)\\n\",\n",
        "            k_slice, lda, sA, sB); return 1;\n",
        "  }\n",
        "\n",
        "  int32_t alpha=1, beta0=0, beta1=1;\n",
        "\n",
        "  cudaGraph_t graph=nullptr; cudaGraphExec_t gexec=nullptr;\n",
        "  CUDA_OK(cudaStreamBeginCapture(s, cudaStreamCaptureModeGlobal),\"begin capture\");\n",
        "  for(int part=0; part<sK; ++part){\n",
        "    const int k0 = part * k_slice;\n",
        "    // NN path: advance B^T by +k0 columns, A^T by +k0 rows\n",
        "    const int8_t* B8_part = dB8 + (size_t)k0 * lda;\n",
        "    const int8_t* A8_part = dA8 + (size_t)k0;\n",
        "\n",
        "    const int32_t* alpha_p = &alpha;\n",
        "    const int32_t* beta_p  = (part==0)? &beta0 : &beta1;\n",
        "\n",
        "    CUBLAS_OK(cublasGemmStridedBatchedEx(\n",
        "      h, CUBLAS_OP_N, CUBLAS_OP_N,\n",
        "      m, n, k_slice,\n",
        "      alpha_p,\n",
        "      B8_part, CUDA_R_8I, lda, sA,\n",
        "      A8_part, CUDA_R_8I, ldb, sB,\n",
        "      beta_p,\n",
        "      dCT,     CUDA_R_32I, ldc, sC,\n",
        "      P,\n",
        "      CUBLAS_COMPUTE_32I,\n",
        "      CUBLAS_GEMM_DEFAULT_TENSOR_OP\n",
        "    ), \"gemm splitK\");\n",
        "  }\n",
        "  CUDA_OK(cudaStreamEndCapture(s,&graph),\"end capture\");\n",
        "  CUDA_OK(cudaGraphInstantiate(&gexec, graph, nullptr, nullptr, 0),\"instantiate\");\n",
        "\n",
        "  double wall_ms=0.0; int iters=0; auto t0=clk::now();\n",
        "  do{\n",
        "    CUDA_OK(cudaGraphLaunch(gexec, s),\"launch\");\n",
        "    CUDA_OK(cudaStreamSynchronize(s),\"sync\");\n",
        "    iters++;\n",
        "    wall_ms = chrono::duration<double, milli>(clk::now()-t0).count();\n",
        "  }while(wall_ms < a.ms_min);\n",
        "\n",
        "  const double secs=wall_ms/1000.0;\n",
        "  const double logical_macs=(double)M*(double)N*(double)K;\n",
        "  const double logical=(logical_macs*iters)/secs/1e9;\n",
        "  const double modular=logical*(double)P;\n",
        "  const double dp4a_eq=modular/4.0;\n",
        "\n",
        "  vector<int32_t> Ccol((size_t)P*(size_t)N*(size_t)M);\n",
        "  CUDA_OK(cudaMemcpy(Ccol.data(), dCT, Ccol.size()*sizeof(int32_t), cudaMemcpyDeviceToHost),\"D2H C\");\n",
        "  long long twoB = 2LL*(a.cert_bound>0? a.cert_bound : (long long)M*(long long)N*(long long)K);\n",
        "  __int128 Mprod=1; for(int i=0;i<P;i++){ Mprod*=primes[i]; if(Mprod>(__int128)9e18) break; }\n",
        "  printf(\"CRT certificate: Mprod~(truncated)  vs  2*bound=%lld  (UNIQUE RECON %s)\\n\",\n",
        "         twoB, (Mprod>twoB?\"OK\":\"(not guaranteed)\"));\n",
        "\n",
        "  uint64_t hsh=0;\n",
        "  if(a.verify){\n",
        "    size_t sC_elems = (size_t)N*(size_t)M;\n",
        "    int R = min(a.recon_K,(int)sC_elems);\n",
        "    for(int t=0;t<R;++t){\n",
        "      for(int g=0; g<P; ++g){\n",
        "        int32_t v = Ccol[(size_t)g*sC_elems + (size_t)t];\n",
        "        hsh = ((hsh ^ (uint64_t)v) * 1099511628211ull);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [G010h_PREPACK_GRAPH_SPLITK_FIX2] M=%d N=%d K=%d primes=%d splitK=%d iters=%d time=%.2f ms (captured)\\n\",\n",
        "         M,N,K,P,sK,iters,wall_ms);\n",
        "  printf(\"  Logical MACs/s:        %.3f G-mac/s\\n\", logical);\n",
        "  printf(\"  Modular MACs/s:        %.3f G-mac/s   (× primes)\\n\", modular);\n",
        "  printf(\"  dp4a-equiv inst/s:     %.3f G-inst/s  (~ modular/4)\\n\", dp4a_eq);\n",
        "  if(a.verify) printf(\"  CRT (strided) hash:    0x%016llx\\n\", (unsigned long long)hsh);\n",
        "  printf(\"  GRAPH: capture=YES (single stream), prepack=YES (once)\\n\");\n",
        "  printf(\"  cuBLAS math mode:      TensorOp (GemmStridedBatchedEx)\\n\");\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  if(gexec) cudaGraphExecDestroy(gexec);\n",
        "  if(graph) cudaGraphDestroy(graph);\n",
        "  cudaStreamDestroy(s);\n",
        "  cublasDestroy(h);\n",
        "  cudaFree(dA8); cudaFree(dB8);\n",
        "  cudaFree(dA); cudaFree(dB); cudaFree(dCT); cudaFree(dPr);\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# Build for T4 (sm_75)\n",
        "nvcc -O3 -std=c++17 g010h_prepack_graph_splitk_fix2.cu -o g010h_prepack_graph_splitk_fix2 -lcublas \\\n",
        "  -gencode arch=compute_75,code=sm_75\n",
        "\n",
        "echo\n",
        "echo \"=== G010h_PREPACK_GRAPH_SPLITK_FIX2: quick (512^3, 5 primes, splitK sweep) ===\"\n",
        "./g010h_prepack_graph_splitk_fix2 --M 512 --N 512 --K 512 --primes 5 --ms 280 --reconK 4096 --splitK 1\n",
        "./g010h_prepack_graph_splitk_fix2 --M 512 --N 512 --K 512 --primes 5 --ms 280 --reconK 4096 --splitK 2\n",
        "./g010h_prepack_graph_splitk_fix2 --M 512 --N 512 --K 512 --primes 5 --ms 280 --reconK 4096 --splitK 4\n",
        "\n",
        "echo\n",
        "echo \"=== G010h_PREPACK_GRAPH_SPLITK_FIX2: big (1024x2048x1024, 9 primes, splitK sweep) ===\"\n",
        "./g010h_prepack_graph_splitk_fix2 --M 1024 --N 1024 --K 2048 --primes 9 --ms 400 --reconK 8192 --splitK 1\n",
        "./g010h_prepack_graph_splitk_fix2 --M 1024 --N 1024 --K 2048 --primes 9 --ms 400 --reconK 8192 --splitK 2\n",
        "./g010h_prepack_graph_splitk_fix2 --M 1024 --N 1024 --K 2048 --primes 9 --ms 400 --reconK 8192 --splitK 4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeP4A02u9XbF",
        "outputId": "ae52b8a6-f8a5-452b-cb3c-142c03d36378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== G010h_PREPACK_GRAPH_SPLITK_FIX2: quick (512^3, 5 primes, splitK sweep) ===\n",
            "============================================================================\n",
            " PREPACK_GRAPH_SPLITK_FIX2  M=512 N=512 K=512 primes=5  ms_min=280  seed=12345  splitK=1\n",
            "============================================================================\n",
            "CRT certificate: Mprod~(truncated)  vs  2*bound=268435456  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G010h_PREPACK_GRAPH_SPLITK_FIX2] M=512 N=512 K=512 primes=5 splitK=1 iters=2208 time=280.03 ms (captured)\n",
            "  Logical MACs/s:        1058.295 G-mac/s\n",
            "  Modular MACs/s:        5291.475 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     1322.869 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0xbc22b9a76b994bd3\n",
            "  GRAPH: capture=YES (single stream), prepack=YES (once)\n",
            "  cuBLAS math mode:      TensorOp (GemmStridedBatchedEx)\n",
            "============================================================================\n",
            "============================================================================\n",
            " PREPACK_GRAPH_SPLITK_FIX2  M=512 N=512 K=512 primes=5  ms_min=280  seed=12345  splitK=2\n",
            "============================================================================\n",
            "CRT certificate: Mprod~(truncated)  vs  2*bound=268435456  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G010h_PREPACK_GRAPH_SPLITK_FIX2] M=512 N=512 K=512 primes=5 splitK=2 iters=2336 time=280.04 ms (captured)\n",
            "  Logical MACs/s:        1119.594 G-mac/s\n",
            "  Modular MACs/s:        5597.968 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     1399.492 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0xbc22b9a76b994bd3\n",
            "  GRAPH: capture=YES (single stream), prepack=YES (once)\n",
            "  cuBLAS math mode:      TensorOp (GemmStridedBatchedEx)\n",
            "============================================================================\n",
            "============================================================================\n",
            " PREPACK_GRAPH_SPLITK_FIX2  M=512 N=512 K=512 primes=5  ms_min=280  seed=12345  splitK=4\n",
            "============================================================================\n",
            "CRT certificate: Mprod~(truncated)  vs  2*bound=268435456  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G010h_PREPACK_GRAPH_SPLITK_FIX2] M=512 N=512 K=512 primes=5 splitK=4 iters=1342 time=280.20 ms (captured)\n",
            "  Logical MACs/s:        642.817 G-mac/s\n",
            "  Modular MACs/s:        3214.085 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     803.521 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0xbc22b9a76b994bd3\n",
            "  GRAPH: capture=YES (single stream), prepack=YES (once)\n",
            "  cuBLAS math mode:      TensorOp (GemmStridedBatchedEx)\n",
            "============================================================================\n",
            "\n",
            "=== G010h_PREPACK_GRAPH_SPLITK_FIX2: big (1024x2048x1024, 9 primes, splitK sweep) ===\n",
            "============================================================================\n",
            " PREPACK_GRAPH_SPLITK_FIX2  M=1024 N=1024 K=2048 primes=9  ms_min=400  seed=12345  splitK=1\n",
            "============================================================================\n",
            "CRT certificate: Mprod~(truncated)  vs  2*bound=4294967296  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G010h_PREPACK_GRAPH_SPLITK_FIX2] M=1024 N=1024 K=2048 primes=9 splitK=1 iters=201 time=400.63 ms (captured)\n",
            "  Logical MACs/s:        1077.410 G-mac/s\n",
            "  Modular MACs/s:        9696.694 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     2424.173 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x8721e41d8c793032\n",
            "  GRAPH: capture=YES (single stream), prepack=YES (once)\n",
            "  cuBLAS math mode:      TensorOp (GemmStridedBatchedEx)\n",
            "============================================================================\n",
            "============================================================================\n",
            " PREPACK_GRAPH_SPLITK_FIX2  M=1024 N=1024 K=2048 primes=9  ms_min=400  seed=12345  splitK=2\n",
            "============================================================================\n",
            "CRT certificate: Mprod~(truncated)  vs  2*bound=4294967296  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G010h_PREPACK_GRAPH_SPLITK_FIX2] M=1024 N=1024 K=2048 primes=9 splitK=2 iters=191 time=401.51 ms (captured)\n",
            "  Logical MACs/s:        1021.571 G-mac/s\n",
            "  Modular MACs/s:        9194.139 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     2298.535 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x8721e41d8c793032\n",
            "  GRAPH: capture=YES (single stream), prepack=YES (once)\n",
            "  cuBLAS math mode:      TensorOp (GemmStridedBatchedEx)\n",
            "============================================================================\n",
            "============================================================================\n",
            " PREPACK_GRAPH_SPLITK_FIX2  M=1024 N=1024 K=2048 primes=9  ms_min=400  seed=12345  splitK=4\n",
            "============================================================================\n",
            "CRT certificate: Mprod~(truncated)  vs  2*bound=4294967296  (UNIQUE RECON OK)\n",
            "============================================================================\n",
            " [G010h_PREPACK_GRAPH_SPLITK_FIX2] M=1024 N=1024 K=2048 primes=9 splitK=4 iters=165 time=400.33 ms (captured)\n",
            "  Logical MACs/s:        885.106 G-mac/s\n",
            "  Modular MACs/s:        7965.957 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     1991.489 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x8721e41d8c793032\n",
            "  GRAPH: capture=YES (single stream), prepack=YES (once)\n",
            "  cuBLAS math mode:      TensorOp (GemmStridedBatchedEx)\n",
            "============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "cat > g011a_a100_multigraph_prepack.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "using namespace std; using clk = chrono::high_resolution_clock;\n",
        "\n",
        "#define CUDA_OK(x,msg) do{ cudaError_t _e=(x); if(_e!=cudaSuccess){ \\\n",
        "  fprintf(stderr,\"CUDA ERROR @%s: %s\\n\", msg, cudaGetErrorString(_e)); exit(1);} }while(0)\n",
        "#define CUBLAS_OK(x,msg) do{ cublasStatus_t _s=(x); if(_s!=CUBLAS_STATUS_SUCCESS){ \\\n",
        "  fprintf(stderr,\"CUBLAS ERROR @%s: %d\\n\", msg, (int)_s); exit(1);} }while(0)\n",
        "\n",
        "// ===== primes ≤127 (pairwise coprime) =====\n",
        "static vector<int> primes_list(int P){\n",
        "  static const int all[] = {127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53,47,43,41,37,31,29,23,19,17,13,11,7,5,3};\n",
        "  int maxP=(int)(sizeof(all)/sizeof(all[0]));\n",
        "  P=max(1,min(P,maxP));\n",
        "  return vector<int>(all, all+P);\n",
        "}\n",
        "\n",
        "// ===== simple FNV1a64 hash appender =====\n",
        "static inline uint64_t fnv1a64_append(uint64_t h, const void* d, size_t n){\n",
        "  const uint8_t* p=(const uint8_t*)d; for(size_t i=0;i<n;i++){ h^=p[i]; h*=1099511628211ULL; } return h;\n",
        "}\n",
        "static uint64_t crt_hash_strided(const vector<int>& P, const vector<int32_t>& Ccol,\n",
        "                                 int M, int N, int stride_elems){\n",
        "  (void)P;\n",
        "  uint64_t h=1469598103934665603ULL;\n",
        "  const size_t tot=(size_t)M*(size_t)N;\n",
        "  const int K = (int)min(tot,(size_t)8192);\n",
        "  size_t idx=0;\n",
        "  for(int i=0;i<K;i++){\n",
        "    idx = (idx + (size_t)stride_elems) % tot;\n",
        "    int32_t v = Ccol[idx];\n",
        "    h = fnv1a64_append(h,&v,sizeof(v));\n",
        "  }\n",
        "  return h;\n",
        "}\n",
        "\n",
        "// ===== pack int32 -> int8 (mod p), per prime =====\n",
        "__global__ void pack_mod_s8_kernel(const int32_t* __restrict__ X, int8_t* __restrict__ Y,\n",
        "                                   int rows, int cols, int ld, int p){\n",
        "  int c = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int r = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "  if(r>=rows || c>=cols) return;\n",
        "  int32_t v = X[(size_t)r*ld + c];\n",
        "  int32_t t = v % p; if(t<0) t += p;\n",
        "  Y[(size_t)r*cols + c] = (int8_t)t; // fits in s8 for p≤127\n",
        "}\n",
        "\n",
        "int main(int argc, char** argv){\n",
        "  // ===== CLI via envs (keeps it simple & consistent with earlier modules) =====\n",
        "  int M=1024, N=1024, K=2048, primes=9, ms_min=400, recon_K=8192, seed=12345, groups=4;\n",
        "  if(getenv(\"G_M\")) M=atoi(getenv(\"G_M\"));\n",
        "  if(getenv(\"G_N\")) N=atoi(getenv(\"G_N\"));\n",
        "  if(getenv(\"G_K\")) K=atoi(getenv(\"G_K\"));\n",
        "  if(getenv(\"G_P\")) primes=atoi(getenv(\"G_P\"));\n",
        "  if(getenv(\"G_MS\")) ms_min=atoi(getenv(\"G_MS\"));\n",
        "  if(getenv(\"G_SEED\")) seed=atoi(getenv(\"G_SEED\"));\n",
        "  if(getenv(\"G_GROUPS\")) groups=max(1, min(8, atoi(getenv(\"G_GROUPS\")))); // up to 8 groups\n",
        "\n",
        "  // quick sanity preset:\n",
        "  // export G_M=512 G_N=512 G_K=512 G_P=5 G_MS=280 G_GROUPS=3\n",
        "\n",
        "  // ===== device info =====\n",
        "  cudaDeviceProp prop{}; CUDA_OK(cudaGetDeviceProperties(&prop, 0), \"get props\");\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" A100 MULTIGRAPH PREPACK  GPU=%s  SM=%d%d  MPs=%d\\n\",\n",
        "         prop.name, prop.major, prop.minor, prop.multiProcessorCount);\n",
        "  printf(\" M=%d N=%d K=%d primes=%d  ms_min=%d  seed=%d  groups=%d\\n\",\n",
        "         M,N,K,primes,ms_min,seed,groups);\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  if(!(prop.major>7)){ fprintf(stderr,\"This build targets A100 (sm_80+).\\n\"); }\n",
        "\n",
        "  // ===== host data =====\n",
        "  mt19937 rng(seed); uniform_int_distribution<int> d(-700,700);\n",
        "  vector<int32_t> Ah((size_t)M*K), Bh((size_t)K*N);\n",
        "  for(auto& x:Ah) x=d(rng);\n",
        "  for(auto& x:Bh) x=d(rng);\n",
        "  auto P = primes_list(primes);\n",
        "\n",
        "  // ===== device buffers =====\n",
        "  int32_t *dA32=nullptr, *dB32=nullptr;\n",
        "  CUDA_OK(cudaMalloc(&dA32, sizeof(int32_t)*(size_t)M*K), \"malloc dA32\");\n",
        "  CUDA_OK(cudaMalloc(&dB32, sizeof(int32_t)*(size_t)K*N), \"malloc dB32\");\n",
        "  CUDA_OK(cudaMemcpy(dA32, Ah.data(), sizeof(int32_t)*(size_t)M*K, cudaMemcpyHostToDevice), \"cpy A\");\n",
        "  CUDA_OK(cudaMemcpy(dB32, Bh.data(), sizeof(int32_t)*(size_t)K*N, cudaMemcpyHostToDevice), \"cpy B\");\n",
        "\n",
        "  // For C^T = B^T * A^T (column-major):\n",
        "  size_t a_batch_elems = (size_t)N * K; // B^T (NxK)\n",
        "  size_t b_batch_elems = (size_t)K * M; // A^T (KxM)\n",
        "  size_t c_batch_elems = (size_t)N * M; // C^T (NxM)\n",
        "\n",
        "  int8_t *dBT8=nullptr, *dAT8=nullptr;\n",
        "  int32_t* dCT32=nullptr;\n",
        "  CUDA_OK(cudaMalloc(&dBT8, (size_t)primes * a_batch_elems), \"malloc dBT8\");\n",
        "  CUDA_OK(cudaMalloc(&dAT8, (size_t)primes * b_batch_elems), \"malloc dAT8\");\n",
        "  CUDA_OK(cudaMalloc(&dCT32,(size_t)primes * c_batch_elems * sizeof(int32_t)), \"malloc dCT32\");\n",
        "\n",
        "  // ===== prepack residues (GPU) =====\n",
        "  dim3 blk(64,4);\n",
        "  dim3 gA( (K+blk.x-1)/blk.x, (M+blk.y-1)/blk.y ); // A(MxK) -> A^T(KxM) data, but we write packed as row-major tiles\n",
        "  dim3 gB( (N+blk.x-1)/blk.x, (K+blk.y-1)/blk.y ); // B(KxN) -> B^T(NxK)\n",
        "  for(int pi=0; pi<primes; ++pi){\n",
        "    int p=P[pi];\n",
        "    pack_mod_s8_kernel<<<gA,blk>>>(dA32, dAT8 + (size_t)pi*b_batch_elems, M, K, K, p);\n",
        "    pack_mod_s8_kernel<<<gB,blk>>>(dB32, dBT8 + (size_t)pi*a_batch_elems, K, N, N, p);\n",
        "  }\n",
        "  CUDA_OK(cudaDeviceSynchronize(), \"prepack sync\");\n",
        "\n",
        "  // ===== cuBLAS handles (one per group) =====\n",
        "  groups = max(1, min(groups, primes));\n",
        "  struct Ctx { cudaStream_t s; cudaGraph_t g; cudaGraphExec_t ge; cublasHandle_t h; int p0,cnt; } ;\n",
        "  vector<vector<int>> G(groups);\n",
        "  for(int i=0;i<primes;i++) G[i%groups].push_back(i);\n",
        "\n",
        "  vector<Ctx> ctx(groups);\n",
        "  for(int gi=0; gi<groups; ++gi){\n",
        "    ctx[gi].p0 = G[gi].empty()?0: G[gi].front();\n",
        "    ctx[gi].cnt= (int)G[gi].size();\n",
        "    CUDA_OK(cudaStreamCreateWithFlags(&ctx[gi].s, cudaStreamNonBlocking), \"stream\");\n",
        "    CUBLAS_OK(cublasCreate(&ctx[gi].h), \"cublasCreate\");\n",
        "    CUBLAS_OK(cublasSetMathMode(ctx[gi].h, CUBLAS_TENSOR_OP_MATH), \"math mode\");\n",
        "    CUBLAS_OK(cublasSetStream(ctx[gi].h, ctx[gi].s), \"set stream\");\n",
        "  }\n",
        "\n",
        "  // ===== GEMM params (INT8 Tensor Core path) =====\n",
        "  // Compute: C^T (NxM) = B^T (NxK) * A^T (KxM)\n",
        "  cublasOperation_t opa=CUBLAS_OP_N, opb=CUBLAS_OP_N;\n",
        "  int m=N, n=M, k=K; // C^T is NxM\n",
        "  int lda=N; long long strideA = (long long)N * K; // B^T batches\n",
        "  int ldb=K; long long strideB = (long long)K * M; // A^T batches\n",
        "  int ldc=N; long long strideC = (long long)N * M; // C^T batches\n",
        "  const int batchAll = primes;\n",
        "  const int alpha = 1, beta = 0;\n",
        "\n",
        "  // ===== build & instantiate one CUDA Graph per group =====\n",
        "  for(int gi=0; gi<groups; ++gi){\n",
        "    if(ctx[gi].cnt==0) continue;\n",
        "    CUDA_OK(cudaStreamBeginCapture(ctx[gi].s, cudaStreamCaptureModeGlobal), \"begin cap\");\n",
        "\n",
        "    const int8_t* A8 = dBT8 + (size_t)ctx[gi].p0 * strideA; // lhs (B^T)\n",
        "    const int8_t* B8 = dAT8 + (size_t)ctx[gi].p0 * strideB; // rhs (A^T)\n",
        "    int32_t*      C32= dCT32+ (size_t)ctx[gi].p0 * strideC;\n",
        "\n",
        "    CUBLAS_OK(\n",
        "      cublasGemmStridedBatchedEx(\n",
        "        ctx[gi].h, opa, opb,\n",
        "        m, n, k,\n",
        "        &alpha,\n",
        "        A8,  CUDA_R_8I,  lda, strideA,\n",
        "        B8,  CUDA_R_8I,  ldb, strideB,\n",
        "        &beta,\n",
        "        C32, CUDA_R_32I, ldc, strideC,\n",
        "        ctx[gi].cnt,\n",
        "        CUDA_R_32I,\n",
        "        CUBLAS_GEMM_DEFAULT_TENSOR_OP\n",
        "      ), \"GemmStridedBatchedEx(capture)\"\n",
        "    );\n",
        "\n",
        "    CUDA_OK(cudaStreamEndCapture(ctx[gi].s, &ctx[gi].g), \"end cap\");\n",
        "    CUDA_OK(cudaGraphInstantiate(&ctx[gi].ge, ctx[gi].g, nullptr, nullptr, 0), \"instantiate\");\n",
        "  }\n",
        "\n",
        "  // ===== run graphs concurrently until ms_min =====\n",
        "  auto t0=clk::now(); int iters=0;\n",
        "  do{\n",
        "    for(int gi=0; gi<groups; ++gi){\n",
        "      if(ctx[gi].cnt==0) continue;\n",
        "      CUDA_OK(cudaGraphLaunch(ctx[gi].ge, ctx[gi].s), \"graph launch\");\n",
        "    }\n",
        "    for(int gi=0; gi<groups; ++gi){\n",
        "      if(ctx[gi].cnt==0) continue;\n",
        "      CUDA_OK(cudaStreamSynchronize(ctx[gi].s), \"sync\");\n",
        "    }\n",
        "    ++iters;\n",
        "  }while( chrono::duration<double, milli>(clk::now()-t0).count() < ms_min );\n",
        "  double wall_ms = chrono::duration<double, milli>(clk::now()-t0).count();\n",
        "  double secs = wall_ms/1000.0;\n",
        "\n",
        "  // ===== CRT hash on first prime’s C^T =====\n",
        "  vector<int32_t> Ccol((size_t)N*M);\n",
        "  CUDA_OK(cudaMemcpy(Ccol.data(), dCT32 + 0*strideC, sizeof(int32_t)*(size_t)N*M, cudaMemcpyDeviceToHost), \"cpy C0\");\n",
        "  uint64_t hsh = crt_hash_strided(P, Ccol, M,N, (int)(((size_t)M*(size_t)N)/8192 + 1));\n",
        "\n",
        "  // ===== meters =====\n",
        "  const double logical_macs = (double)M*(double)N*(double)K; // per real GEMM\n",
        "  const double logical = (logical_macs*iters)/secs/1e9;\n",
        "  const double modular = logical * primes;\n",
        "  const double dp4a_eq = modular / 4.0;\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [G011a_A100_MULTIGRAPH] M=%d N=%d K=%d primes=%d groups=%d iters=%d time=%.2f ms (captured: %d graphs)\\n\",\n",
        "         M,N,K,primes,groups,iters,wall_ms,groups);\n",
        "  printf(\"  Logical MACs/s:        %.3f G-mac/s\\n\", logical);\n",
        "  printf(\"  Modular MACs/s:        %.3f G-mac/s   (× primes)\\n\", modular);\n",
        "  printf(\"  dp4a-equiv inst/s:     %.3f G-inst/s  (~ modular/4)\\n\", dp4a_eq);\n",
        "  printf(\"  CRT (strided) hash:    0x%016llx\\n\", (unsigned long long)hsh);\n",
        "  printf(\"  GRAPH: capture=YES (%d streams), prepack=YES (once)\\n\", groups);\n",
        "  printf(\"  cuBLAS math mode:      TensorOp (INT8, s32 accum)\\n\");\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  // cleanup\n",
        "  for(int gi=0; gi<groups; ++gi){\n",
        "    if(ctx[gi].cnt){ cudaGraphExecDestroy(ctx[gi].ge); cudaGraphDestroy(ctx[gi].g); }\n",
        "    cublasDestroy(ctx[gi].h);\n",
        "    cudaStreamDestroy(ctx[gi].s);\n",
        "  }\n",
        "  cudaFree(dA32); cudaFree(dB32); cudaFree(dBT8); cudaFree(dAT8); cudaFree(dCT32);\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# Build for A100 (sm_80) -> emits native SASS; avoids PTX-toolchain mismatch\n",
        "/usr/local/cuda/bin/nvcc -O3 -std=c++17 g011a_a100_multigraph_prepack.cu -o g011a_a100_multigraph_prepack -lcublas -arch=sm_80\n",
        "\n",
        "echo\n",
        "echo \"=== G011a: quick (A100) — 512^3, 5 primes, groups=3 ===\"\n",
        "G_M=512 G_N=512 G_K=512 G_P=5 G_MS=280 G_GROUPS=3 ./g011a_a100_multigraph_prepack\n",
        "\n",
        "echo\n",
        "echo \"=== G011a: big (A100) — 1024x2048x1024, 9 primes, groups=4 ===\"\n",
        "G_M=1024 G_N=1024 G_K=2048 G_P=9 G_MS=400 G_GROUPS=4 ./g011a_a100_multigraph_prepack\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHxTBLHVRhbj",
        "outputId": "bc4bc214-25b4-4d29-da21-5ce094b0e540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== G011a: quick (A100) — 512^3, 5 primes, groups=3 ===\n",
            "============================================================================\n",
            " A100 MULTIGRAPH PREPACK  GPU=NVIDIA A100-SXM4-40GB  SM=80  MPs=108\n",
            " M=512 N=512 K=512 primes=5  ms_min=280  seed=12345  groups=3\n",
            "============================================================================\n",
            "============================================================================\n",
            " [G011a_A100_MULTIGRAPH] M=512 N=512 K=512 primes=5 groups=3 iters=5085 time=280.02 ms (captured: 3 graphs)\n",
            "  Logical MACs/s:        2437.291 G-mac/s\n",
            "  Modular MACs/s:        12186.456 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     3046.614 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x2b6459b7b651327a\n",
            "  GRAPH: capture=YES (3 streams), prepack=YES (once)\n",
            "  cuBLAS math mode:      TensorOp (INT8, s32 accum)\n",
            "============================================================================\n",
            "\n",
            "=== G011a: big (A100) — 1024x2048x1024, 9 primes, groups=4 ===\n",
            "============================================================================\n",
            " A100 MULTIGRAPH PREPACK  GPU=NVIDIA A100-SXM4-40GB  SM=80  MPs=108\n",
            " M=1024 N=1024 K=2048 primes=9  ms_min=400  seed=12345  groups=4\n",
            "============================================================================\n",
            "============================================================================\n",
            " [G011a_A100_MULTIGRAPH] M=1024 N=1024 K=2048 primes=9 groups=4 iters=679 time=400.08 ms (captured: 4 graphs)\n",
            "  Logical MACs/s:        3644.581 G-mac/s\n",
            "  Modular MACs/s:        32801.232 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     8200.308 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x62f0aed3b404e2dc\n",
            "  GRAPH: capture=YES (4 streams), prepack=YES (once)\n",
            "  cuBLAS math mode:      TensorOp (INT8, s32 accum)\n",
            "============================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "g011a_a100_multigraph_prepack.cu(51): warning #177-D: variable \"recon_K\" was declared but never referenced\n",
            "    int M=1024, N=1024, K=2048, primes=9, ms_min=400, recon_K=8192, seed=12345, groups=4;\n",
            "                                                      ^\n",
            "\n",
            "Remark: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "g011a_a100_multigraph_prepack.cu(133): warning #177-D: variable \"batchAll\" was declared but never referenced\n",
            "    const int batchAll = primes;\n",
            "              ^\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "cat > g011c_fix2_a100_multigraph_cublas.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "using namespace std; using clk = chrono::high_resolution_clock;\n",
        "\n",
        "#define CUDA_OK(x,msg) do{ cudaError_t _e=(x); if(_e!=cudaSuccess){ \\\n",
        "  fprintf(stderr,\"CUDA ERROR @%s: %s\\n\", msg, cudaGetErrorString(_e)); exit(1);} }while(0)\n",
        "#define CUBLAS_OK(x,msg) do{ cublasStatus_t _s=(x); if(_s!=CUBLAS_STATUS_SUCCESS){ \\\n",
        "  fprintf(stderr,\"CUBLAS ERROR @%s: %d\\n\", msg, (int)_s); exit(1);} }while(0)\n",
        "\n",
        "// primes ≤127 (pairwise coprime)\n",
        "static vector<int> primes_list(int P){\n",
        "  static const int all[] = {127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53,47,43,41,37,31,29,23,19,17,13,11,7,5,3};\n",
        "  int maxP=(int)(sizeof(all)/sizeof(all[0]));\n",
        "  return vector<int>(all, all+max(1,min(P,maxP)));\n",
        "}\n",
        "\n",
        "// tiny WMMA probe (just for choosing groups)\n",
        "#if __CUDACC_VER_MAJOR__ >= 11\n",
        "#include <mma.h>\n",
        "using namespace nvcuda;\n",
        "__global__ void probe_wmma(int iters,int kf, unsigned* sink){\n",
        "#if __CUDA_ARCH__ >= 800\n",
        "  if(threadIdx.x>=32) return;\n",
        "  __shared__ half A[256], B[256];\n",
        "  for(int i=threadIdx.x;i<256;i+=32){ A[i]=__float2half((i%7)*0.125f); B[i]=__float2half(((i*3)%11)*0.09375f); }\n",
        "  __syncthreads();\n",
        "  wmma::fragment<wmma::matrix_a,16,16,16,half,wmma::row_major> a;\n",
        "  wmma::fragment<wmma::matrix_b,16,16,16,half,wmma::row_major> b;\n",
        "  wmma::fragment<wmma::accumulator,16,16,16,float> c;\n",
        "  unsigned s=0;\n",
        "  for(int it=0;it<iters;++it){\n",
        "    wmma::load_matrix_sync(a,A,16);\n",
        "    wmma::load_matrix_sync(b,B,16);\n",
        "    wmma::fill_fragment(c,0.f);\n",
        "    #pragma unroll 4\n",
        "    for(int kk=0; kk<kf; ++kk){ wmma::mma_sync(c,a,b,c); }\n",
        "    if(threadIdx.x==0){ float acc=0.f; for(int i=0;i<c.num_elements;i++) acc+=c.x[i]; s^=__float_as_uint(acc); }\n",
        "  }\n",
        "  if(threadIdx.x==0) sink[blockIdx.x]=s;\n",
        "#else\n",
        "  if(threadIdx.x==0 && blockIdx.x==0) sink[0]=42;\n",
        "#endif\n",
        "}\n",
        "static double wmma_gops_probe(){\n",
        "  int blocks=1024, iters=256, kf=64;\n",
        "  unsigned *d=nullptr; CUDA_OK(cudaMalloc(&d, blocks*sizeof(unsigned)),\"probe malloc\");\n",
        "  cudaEvent_t a,b; cudaEventCreate(&a); cudaEventCreate(&b);\n",
        "  cudaEventRecord(a);\n",
        "  probe_wmma<<<blocks,32>>>(iters,kf,d);\n",
        "  CUDA_OK(cudaGetLastError(),\"probe launch\");\n",
        "  cudaEventRecord(b); cudaEventSynchronize(b);\n",
        "  float ms=0.f; cudaEventElapsedTime(&ms,a,b);\n",
        "  cudaEventDestroy(a); cudaEventDestroy(b);\n",
        "  cudaFree(d);\n",
        "  double ops = (double)blocks * iters * kf * 8192.0;\n",
        "  return (ops/(ms/1000.0))/1e9;\n",
        "}\n",
        "#else\n",
        "static double wmma_gops_probe(){ return 0.0; }\n",
        "#endif\n",
        "\n",
        "// FNV1a64 + CRT hash (strided)\n",
        "static inline uint64_t fnv1a64_append(uint64_t h,const void* d,size_t n){\n",
        "  const uint8_t* p=(const uint8_t*)d; for(size_t i=0;i<n;i++){ h^=p[i]; h*=1099511628211ULL; } return h;\n",
        "}\n",
        "static uint64_t crt_hash_strided(const vector<int>&, const vector<int32_t>& Ccol,\n",
        "                                 int M,int N,int stride_elems){\n",
        "  uint64_t h=1469598103934665603ULL; size_t tot=(size_t)M*(size_t)N;\n",
        "  int K=(int)min(tot,(size_t)8192); size_t idx=0;\n",
        "  for(int i=0;i<K;i++){ idx=(idx+(size_t)stride_elems)%tot; int32_t v=Ccol[idx]; h=fnv1a64_append(h,&v,sizeof(v)); }\n",
        "  return h;\n",
        "}\n",
        "\n",
        "// int32 -> int8 mod p (row-major)\n",
        "__global__ void pack_mod_s8(const int32_t* __restrict__ X, int8_t* __restrict__ Y,\n",
        "                            int rows,int cols,int ld_in,int p){\n",
        "  int c=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  int r=blockIdx.y*blockDim.y+threadIdx.y;\n",
        "  if(r>=rows||c>=cols) return;\n",
        "  int32_t v=X[(size_t)r*ld_in + c]; int t=v%p; if(t<0) t+=p; Y[(size_t)r*cols + c]=(int8_t)t;\n",
        "}\n",
        "\n",
        "struct Args{ int M,N,K,P,ms_min,seed; };\n",
        "static Args preset_small(){ return {512,512,512,5,280,12345}; }\n",
        "static Args preset_big()  { return {1024,1024,2048,9,400,12345}; }\n",
        "\n",
        "static int choose_groups_auto(int P, int sms, double wmma_gops){\n",
        "  int base = max(2, min(8, sms/20));\n",
        "  if(wmma_gops > 20000.0) base = min(base+1, 8);\n",
        "  return max(1, min(P, base));\n",
        "}\n",
        "\n",
        "int run_case(const Args a){\n",
        "  cudaDeviceProp prop{}; CUDA_OK(cudaGetDeviceProperties(&prop,0),\"props\");\n",
        "  double gops = wmma_gops_probe();\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" A100 MULTIGRAPH CUBLAS  GPU=%s  CC=%d.%d  SMs=%d\\n\", prop.name, prop.major, prop.minor, prop.multiProcessorCount);\n",
        "  printf(\" M=%d N=%d K=%d primes=%d  ms_min=%d  seed=%d\\n\", a.M,a.N,a.K,a.P,a.ms_min,a.seed);\n",
        "  printf(\" WMMA quick probe: %.1f G-ops/s\\n\", gops);\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  // host data\n",
        "  mt19937 rng(a.seed); uniform_int_distribution<int> d(-700,700);\n",
        "  vector<int32_t> Ah((size_t)a.M*a.K), Bh((size_t)a.K*a.N);\n",
        "  for(auto&x:Ah) x=d(rng); for(auto&x:Bh) x=d(rng);\n",
        "  auto P = primes_list(a.P);\n",
        "\n",
        "  // device src\n",
        "  int32_t *dA32=nullptr,*dB32=nullptr; CUDA_OK(cudaMalloc(&dA32,sizeof(int32_t)*(size_t)a.M*a.K),\"malloc dA32\");\n",
        "  CUDA_OK(cudaMalloc(&dB32,sizeof(int32_t)*(size_t)a.K*a.N),\"malloc dB32\");\n",
        "  CUDA_OK(cudaMemcpy(dA32,Ah.data(),sizeof(int32_t)*(size_t)a.M*a.K,cudaMemcpyHostToDevice),\"cpy A\");\n",
        "  CUDA_OK(cudaMemcpy(dB32,Bh.data(),sizeof(int32_t)*(size_t)a.K*a.N,cudaMemcpyHostToDevice),\"cpy B\");\n",
        "\n",
        "  // residues\n",
        "  size_t strideA=(size_t)a.M*a.K, strideB=(size_t)a.K*a.N, strideC=(size_t)a.M*a.N;\n",
        "  int8_t *dA8=nullptr,*dB8=nullptr; int32_t* dC32=nullptr;\n",
        "  CUDA_OK(cudaMalloc(&dA8, strideA*a.P),\"malloc dA8\");\n",
        "  CUDA_OK(cudaMalloc(&dB8, strideB*a.P),\"malloc dB8\");\n",
        "  CUDA_OK(cudaMalloc(&dC32,strideC*a.P*sizeof(int32_t)),\"malloc dC32\");\n",
        "\n",
        "  // prepack on GPU\n",
        "  dim3 blk(64,4);\n",
        "  dim3 gA((a.K+blk.x-1)/blk.x,(a.M+blk.y-1)/blk.y);\n",
        "  dim3 gB((a.N+blk.x-1)/blk.x,(a.K+blk.y-1)/blk.y);\n",
        "  for(int pi=0;pi<a.P;++pi){\n",
        "    int p=P[pi];\n",
        "    pack_mod_s8<<<gA,blk>>>(dA32,dA8+pi*strideA, a.M,a.K,a.K,p);\n",
        "    pack_mod_s8<<<gB,blk>>>(dB32,dB8+pi*strideB, a.K,a.N,a.N,p);\n",
        "  }\n",
        "  CUDA_OK(cudaDeviceSynchronize(),\"prepack sync\");\n",
        "\n",
        "  // choose groups and slice CONTIGUOUS chunks\n",
        "  int groups = choose_groups_auto(a.P, prop.multiProcessorCount, gops);\n",
        "  vector<pair<int,int>> slices; slices.reserve(groups); // (p0, cnt)\n",
        "  {\n",
        "    int base=a.P/groups, rem=a.P%groups, p0=0;\n",
        "    for(int gi=0; gi<groups; ++gi){\n",
        "      int cnt = base + (gi<rem?1:0);\n",
        "      slices.push_back({p0,cnt});\n",
        "      p0 += cnt;\n",
        "    }\n",
        "  }\n",
        "  // pretty print plan\n",
        "  fprintf(stdout, \" GROUP PLAN:\"); for(int gi=0; gi<groups; ++gi){ fprintf(stdout,\" [%d:+%d]\", slices[gi].first, slices[gi].second); } fprintf(stdout,\"\\n\");\n",
        "\n",
        "  struct GCtx{ cudaStream_t s{}; cudaGraph_t g{}; cudaGraphExec_t ge{}; cublasHandle_t h{}; int p0=0,cnt=0; };\n",
        "  vector<GCtx> ctx(groups);\n",
        "\n",
        "  // Column-major trick: C^T = B^T · A^T\n",
        "  int m = a.N, n = a.M, k = a.K;\n",
        "  int lda = a.N, ldb = a.K, ldc = a.N;            // leading dims for column-major views\n",
        "  long long sA = (long long)strideB;              // B^T stride (source was row-major B)\n",
        "  long long sB = (long long)strideA;              // A^T stride (source was row-major A)\n",
        "  long long sC = (long long)strideC;              // C^T stride\n",
        "  const int32_t alpha = 1, beta = 0;\n",
        "\n",
        "  for(int gi=0; gi<groups; ++gi){\n",
        "    ctx[gi].p0=slices[gi].first; ctx[gi].cnt=slices[gi].second;\n",
        "    if(!ctx[gi].cnt) continue;\n",
        "\n",
        "    CUDA_OK(cudaStreamCreateWithFlags(&ctx[gi].s, cudaStreamNonBlocking),\"stream\");\n",
        "    CUBLAS_OK(cublasCreate(&ctx[gi].h),\"cublasCreate\");\n",
        "    CUBLAS_OK(cublasSetStream(ctx[gi].h, ctx[gi].s),\"setStream\");\n",
        "    CUBLAS_OK(cublasSetMathMode(ctx[gi].h, CUBLAS_TENSOR_OP_MATH),\"mathMode\");\n",
        "\n",
        "    const void* A8 = dA8 + (size_t)ctx[gi].p0 * strideA;\n",
        "    const void* B8 = dB8 + (size_t)ctx[gi].p0 * strideB;\n",
        "    void*       C32= dC32+ (size_t)ctx[gi].p0 * strideC;\n",
        "\n",
        "    CUDA_OK(cudaStreamBeginCapture(ctx[gi].s, cudaStreamCaptureModeGlobal),\"begin cap\");\n",
        "    CUBLAS_OK(\n",
        "      cublasGemmStridedBatchedEx(\n",
        "        ctx[gi].h,\n",
        "        CUBLAS_OP_T, CUBLAS_OP_T,\n",
        "        m, n, k,\n",
        "        &alpha,\n",
        "        B8, CUDA_R_8I, lda, sA,\n",
        "        A8, CUDA_R_8I, ldb, sB,\n",
        "        &beta,\n",
        "        C32, CUDA_R_32I, ldc, sC,\n",
        "        ctx[gi].cnt,\n",
        "        CUBLAS_COMPUTE_32I, CUBLAS_GEMM_DEFAULT_TENSOR_OP\n",
        "      ), \"GemmStridedBatchedEx(cap)\"\n",
        "    );\n",
        "    CUDA_OK(cudaStreamEndCapture(ctx[gi].s, &ctx[gi].g),\"end cap\");\n",
        "    CUDA_OK(cudaGraphInstantiate(&ctx[gi].ge, ctx[gi].g, nullptr, nullptr, 0),\"instantiate\");\n",
        "  }\n",
        "\n",
        "  // run graphs\n",
        "  auto t0=clk::now(); int iters=0;\n",
        "  do{\n",
        "    for(int gi=0; gi<groups; ++gi) if(ctx[gi].cnt) CUDA_OK(cudaGraphLaunch(ctx[gi].ge, ctx[gi].s),\"launch\");\n",
        "    for(int gi=0; gi<groups; ++gi) if(ctx[gi].cnt) CUDA_OK(cudaStreamSynchronize(ctx[gi].s),\"sync\");\n",
        "    ++iters;\n",
        "  }while( chrono::duration<double,milli>(clk::now()-t0).count() < a.ms_min );\n",
        "  double wall_ms = chrono::duration<double,milli>(clk::now()-t0).count();\n",
        "  double secs = wall_ms/1000.0;\n",
        "\n",
        "  // copy prime0 slice back (C^T for prime 0) to hash\n",
        "  vector<int32_t> C0((size_t)a.M*a.N);\n",
        "  CUDA_OK(cudaMemcpy(C0.data(), dC32 + 0*(size_t)strideC, sizeof(int32_t)*strideC, cudaMemcpyDeviceToHost),\"cpyC0\");\n",
        "  uint64_t hsh = crt_hash_strided(P, C0, a.M, a.N, (int)(((size_t)a.M*(size_t)a.N)/8192 + 1));\n",
        "\n",
        "  const double logical_macs = (double)a.M*(double)a.N*(double)a.K;\n",
        "  const double logical = (logical_macs*iters)/secs/1e9;\n",
        "  const double modular = logical * a.P;\n",
        "  const double dp4a_eq = modular / 4.0;\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [G011c_FIX2_A100_CUBLAS] M=%d N=%d K=%d primes=%d groups=%d iters=%d time=%.2f ms (captured: %d graphs)\\n\",\n",
        "         a.M,a.N,a.K,a.P,groups,iters,wall_ms,groups);\n",
        "  printf(\"  Logical MACs/s:        %.3f G-mac/s\\n\", logical);\n",
        "  printf(\"  Modular MACs/s:        %.3f G-mac/s   (× primes)\\n\", modular);\n",
        "  printf(\"  dp4a-equiv inst/s:     %.3f G-inst/s  (~ modular/4)\\n\", dp4a_eq);\n",
        "  printf(\"  CRT (strided) hash:    0x%016llx\\n\", (unsigned long long)hsh);\n",
        "  printf(\"  GRAPH: %d streams/graphs (auto, contiguous slices), prepack=YES, cuBLAS TensorOp path\\n\", groups);\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  for(int gi=0; gi<groups; ++gi){\n",
        "    if(ctx[gi].ge) cudaGraphExecDestroy(ctx[gi].ge);\n",
        "    if(ctx[gi].g)  cudaGraphDestroy(ctx[gi].g);\n",
        "    if(ctx[gi].h)  cublasDestroy(ctx[gi].h);\n",
        "    if(ctx[gi].s)  cudaStreamDestroy(ctx[gi].s);\n",
        "  }\n",
        "  cudaFree(dA32); cudaFree(dB32); cudaFree(dA8); cudaFree(dB8); cudaFree(dC32);\n",
        "  return 0;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  // small then big\n",
        "  run_case({512,512,512,5,280,12345});\n",
        "  run_case({1024,1024,2048,9,400,12345});\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# Build for A100 (sm_80)\n",
        "nvcc -O3 -std=c++17 g011c_fix2_a100_multigraph_cublas.cu -o g011c_fix2_a100_multigraph_cublas -lcublas -arch=sm_80\n",
        "\n",
        "echo\n",
        "echo \"=== G011c_FIX2: small (A100) — 512^3, 5 primes ===\"\n",
        "./g011c_fix2_a100_multigraph_cublas\n",
        "\n",
        "echo\n",
        "echo \"=== G011c_FIX2: big (A100) — 1024x2048x1024, 9 primes ===\"\n",
        "./g011c_fix2_a100_multigraph_cublas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q5L3080lmmwy",
        "outputId": "4531c4df-0320-4ccb-8fce-efd0e52d71ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== G011c_FIX2: small (A100) — 512^3, 5 primes ===\n",
            "============================================================================\n",
            " A100 MULTIGRAPH CUBLAS  GPU=NVIDIA A100-SXM4-40GB  CC=8.0  SMs=108\n",
            " M=512 N=512 K=512 primes=5  ms_min=280  seed=12345\n",
            " WMMA quick probe: 129304.2 G-ops/s\n",
            "============================================================================\n",
            " GROUP PLAN: [0:+1] [1:+1] [2:+1] [3:+1] [4:+1]\n",
            "============================================================================\n",
            " [G011c_FIX2_A100_CUBLAS] M=512 N=512 K=512 primes=5 groups=5 iters=5061 time=280.04 ms (captured: 5 graphs)\n",
            "  Logical MACs/s:        2425.654 G-mac/s\n",
            "  Modular MACs/s:        12128.269 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     3032.067 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0xcd6db40eed6a5b75\n",
            "  GRAPH: 5 streams/graphs (auto, contiguous slices), prepack=YES, cuBLAS TensorOp path\n",
            "============================================================================\n",
            "============================================================================\n",
            " A100 MULTIGRAPH CUBLAS  GPU=NVIDIA A100-SXM4-40GB  CC=8.0  SMs=108\n",
            " M=1024 N=1024 K=2048 primes=9  ms_min=400  seed=12345\n",
            " WMMA quick probe: 184246.4 G-ops/s\n",
            "============================================================================\n",
            " GROUP PLAN: [0:+2] [2:+2] [4:+2] [6:+1] [7:+1] [8:+1]\n",
            " ** On entry to GEMM_EX  parameter number 9 had an illegal value\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "g011c_fix2_a100_multigraph_cublas.cu(85): warning #177-D: function \"preset_small\" was declared but never referenced\n",
            "  static Args preset_small(){ return {512,512,512,5,280,12345}; }\n",
            "              ^\n",
            "\n",
            "Remark: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "g011c_fix2_a100_multigraph_cublas.cu(86): warning #177-D: function \"preset_big\" was declared but never referenced\n",
            "  static Args preset_big() { return {1024,1024,2048,9,400,12345}; }\n",
            "              ^\n",
            "\n",
            "CUBLAS ERROR @GemmStridedBatchedEx(cap): 7\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command 'b'set -euo pipefail\\n\\ncat > g011c_fix2_a100_multigraph_cublas.cu <<\\'CU\\'\\n#include <bits/stdc++.h>\\n#include <cuda_runtime.h>\\n#include <cublas_v2.h>\\nusing namespace std; using clk = chrono::high_resolution_clock;\\n\\n#define CUDA_OK(x,msg) do{ cudaError_t _e=(x); if(_e!=cudaSuccess){ \\\\\\n  fprintf(stderr,\"CUDA ERROR @%s: %s\\\\n\", msg, cudaGetErrorString(_e)); exit(1);} }while(0)\\n#define CUBLAS_OK(x,msg) do{ cublasStatus_t _s=(x); if(_s!=CUBLAS_STATUS_SUCCESS){ \\\\\\n  fprintf(stderr,\"CUBLAS ERROR @%s: %d\\\\n\", msg, (int)_s); exit(1);} }while(0)\\n\\n// primes \\xe2\\x89\\xa4127 (pairwise coprime)\\nstatic vector<int> primes_list(int P){\\n  static const int all[] = {127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53,47,43,41,37,31,29,23,19,17,13,11,7,5,3};\\n  int maxP=(int)(sizeof(all)/sizeof(all[0]));\\n  return vector<int>(all, all+max(1,min(P,maxP)));\\n}\\n\\n// tiny WMMA probe (just for choosing groups)\\n#if __CUDACC_VER_MAJOR__ >= 11\\n#include <mma.h>\\nusing namespace nvcuda;\\n__global__ void probe_wmma(int iters,int kf, unsigned* sink){\\n#if __CUDA_ARCH__ >= 800\\n  if(threadIdx.x>=32) return;\\n  __shared__ half A[256], B[256];\\n  for(int i=threadIdx.x;i<256;i+=32){ A[i]=__float2half((i%7)*0.125f); B[i]=__float2half(((i*3)%11)*0.09375f); }\\n  __syncthreads();\\n  wmma::fragment<wmma::matrix_a,16,16,16,half,wmma::row_major> a;\\n  wmma::fragment<wmma::matrix_b,16,16,16,half,wmma::row_major> b;\\n  wmma::fragment<wmma::accumulator,16,16,16,float> c;\\n  unsigned s=0;\\n  for(int it=0;it<iters;++it){\\n    wmma::load_matrix_sync(a,A,16);\\n    wmma::load_matrix_sync(b,B,16);\\n    wmma::fill_fragment(c,0.f);\\n    #pragma unroll 4\\n    for(int kk=0; kk<kf; ++kk){ wmma::mma_sync(c,a,b,c); }\\n    if(threadIdx.x==0){ float acc=0.f; for(int i=0;i<c.num_elements;i++) acc+=c.x[i]; s^=__float_as_uint(acc); }\\n  }\\n  if(threadIdx.x==0) sink[blockIdx.x]=s;\\n#else\\n  if(threadIdx.x==0 && blockIdx.x==0) sink[0]=42;\\n#endif\\n}\\nstatic double wmma_gops_probe(){\\n  int blocks=1024, iters=256, kf=64;\\n  unsigned *d=nullptr; CUDA_OK(cudaMalloc(&d, blocks*sizeof(unsigned)),\"probe malloc\");\\n  cudaEvent_t a,b; cudaEventCreate(&a); cudaEventCreate(&b);\\n  cudaEventRecord(a);\\n  probe_wmma<<<blocks,32>>>(iters,kf,d);\\n  CUDA_OK(cudaGetLastError(),\"probe launch\");\\n  cudaEventRecord(b); cudaEventSynchronize(b);\\n  float ms=0.f; cudaEventElapsedTime(&ms,a,b);\\n  cudaEventDestroy(a); cudaEventDestroy(b);\\n  cudaFree(d);\\n  double ops = (double)blocks * iters * kf * 8192.0;\\n  return (ops/(ms/1000.0))/1e9;\\n}\\n#else\\nstatic double wmma_gops_probe(){ return 0.0; }\\n#endif\\n\\n// FNV1a64 + CRT hash (strided)\\nstatic inline uint64_t fnv1a64_append(uint64_t h,const void* d,size_t n){\\n  const uint8_t* p=(const uint8_t*)d; for(size_t i=0;i<n;i++){ h^=p[i]; h*=1099511628211ULL; } return h;\\n}\\nstatic uint64_t crt_hash_strided(const vector<int>&, const vector<int32_t>& Ccol,\\n                                 int M,int N,int stride_elems){\\n  uint64_t h=1469598103934665603ULL; size_t tot=(size_t)M*(size_t)N;\\n  int K=(int)min(tot,(size_t)8192); size_t idx=0;\\n  for(int i=0;i<K;i++){ idx=(idx+(size_t)stride_elems)%tot; int32_t v=Ccol[idx]; h=fnv1a64_append(h,&v,sizeof(v)); }\\n  return h;\\n}\\n\\n// int32 -> int8 mod p (row-major)\\n__global__ void pack_mod_s8(const int32_t* __restrict__ X, int8_t* __restrict__ Y,\\n                            int rows,int cols,int ld_in,int p){\\n  int c=blockIdx.x*blockDim.x+threadIdx.x;\\n  int r=blockIdx.y*blockDim.y+threadIdx.y;\\n  if(r>=rows||c>=cols) return;\\n  int32_t v=X[(size_t)r*ld_in + c]; int t=v%p; if(t<0) t+=p; Y[(size_t)r*cols + c]=(int8_t)t;\\n}\\n\\nstruct Args{ int M,N,K,P,ms_min,seed; };\\nstatic Args preset_small(){ return {512,512,512,5,280,12345}; }\\nstatic Args preset_big()  { return {1024,1024,2048,9,400,12345}; }\\n\\nstatic int choose_groups_auto(int P, int sms, double wmma_gops){\\n  int base = max(2, min(8, sms/20));\\n  if(wmma_gops > 20000.0) base = min(base+1, 8);\\n  return max(1, min(P, base));\\n}\\n\\nint run_case(const Args a){\\n  cudaDeviceProp prop{}; CUDA_OK(cudaGetDeviceProperties(&prop,0),\"props\");\\n  double gops = wmma_gops_probe();\\n\\n  printf(\"============================================================================\\\\n\");\\n  printf(\" A100 MULTIGRAPH CUBLAS  GPU=%s  CC=%d.%d  SMs=%d\\\\n\", prop.name, prop.major, prop.minor, prop.multiProcessorCount);\\n  printf(\" M=%d N=%d K=%d primes=%d  ms_min=%d  seed=%d\\\\n\", a.M,a.N,a.K,a.P,a.ms_min,a.seed);\\n  printf(\" WMMA quick probe: %.1f G-ops/s\\\\n\", gops);\\n  printf(\"============================================================================\\\\n\");\\n\\n  // host data\\n  mt19937 rng(a.seed); uniform_int_distribution<int> d(-700,700);\\n  vector<int32_t> Ah((size_t)a.M*a.K), Bh((size_t)a.K*a.N);\\n  for(auto&x:Ah) x=d(rng); for(auto&x:Bh) x=d(rng);\\n  auto P = primes_list(a.P);\\n\\n  // device src\\n  int32_t *dA32=nullptr,*dB32=nullptr; CUDA_OK(cudaMalloc(&dA32,sizeof(int32_t)*(size_t)a.M*a.K),\"malloc dA32\");\\n  CUDA_OK(cudaMalloc(&dB32,sizeof(int32_t)*(size_t)a.K*a.N),\"malloc dB32\");\\n  CUDA_OK(cudaMemcpy(dA32,Ah.data(),sizeof(int32_t)*(size_t)a.M*a.K,cudaMemcpyHostToDevice),\"cpy A\");\\n  CUDA_OK(cudaMemcpy(dB32,Bh.data(),sizeof(int32_t)*(size_t)a.K*a.N,cudaMemcpyHostToDevice),\"cpy B\");\\n\\n  // residues\\n  size_t strideA=(size_t)a.M*a.K, strideB=(size_t)a.K*a.N, strideC=(size_t)a.M*a.N;\\n  int8_t *dA8=nullptr,*dB8=nullptr; int32_t* dC32=nullptr;\\n  CUDA_OK(cudaMalloc(&dA8, strideA*a.P),\"malloc dA8\");\\n  CUDA_OK(cudaMalloc(&dB8, strideB*a.P),\"malloc dB8\");\\n  CUDA_OK(cudaMalloc(&dC32,strideC*a.P*sizeof(int32_t)),\"malloc dC32\");\\n\\n  // prepack on GPU\\n  dim3 blk(64,4);\\n  dim3 gA((a.K+blk.x-1)/blk.x,(a.M+blk.y-1)/blk.y);\\n  dim3 gB((a.N+blk.x-1)/blk.x,(a.K+blk.y-1)/blk.y);\\n  for(int pi=0;pi<a.P;++pi){\\n    int p=P[pi];\\n    pack_mod_s8<<<gA,blk>>>(dA32,dA8+pi*strideA, a.M,a.K,a.K,p);\\n    pack_mod_s8<<<gB,blk>>>(dB32,dB8+pi*strideB, a.K,a.N,a.N,p);\\n  }\\n  CUDA_OK(cudaDeviceSynchronize(),\"prepack sync\");\\n\\n  // choose groups and slice CONTIGUOUS chunks\\n  int groups = choose_groups_auto(a.P, prop.multiProcessorCount, gops);\\n  vector<pair<int,int>> slices; slices.reserve(groups); // (p0, cnt)\\n  {\\n    int base=a.P/groups, rem=a.P%groups, p0=0;\\n    for(int gi=0; gi<groups; ++gi){\\n      int cnt = base + (gi<rem?1:0);\\n      slices.push_back({p0,cnt});\\n      p0 += cnt;\\n    }\\n  }\\n  // pretty print plan\\n  fprintf(stdout, \" GROUP PLAN:\"); for(int gi=0; gi<groups; ++gi){ fprintf(stdout,\" [%d:+%d]\", slices[gi].first, slices[gi].second); } fprintf(stdout,\"\\\\n\");\\n\\n  struct GCtx{ cudaStream_t s{}; cudaGraph_t g{}; cudaGraphExec_t ge{}; cublasHandle_t h{}; int p0=0,cnt=0; };\\n  vector<GCtx> ctx(groups);\\n\\n  // Column-major trick: C^T = B^T \\xc2\\xb7 A^T\\n  int m = a.N, n = a.M, k = a.K;\\n  int lda = a.N, ldb = a.K, ldc = a.N;            // leading dims for column-major views\\n  long long sA = (long long)strideB;              // B^T stride (source was row-major B)\\n  long long sB = (long long)strideA;              // A^T stride (source was row-major A)\\n  long long sC = (long long)strideC;              // C^T stride\\n  const int32_t alpha = 1, beta = 0;\\n\\n  for(int gi=0; gi<groups; ++gi){\\n    ctx[gi].p0=slices[gi].first; ctx[gi].cnt=slices[gi].second;\\n    if(!ctx[gi].cnt) continue;\\n\\n    CUDA_OK(cudaStreamCreateWithFlags(&ctx[gi].s, cudaStreamNonBlocking),\"stream\");\\n    CUBLAS_OK(cublasCreate(&ctx[gi].h),\"cublasCreate\");\\n    CUBLAS_OK(cublasSetStream(ctx[gi].h, ctx[gi].s),\"setStream\");\\n    CUBLAS_OK(cublasSetMathMode(ctx[gi].h, CUBLAS_TENSOR_OP_MATH),\"mathMode\");\\n\\n    const void* A8 = dA8 + (size_t)ctx[gi].p0 * strideA;\\n    const void* B8 = dB8 + (size_t)ctx[gi].p0 * strideB;\\n    void*       C32= dC32+ (size_t)ctx[gi].p0 * strideC;\\n\\n    CUDA_OK(cudaStreamBeginCapture(ctx[gi].s, cudaStreamCaptureModeGlobal),\"begin cap\");\\n    CUBLAS_OK(\\n      cublasGemmStridedBatchedEx(\\n        ctx[gi].h,\\n        CUBLAS_OP_T, CUBLAS_OP_T,\\n        m, n, k,\\n        &alpha,\\n        B8, CUDA_R_8I, lda, sA,\\n        A8, CUDA_R_8I, ldb, sB,\\n        &beta,\\n        C32, CUDA_R_32I, ldc, sC,\\n        ctx[gi].cnt,\\n        CUBLAS_COMPUTE_32I, CUBLAS_GEMM_DEFAULT_TENSOR_OP\\n      ), \"GemmStridedBatchedEx(cap)\"\\n    );\\n    CUDA_OK(cudaStreamEndCapture(ctx[gi].s, &ctx[gi].g),\"end cap\");\\n    CUDA_OK(cudaGraphInstantiate(&ctx[gi].ge, ctx[gi].g, nullptr, nullptr, 0),\"instantiate\");\\n  }\\n\\n  // run graphs\\n  auto t0=clk::now(); int iters=0;\\n  do{\\n    for(int gi=0; gi<groups; ++gi) if(ctx[gi].cnt) CUDA_OK(cudaGraphLaunch(ctx[gi].ge, ctx[gi].s),\"launch\");\\n    for(int gi=0; gi<groups; ++gi) if(ctx[gi].cnt) CUDA_OK(cudaStreamSynchronize(ctx[gi].s),\"sync\");\\n    ++iters;\\n  }while( chrono::duration<double,milli>(clk::now()-t0).count() < a.ms_min );\\n  double wall_ms = chrono::duration<double,milli>(clk::now()-t0).count();\\n  double secs = wall_ms/1000.0;\\n\\n  // copy prime0 slice back (C^T for prime 0) to hash\\n  vector<int32_t> C0((size_t)a.M*a.N);\\n  CUDA_OK(cudaMemcpy(C0.data(), dC32 + 0*(size_t)strideC, sizeof(int32_t)*strideC, cudaMemcpyDeviceToHost),\"cpyC0\");\\n  uint64_t hsh = crt_hash_strided(P, C0, a.M, a.N, (int)(((size_t)a.M*(size_t)a.N)/8192 + 1));\\n\\n  const double logical_macs = (double)a.M*(double)a.N*(double)a.K;\\n  const double logical = (logical_macs*iters)/secs/1e9;\\n  const double modular = logical * a.P;\\n  const double dp4a_eq = modular / 4.0;\\n\\n  printf(\"============================================================================\\\\n\");\\n  printf(\" [G011c_FIX2_A100_CUBLAS] M=%d N=%d K=%d primes=%d groups=%d iters=%d time=%.2f ms (captured: %d graphs)\\\\n\",\\n         a.M,a.N,a.K,a.P,groups,iters,wall_ms,groups);\\n  printf(\"  Logical MACs/s:        %.3f G-mac/s\\\\n\", logical);\\n  printf(\"  Modular MACs/s:        %.3f G-mac/s   (\\xc3\\x97 primes)\\\\n\", modular);\\n  printf(\"  dp4a-equiv inst/s:     %.3f G-inst/s  (~ modular/4)\\\\n\", dp4a_eq);\\n  printf(\"  CRT (strided) hash:    0x%016llx\\\\n\", (unsigned long long)hsh);\\n  printf(\"  GRAPH: %d streams/graphs (auto, contiguous slices), prepack=YES, cuBLAS TensorOp path\\\\n\", groups);\\n  printf(\"============================================================================\\\\n\");\\n\\n  for(int gi=0; gi<groups; ++gi){\\n    if(ctx[gi].ge) cudaGraphExecDestroy(ctx[gi].ge);\\n    if(ctx[gi].g)  cudaGraphDestroy(ctx[gi].g);\\n    if(ctx[gi].h)  cublasDestroy(ctx[gi].h);\\n    if(ctx[gi].s)  cudaStreamDestroy(ctx[gi].s);\\n  }\\n  cudaFree(dA32); cudaFree(dB32); cudaFree(dA8); cudaFree(dB8); cudaFree(dC32);\\n  return 0;\\n}\\n\\nint main(){\\n  // small then big\\n  run_case({512,512,512,5,280,12345});\\n  run_case({1024,1024,2048,9,400,12345});\\n  return 0;\\n}\\nCU\\n\\n# Build for A100 (sm_80)\\nnvcc -O3 -std=c++17 g011c_fix2_a100_multigraph_cublas.cu -o g011c_fix2_a100_multigraph_cublas -lcublas -arch=sm_80\\n\\necho\\necho \"=== G011c_FIX2: small (A100) \\xe2\\x80\\x94 512^3, 5 primes ===\"\\n./g011c_fix2_a100_multigraph_cublas\\n\\necho\\necho \"=== G011c_FIX2: big (A100) \\xe2\\x80\\x94 1024x2048x1024, 9 primes ===\"\\n./g011c_fix2_a100_multigraph_cublas\\n'' returned non-zero exit status 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-485735939.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'set -euo pipefail\\n\\ncat > g011c_fix2_a100_multigraph_cublas.cu <<\\'CU\\'\\n#include <bits/stdc++.h>\\n#include <cuda_runtime.h>\\n#include <cublas_v2.h>\\nusing namespace std; using clk = chrono::high_resolution_clock;\\n\\n#define CUDA_OK(x,msg) do{ cudaError_t _e=(x); if(_e!=cudaSuccess){ \\\\\\n  fprintf(stderr,\"CUDA ERROR @%s: %s\\\\n\", msg, cudaGetErrorString(_e)); exit(1);} }while(0)\\n#define CUBLAS_OK(x,msg) do{ cublasStatus_t _s=(x); if(_s!=CUBLAS_STATUS_SUCCESS){ \\\\\\n  fprintf(stderr,\"CUBLAS ERROR @%s: %d\\\\n\", msg, (int)_s); exit(1);} }while(0)\\n\\n// primes ≤127 (pairwise coprime)\\nstatic vector<int> primes_list(int P){\\n  static const int all[] = {127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53,47,43,41,37,31,29,23,19,17,13,11,7,5,3};\\n  int maxP=(int)(sizeof(all)/sizeof(all[0]));\\n  return vector<int>(all, all+max(1,min(P,maxP)));\\n}\\n\\n// tiny WMMA probe (just for choosing groups)\\n#if __CUDACC_VER_MAJOR__ >= 11\\n#include <mma.h>\\nusing namespace nvcuda;\\n__global__ void probe_wmma(int iters,int kf, unsigned* sink){\\n#if __CUDA_ARCH__ >= 800\\n  if(threadIdx.x>=32) return;\\n  __shared__ half A[256], B[256];\\n  for(int i=threadIdx.x;i<256;i+=32){ A[i]=__float2half((i%7)*0.125f); B[i]=__float2half(((i*3)%11)*0.09375f); }\\n  __syncthreads();\\n  wmma::fragment<wmma::matrix_a,16,16,16,half,wmma::row_...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'set -euo pipefail\\n\\ncat > g011c_fix2_a100_multigraph_cublas.cu <<\\'CU\\'\\n#include <bits/stdc++.h>\\n#include <cuda_runtime.h>\\n#include <cublas_v2.h>\\nusing namespace std; using clk = chrono::high_resolution_clock;\\n\\n#define CUDA_OK(x,msg) do{ cudaError_t _e=(x); if(_e!=cudaSuccess){ \\\\\\n  fprintf(stderr,\"CUDA ERROR @%s: %s\\\\n\", msg, cudaGetErrorString(_e)); exit(1);} }while(0)\\n#define CUBLAS_OK(x,msg) do{ cublasStatus_t _s=(x); if(_s!=CUBLAS_STATUS_SUCCESS){ \\\\\\n  fprintf(stderr,\"CUBLAS ERROR @%s: %d\\\\n\", msg, (int)_s); exit(1);} }while(0)\\n\\n// primes \\xe2\\x89\\xa4127 (pairwise coprime)\\nstatic vector<int> primes_list(int P){\\n  static const int all[] = {127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53,47,43,41,37,31,29,23,19,17,13,11,7,5,3};\\n  int maxP=(int)(sizeof(all)/sizeof(all[0]));\\n  return vector<int>(all, all+max(1,min(P,maxP)));\\n}\\n\\n// tiny WMMA probe (just for choosing groups)\\n#if __CUDACC_VER_MAJOR__ >= 11\\n#include <mma.h>\\nusing namespace nvcuda;\\n__global__ void probe_wmma(int iters,int kf, unsigned* sink){\\n#if __CUDA_ARCH__ >= 800\\n  if(threadIdx.x>=32) return;\\n  __shared__ half A[256], B[256];\\n  for(int i=threadIdx.x;i<256;i+=32){ A[i]=__float2half((i%7)*0.125f); B[i]=__float2half(((i*3)%11)*0.09375f); }\\n  __syncthreads();\\n  wmma::fragment<wmma::matrix_a,16,16,16,half,wmma::row_major> a;\\n  wmma::fragment<wmma::matrix_b,16,16,16,half,wmma::row_major> b;\\n  wmma::fragment<wmma::accumulator,16,16,16,..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "cat > g011c_fix3_a100_multigraph_cublas.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "using namespace std; using clk = chrono::high_resolution_clock;\n",
        "\n",
        "#define CUDA_OK(x,msg) do{ cudaError_t _e=(x); if(_e!=cudaSuccess){ \\\n",
        "  fprintf(stderr,\"CUDA ERROR @%s: %s\\n\", msg, cudaGetErrorString(_e)); exit(1);} }while(0)\n",
        "#define CUBLAS_OK(x,msg) do{ cublasStatus_t _s=(x); if(_s!=CUBLAS_STATUS_SUCCESS){ \\\n",
        "  fprintf(stderr,\"CUBLAS ERROR @%s: %d\\n\", msg, (int)_s); exit(1);} }while(0)\n",
        "\n",
        "// primes ≤127 (pairwise coprime)\n",
        "static vector<int> primes_list(int P){\n",
        "  static const int all[] = {127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53,47,43,41,37,31,29,23,19,17,13,11,7,5,3};\n",
        "  int maxP=(int)(sizeof(all)/sizeof(all[0])); P=max(1,min(P,maxP));\n",
        "  return vector<int>(all, all+P);\n",
        "}\n",
        "\n",
        "// tiny WMMA probe (just to print headroom)\n",
        "#if __CUDACC_VER_MAJOR__ >= 11\n",
        "#include <mma.h>\n",
        "using namespace nvcuda;\n",
        "__global__ void probe_wmma(int iters,int kf, unsigned* sink){\n",
        "#if __CUDA_ARCH__ >= 800\n",
        "  if(threadIdx.x>=32) return;\n",
        "  __shared__ half A[256], B[256];\n",
        "  for(int i=threadIdx.x;i<256;i+=32){ A[i]=__float2half((i%7)*0.125f); B[i]=__float2half(((i*3)%11)*0.09375f); }\n",
        "  __syncthreads();\n",
        "  wmma::fragment<wmma::matrix_a,16,16,16,half,wmma::row_major> a;\n",
        "  wmma::fragment<wmma::matrix_b,16,16,16,half,wmma::row_major> b;\n",
        "  wmma::fragment<wmma::accumulator,16,16,16,float> c;\n",
        "  unsigned s=0;\n",
        "  for(int it=0;it<iters;++it){\n",
        "    wmma::load_matrix_sync(a,A,16);\n",
        "    wmma::load_matrix_sync(b,B,16);\n",
        "    wmma::fill_fragment(c,0.f);\n",
        "    #pragma unroll 4\n",
        "    for(int kk=0; kk<kf; ++kk){ wmma::mma_sync(c,a,b,c); }\n",
        "    if(threadIdx.x==0){ float acc=0.f; for(int i=0;i<c.num_elements;i++) acc+=c.x[i]; s^=__float_as_uint(acc); }\n",
        "  }\n",
        "  if(threadIdx.x==0) sink[blockIdx.x]=s;\n",
        "#else\n",
        "  if(threadIdx.x==0 && blockIdx.x==0) sink[0]=42;\n",
        "#endif\n",
        "}\n",
        "static double wmma_gops_probe(){\n",
        "  int blocks=1024, iters=256, kf=64;\n",
        "  unsigned *d=nullptr; CUDA_OK(cudaMalloc(&d, blocks*sizeof(unsigned)),\"probe malloc\");\n",
        "  cudaEvent_t a,b; cudaEventCreate(&a); cudaEventCreate(&b);\n",
        "  cudaEventRecord(a);\n",
        "  probe_wmma<<<blocks,32>>>(iters,kf,d);\n",
        "  CUDA_OK(cudaGetLastError(),\"probe launch\");\n",
        "  cudaEventRecord(b); cudaEventSynchronize(b);\n",
        "  float ms=0.f; cudaEventElapsedTime(&ms,a,b);\n",
        "  cudaEventDestroy(a); cudaEventDestroy(b);\n",
        "  cudaFree(d);\n",
        "  double ops = (double)blocks * iters * kf * 8192.0;\n",
        "  return (ops/(ms/1000.0))/1e9;\n",
        "}\n",
        "#else\n",
        "static double wmma_gops_probe(){ return 0.0; }\n",
        "#endif\n",
        "\n",
        "// simple CRT hash (strided)\n",
        "static inline uint64_t fnv1a64_append(uint64_t h,const void* d,size_t n){\n",
        "  const uint8_t* p=(const uint8_t*)d; for(size_t i=0;i<n;i++){ h^=p[i]; h*=1099511628211ULL; } return h;\n",
        "}\n",
        "static uint64_t crt_hash_strided(const vector<int>&, const vector<int32_t>& Ccol,\n",
        "                                 int M,int N,int stride_elems){\n",
        "  uint64_t h=1469598103934665603ULL; size_t tot=(size_t)M*(size_t)N;\n",
        "  int K=(int)min(tot,(size_t)8192); size_t idx=0;\n",
        "  for(int i=0;i<K;i++){ idx=(idx+(size_t)stride_elems)%tot; int32_t v=Ccol[idx]; h=fnv1a64_append(h,&v,sizeof(v)); }\n",
        "  return h;\n",
        "}\n",
        "\n",
        "// int32 -> int8 mod p (row-major)\n",
        "__global__ void pack_mod_s8(const int32_t* __restrict__ X, int8_t* __restrict__ Y,\n",
        "                            int rows,int cols,int ld_in,int p){\n",
        "  int c=blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  int r=blockIdx.y*blockDim.y+threadIdx.y;\n",
        "  if(r>=rows||c>=cols) return;\n",
        "  int32_t v=X[(size_t)r*ld_in + c]; int t=v%p; if(t<0) t+=p; Y[(size_t)r*cols + c]=(int8_t)t;\n",
        "}\n",
        "\n",
        "struct Args{ int M,N,K,P,ms_min,seed; };\n",
        "static Args preset_small(){ return {512,512,512,5,280,12345}; }\n",
        "static Args preset_big()  { return {1024,1024,2048,9,400,12345}; }\n",
        "\n",
        "static int choose_groups_auto(int P, int sms, double wmma_gops){\n",
        "  int base = max(2, min(8, sms/20));\n",
        "  if(wmma_gops > 20000.0) base = min(base+1, 8);\n",
        "  return max(1, min(P, base));\n",
        "}\n",
        "\n",
        "int run_case(const Args a){\n",
        "  cudaDeviceProp prop{}; CUDA_OK(cudaGetDeviceProperties(&prop,0),\"props\");\n",
        "  double gops = wmma_gops_probe();\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" A100 MULTIGRAPH CUBLAS  GPU=%s  CC=%d.%d  SMs=%d\\n\", prop.name, prop.major, prop.minor, prop.multiProcessorCount);\n",
        "  printf(\" M=%d N=%d K=%d primes=%d  ms_min=%d  seed=%d\\n\", a.M,a.N,a.K,a.P,a.ms_min,a.seed);\n",
        "  printf(\" WMMA quick probe: %.1f G-ops/s\\n\", gops);\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  // host data\n",
        "  mt19937 rng(a.seed); uniform_int_distribution<int> d(-700,700);\n",
        "  vector<int32_t> Ah((size_t)a.M*a.K), Bh((size_t)a.K*a.N);\n",
        "  for(auto&x:Ah) x=d(rng); for(auto&x:Bh) x=d(rng);\n",
        "  auto P = primes_list(a.P);\n",
        "\n",
        "  // device src\n",
        "  int32_t *dA32=nullptr,*dB32=nullptr; CUDA_OK(cudaMalloc(&dA32,sizeof(int32_t)*(size_t)a.M*a.K),\"malloc dA32\");\n",
        "  CUDA_OK(cudaMalloc(&dB32,sizeof(int32_t)*(size_t)a.K*a.N),\"malloc dB32\");\n",
        "  CUDA_OK(cudaMemcpy(dA32,Ah.data(),sizeof(int32_t)*(size_t)a.M*a.K,cudaMemcpyHostToDevice),\"cpy A\");\n",
        "  CUDA_OK(cudaMemcpy(dB32,Bh.data(),sizeof(int32_t)*(size_t)a.K*a.N,cudaMemcpyHostToDevice),\"cpy B\");\n",
        "\n",
        "  // residues storage\n",
        "  size_t strideA=(size_t)a.M*a.K, strideB=(size_t)a.K*a.N, strideC=(size_t)a.M*a.N;\n",
        "  int8_t *dA8=nullptr,*dB8=nullptr; int32_t* dC32=nullptr;\n",
        "  CUDA_OK(cudaMalloc(&dA8, strideA*a.P),\"malloc dA8\");\n",
        "  CUDA_OK(cudaMalloc(&dB8, strideB*a.P),\"malloc dB8\");\n",
        "  CUDA_OK(cudaMalloc(&dC32,strideC*a.P*sizeof(int32_t)),\"malloc dC32\");\n",
        "\n",
        "  // prepack residues on GPU\n",
        "  dim3 blk(64,4);\n",
        "  dim3 gA((a.K+blk.x-1)/blk.x,(a.M+blk.y-1)/blk.y);\n",
        "  dim3 gB((a.N+blk.x-1)/blk.x,(a.K+blk.y-1)/blk.y);\n",
        "  for(int pi=0;pi<a.P;++pi){\n",
        "    int p=P[pi];\n",
        "    pack_mod_s8<<<gA,blk>>>(dA32,dA8+pi*strideA, a.M,a.K,a.K,p);\n",
        "    pack_mod_s8<<<gB,blk>>>(dB32,dB8+pi*strideB, a.K,a.N,a.N,p);\n",
        "  }\n",
        "  CUDA_OK(cudaDeviceSynchronize(),\"prepack sync\");\n",
        "\n",
        "  // choose contiguous slices across groups\n",
        "  int groups = choose_groups_auto(a.P, prop.multiProcessorCount, gops);\n",
        "  vector<pair<int,int>> slices; slices.reserve(groups);\n",
        "  { int base=a.P/groups, rem=a.P%groups, p0=0;\n",
        "    for(int gi=0; gi<groups; ++gi){ int cnt=base+(gi<rem?1:0); slices.push_back({p0,cnt}); p0+=cnt; } }\n",
        "  fprintf(stdout,\" GROUP PLAN:\"); for(auto s: slices) fprintf(stdout,\" [%d:+%d]\", s.first, s.second); fprintf(stdout,\"\\n\");\n",
        "\n",
        "  struct GCtx{ cudaStream_t s{}; cudaGraph_t g{}; cudaGraphExec_t ge{}; cublasHandle_t h{}; int p0=0,cnt=0; };\n",
        "  vector<GCtx> ctx(groups);\n",
        "\n",
        "  // Column-major trick: compute C^T (N×M) = B^T (N×K) · A^T (K×M)\n",
        "  const int m = a.N, n = a.M, k = a.K;\n",
        "  // FIX: leading dimensions for transposed operands:\n",
        "  const int lda = k;   // must be >= k when transa == T\n",
        "  const int ldb = n;   // must be >= n when transb == T\n",
        "  const int ldc = m;   // rows of C^T\n",
        "  const long long sA = (long long)strideB; // B^T stride (src was row-major B)\n",
        "  const long long sB = (long long)strideA; // A^T stride (src was row-major A)\n",
        "  const long long sC = (long long)strideC; // C^T stride\n",
        "  const int32_t alpha = 1, beta = 0;\n",
        "\n",
        "  for(int gi=0; gi<groups; ++gi){\n",
        "    ctx[gi].p0=slices[gi].first; ctx[gi].cnt=slices[gi].second;\n",
        "    if(!ctx[gi].cnt) continue;\n",
        "\n",
        "    CUDA_OK(cudaStreamCreateWithFlags(&ctx[gi].s, cudaStreamNonBlocking),\"stream\");\n",
        "    CUBLAS_OK(cublasCreate(&ctx[gi].h),\"cublasCreate\");\n",
        "    CUBLAS_OK(cublasSetStream(ctx[gi].h, ctx[gi].s),\"setStream\");\n",
        "    CUBLAS_OK(cublasSetMathMode(ctx[gi].h, CUBLAS_TENSOR_OP_MATH),\"mathMode\");\n",
        "\n",
        "    const void* A8 = dA8 + (size_t)ctx[gi].p0 * strideA; // will be op(B) in math, but is \"A\" arg\n",
        "    const void* B8 = dB8 + (size_t)ctx[gi].p0 * strideB; // will be op(A) in math, but is \"B\" arg\n",
        "    void*       C32= dC32+ (size_t)ctx[gi].p0 * strideC;\n",
        "\n",
        "    CUDA_OK(cudaStreamBeginCapture(ctx[gi].s, cudaStreamCaptureModeGlobal),\"begin cap\");\n",
        "    CUBLAS_OK(\n",
        "      cublasGemmStridedBatchedEx(\n",
        "        ctx[gi].h,\n",
        "        CUBLAS_OP_T, CUBLAS_OP_T,\n",
        "        m, n, k,\n",
        "        &alpha,\n",
        "        B8, CUDA_R_8I, lda, sA,   // A operand = B^T, requires lda >= k\n",
        "        A8, CUDA_R_8I, ldb, sB,   // B operand = A^T, requires ldb >= n\n",
        "        &beta,\n",
        "        C32, CUDA_R_32I, ldc, sC,\n",
        "        ctx[gi].cnt,\n",
        "        CUBLAS_COMPUTE_32I, CUBLAS_GEMM_DEFAULT_TENSOR_OP\n",
        "      ), \"GemmStridedBatchedEx(cap)\"\n",
        "    );\n",
        "    CUDA_OK(cudaStreamEndCapture(ctx[gi].s, &ctx[gi].g),\"end cap\");\n",
        "    CUDA_OK(cudaGraphInstantiate(&ctx[gi].ge, ctx[gi].g, nullptr, nullptr, 0),\"instantiate\");\n",
        "  }\n",
        "\n",
        "  // run graphs until ms_min\n",
        "  auto t0=clk::now(); int iters=0;\n",
        "  do{\n",
        "    for(int gi=0; gi<groups; ++gi) if(ctx[gi].cnt) CUDA_OK(cudaGraphLaunch(ctx[gi].ge, ctx[gi].s),\"launch\");\n",
        "    for(int gi=0; gi<groups; ++gi) if(ctx[gi].cnt) CUDA_OK(cudaStreamSynchronize(ctx[gi].s),\"sync\");\n",
        "    ++iters;\n",
        "  }while( chrono::duration<double,milli>(clk::now()-t0).count() < a.ms_min );\n",
        "  double wall_ms = chrono::duration<double,milli>(clk::now()-t0).count();\n",
        "  double secs = wall_ms/1000.0;\n",
        "\n",
        "  // copy prime0 slice back (C^T for prime 0) to hash\n",
        "  vector<int32_t> C0((size_t)a.M*a.N);\n",
        "  CUDA_OK(cudaMemcpy(C0.data(), dC32 + 0*(size_t)strideC, sizeof(int32_t)*strideC, cudaMemcpyDeviceToHost),\"cpyC0\");\n",
        "  uint64_t hsh = crt_hash_strided(P, C0, a.M, a.N, (int)(((size_t)a.M*(size_t)a.N)/8192 + 1));\n",
        "\n",
        "  const double logical_macs = (double)a.M*(double)a.N*(double)a.K;\n",
        "  const double logical = (logical_macs*iters)/secs/1e9;\n",
        "  const double modular = logical * a.P;\n",
        "  const double dp4a_eq = modular / 4.0;\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [G011c_FIX3_A100_CUBLAS] M=%d N=%d K=%d primes=%d groups=%d iters=%d time=%.2f ms (captured: %d graphs)\\n\",\n",
        "         a.M,a.N,a.K,a.P,groups,iters,wall_ms,groups);\n",
        "  printf(\"  Logical MACs/s:        %.3f G-mac/s\\n\", logical);\n",
        "  printf(\"  Modular MACs/s:        %.3f G-mac/s   (× primes)\\n\", modular);\n",
        "  printf(\"  dp4a-equiv inst/s:     %.3f G-inst/s  (~ modular/4)\\n\", dp4a_eq);\n",
        "  printf(\"  CRT (strided) hash:    0x%016llx\\n\", (unsigned long long)hsh);\n",
        "  printf(\"  GRAPH: %d streams/graphs (auto, contiguous slices), prepack=YES, cuBLAS TensorOp path\\n\", groups);\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  for(int gi=0; gi<groups; ++gi){\n",
        "    if(ctx[gi].ge) cudaGraphExecDestroy(ctx[gi].ge);\n",
        "    if(ctx[gi].g)  cudaGraphDestroy(ctx[gi].g);\n",
        "    if(ctx[gi].h)  cublasDestroy(ctx[gi].h);\n",
        "    if(ctx[gi].s)  cudaStreamDestroy(ctx[gi].s);\n",
        "  }\n",
        "  cudaFree(dA32); cudaFree(dB32); cudaFree(dA8); cudaFree(dB8); cudaFree(dC32);\n",
        "  return 0;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  run_case(preset_small());\n",
        "  run_case(preset_big());\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# Build for A100 (sm_80)\n",
        "nvcc -O3 -std=c++17 g011c_fix3_a100_multigraph_cublas.cu -o g011c_fix3_a100_multigraph_cublas -lcublas -arch=sm_80\n",
        "\n",
        "echo\n",
        "echo \"=== G011c_FIX3: small (A100) — 512^3, 5 primes ===\"\n",
        "./g011c_fix3_a100_multigraph_cublas\n",
        "\n",
        "echo\n",
        "echo \"=== G011c_FIX3: big (A100) — 1024x2048x1024, 9 primes ===\"\n",
        "./g011c_fix3_a100_multigraph_cublas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v1Dl-IlnWcP",
        "outputId": "363e99ca-7463-4a71-cb5a-dbbf1bf31d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== G011c_FIX3: small (A100) — 512^3, 5 primes ===\n",
            "============================================================================\n",
            " A100 MULTIGRAPH CUBLAS  GPU=NVIDIA A100-SXM4-40GB  CC=8.0  SMs=108\n",
            " M=512 N=512 K=512 primes=5  ms_min=280  seed=12345\n",
            " WMMA quick probe: 126979.9 G-ops/s\n",
            "============================================================================\n",
            " GROUP PLAN: [0:+1] [1:+1] [2:+1] [3:+1] [4:+1]\n",
            "============================================================================\n",
            " [G011c_FIX3_A100_CUBLAS] M=512 N=512 K=512 primes=5 groups=5 iters=5347 time=280.05 ms (captured: 5 graphs)\n",
            "  Logical MACs/s:        2562.651 G-mac/s\n",
            "  Modular MACs/s:        12813.257 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     3203.314 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0xcd6db40eed6a5b75\n",
            "  GRAPH: 5 streams/graphs (auto, contiguous slices), prepack=YES, cuBLAS TensorOp path\n",
            "============================================================================\n",
            "============================================================================\n",
            " A100 MULTIGRAPH CUBLAS  GPU=NVIDIA A100-SXM4-40GB  CC=8.0  SMs=108\n",
            " M=1024 N=1024 K=2048 primes=9  ms_min=400  seed=12345\n",
            " WMMA quick probe: 180165.6 G-ops/s\n",
            "============================================================================\n",
            " GROUP PLAN: [0:+2] [2:+2] [4:+2] [6:+1] [7:+1] [8:+1]\n",
            "============================================================================\n",
            " [G011c_FIX3_A100_CUBLAS] M=1024 N=1024 K=2048 primes=9 groups=6 iters=702 time=400.32 ms (captured: 6 graphs)\n",
            "  Logical MACs/s:        3765.830 G-mac/s\n",
            "  Modular MACs/s:        33892.472 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     8473.118 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x0d8141cdf20975e6\n",
            "  GRAPH: 6 streams/graphs (auto, contiguous slices), prepack=YES, cuBLAS TensorOp path\n",
            "============================================================================\n",
            "\n",
            "=== G011c_FIX3: big (A100) — 1024x2048x1024, 9 primes ===\n",
            "============================================================================\n",
            " A100 MULTIGRAPH CUBLAS  GPU=NVIDIA A100-SXM4-40GB  CC=8.0  SMs=108\n",
            " M=512 N=512 K=512 primes=5  ms_min=280  seed=12345\n",
            " WMMA quick probe: 163480.8 G-ops/s\n",
            "============================================================================\n",
            " GROUP PLAN: [0:+1] [1:+1] [2:+1] [3:+1] [4:+1]\n",
            "============================================================================\n",
            " [G011c_FIX3_A100_CUBLAS] M=512 N=512 K=512 primes=5 groups=5 iters=5866 time=280.03 ms (captured: 5 graphs)\n",
            "  Logical MACs/s:        2811.514 G-mac/s\n",
            "  Modular MACs/s:        14057.569 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     3514.392 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0xcd6db40eed6a5b75\n",
            "  GRAPH: 5 streams/graphs (auto, contiguous slices), prepack=YES, cuBLAS TensorOp path\n",
            "============================================================================\n",
            "============================================================================\n",
            " A100 MULTIGRAPH CUBLAS  GPU=NVIDIA A100-SXM4-40GB  CC=8.0  SMs=108\n",
            " M=1024 N=1024 K=2048 primes=9  ms_min=400  seed=12345\n",
            " WMMA quick probe: 183702.6 G-ops/s\n",
            "============================================================================\n",
            " GROUP PLAN: [0:+2] [2:+2] [4:+2] [6:+1] [7:+1] [8:+1]\n",
            "============================================================================\n",
            " [G011c_FIX3_A100_CUBLAS] M=1024 N=1024 K=2048 primes=9 groups=6 iters=702 time=400.46 ms (captured: 6 graphs)\n",
            "  Logical MACs/s:        3764.482 G-mac/s\n",
            "  Modular MACs/s:        33880.337 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     8470.084 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x0d8141cdf20975e6\n",
            "  GRAPH: 6 streams/graphs (auto, contiguous slices), prepack=YES, cuBLAS TensorOp path\n",
            "============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# ============================\n",
        "# G011e_FIX2 :: A100 cuBLAS INT8 RNS (MULTIGRAPH, no cuBLASLt)\n",
        "# Correct leading dims for opA=opB=T: lda=K, ldb=M, ldc=N.\n",
        "# ============================\n",
        "\n",
        "cat > g011e_fix2_a100_cublas_multigraph.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "using namespace std;\n",
        "using clk = chrono::high_resolution_clock;\n",
        "\n",
        "#define CUDA_OK(x,msg) do{ cudaError_t _e=(x); if(_e!=cudaSuccess){ \\\n",
        "  fprintf(stderr,\"CUDA ERROR @%s: %s\\n\", msg, cudaGetErrorString(_e)); exit(1);} }while(0)\n",
        "#define CUBLAS_OK(x,msg) do{ cublasStatus_t _s=(x); if(_s!=CUBLAS_STATUS_SUCCESS){ \\\n",
        "  fprintf(stderr,\"CUBLAS ERROR @%s: %d\\n\", msg, (int)_s); exit(1);} }while(0)\n",
        "\n",
        "static vector<int> primes_list(int P){\n",
        "  static const int all[] = {127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53,47,43,41,37,31,29,23,19,17,13,11,7,5,3};\n",
        "  int maxP=(int)(sizeof(all)/sizeof(all[0]));\n",
        "  return vector<int>(all, all+max(1,min(P,maxP)));\n",
        "}\n",
        "\n",
        "struct Args {\n",
        "  int M=1024, N=1024, K=2048;\n",
        "  int primes=9, ms_min=400, recon_K=8192;\n",
        "  long long cert_bound=0; unsigned seed=12345u;\n",
        "  int groups=0; // 0 => one graph per prime\n",
        "};\n",
        "static void parse(int argc,char**argv,Args& a){\n",
        "  for(int i=1;i<argc;i++){\n",
        "    string s=argv[i]; auto need=[&]{ if(i+1>=argc){fprintf(stderr,\"Missing %s\\n\",s.c_str()); exit(1);} };\n",
        "    if(s==\"--M\"){need(); a.M=atoi(argv[++i]);}\n",
        "    else if(s==\"--N\"){need(); a.N=atoi(argv[++i]);}\n",
        "    else if(s==\"--K\"){need(); a.K=atoi(argv[++i]);}\n",
        "    else if(s==\"--primes\"){need(); a.primes=atoi(argv[++i]);}\n",
        "    else if(s==\"--ms\"){need(); a.ms_min=atoi(argv[++i]);}\n",
        "    else if(s==\"--reconK\"){need(); a.recon_K=atoi(argv[++i]);}\n",
        "    else if(s==\"--cert\"){need(); a.cert_bound=atoll(argv[++i]);}\n",
        "    else if(s==\"--seed\"){need(); a.seed=(unsigned)strtoul(argv[++i],nullptr,10);}\n",
        "    else if(s==\"--groups\"){need(); a.groups=atoi(argv[++i]);}\n",
        "  }\n",
        "}\n",
        "\n",
        "static void fill_rand_i32(vector<int32_t>&A,int R,int C,unsigned seed,int maxAbs=700){\n",
        "  mt19937 rng(seed); uniform_int_distribution<int>d(-maxAbs,maxAbs);\n",
        "  A.resize((size_t)R*C); for(auto&x:A)x=d(rng);\n",
        "}\n",
        "static uint64_t mix64(uint64_t x){ x^=x>>33; x*=0xff51afd7ed558ccdULL; x^=x>>33; x*=0xc4ceb9fe1a85ec53ULL; x^=x>>33; return x; }\n",
        "static uint64_t crt_hash_strided(const vector<int>& P, const vector<int32_t>& C, int M,int N, int strideK){\n",
        "  uint64_t h=0; size_t S=(size_t)M*N, step=max(1, (int)(S/max(1,strideK)));\n",
        "  for(size_t i=0;i<S; i+=step){\n",
        "    int64_t v=C[i]; for(int p: P){ int32_t r=(int32_t)(v%p); if(r<0) r+=p; h ^= mix64(((uint64_t)p<<32) ^ (uint64_t)r); }\n",
        "  }\n",
        "  return h;\n",
        "}\n",
        "\n",
        "// pack residues to int8 (row-major in/out)\n",
        "__global__ void k_pack_mod_s8_rowmajor(const int32_t* __restrict__ A, int8_t* __restrict__ Ao,\n",
        "                                       int R, int C, int p){\n",
        "  int idx = blockDim.x*blockIdx.x + threadIdx.x;\n",
        "  int n = R*C;\n",
        "  for(int i=idx;i<n;i+=gridDim.x*blockDim.x){\n",
        "    int32_t v = A[i]%p; if(v<0) v += p;\n",
        "    Ao[i] = (int8_t)(v);\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc,char**argv){\n",
        "  ios::sync_with_stdio(false);\n",
        "  Args a; parse(argc,argv,a);\n",
        "\n",
        "  cudaDeviceProp prop; CUDA_OK(cudaGetDeviceProperties(&prop,0),\"props\");\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" A100 MULTIGRAPH CUBLAS  GPU=%s  CC=%d.%d  SMs=%d\\n\", prop.name, prop.major, prop.minor, prop.multiProcessorCount);\n",
        "  printf(\" M=%d N=%d K=%d primes=%d  ms_min=%d  seed=%u  groups=%d\\n\", a.M,a.N,a.K,a.primes,a.ms_min,a.seed,a.groups);\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  // host matrices (row-major)\n",
        "  vector<int32_t> hA,hB; fill_rand_i32(hA,a.M,a.K,a.seed+1); fill_rand_i32(hB,a.K,a.N,a.seed+2);\n",
        "\n",
        "  // device int32 sources\n",
        "  int32_t *dA32=nullptr, *dB32=nullptr;\n",
        "  size_t bytesA32=(size_t)a.M*a.K*sizeof(int32_t);\n",
        "  size_t bytesB32=(size_t)a.K*a.N*sizeof(int32_t);\n",
        "  CUDA_OK(cudaMalloc(&dA32, bytesA32), \"malloc A32\");\n",
        "  CUDA_OK(cudaMalloc(&dB32, bytesB32), \"malloc B32\");\n",
        "  CUDA_OK(cudaMemcpy(dA32, hA.data(), bytesA32, cudaMemcpyHostToDevice), \"cpy A32\");\n",
        "  CUDA_OK(cudaMemcpy(dB32, hB.data(), bytesB32, cudaMemcpyHostToDevice), \"cpy B32\");\n",
        "\n",
        "  // primes + prepack int8 residues once\n",
        "  vector<int> P = primes_list(a.primes);\n",
        "  const int Pn = (int)P.size();\n",
        "  int8_t *dA8=nullptr, *dB8=nullptr;\n",
        "  size_t bytesA8=(size_t)a.M*a.K*Pn*sizeof(int8_t);\n",
        "  size_t bytesB8=(size_t)a.K*a.N*Pn*sizeof(int8_t);\n",
        "  CUDA_OK(cudaMalloc(&dA8, bytesA8), \"malloc A8\");\n",
        "  CUDA_OK(cudaMalloc(&dB8, bytesB8), \"malloc B8\");\n",
        "\n",
        "  dim3 tpb(512);\n",
        "  dim3 gA((a.M*a.K + tpb.x-1)/tpb.x), gB((a.K*a.N + tpb.x-1)/tpb.x);\n",
        "  for(int pi=0; pi<Pn; ++pi){\n",
        "    k_pack_mod_s8_rowmajor<<<gA,tpb>>>(dA32, dA8 + (size_t)pi*a.M*a.K, a.M,a.K, P[pi]);\n",
        "    k_pack_mod_s8_rowmajor<<<gB,tpb>>>(dB32, dB8 + (size_t)pi*a.K*a.N, a.K,a.N, P[pi]);\n",
        "  }\n",
        "  CUDA_OK(cudaDeviceSynchronize(),\"pack sync\");\n",
        "\n",
        "  // output s32 (C^T buffers)\n",
        "  int32_t* dC32=nullptr; size_t bytesC32=(size_t)a.M*a.N*Pn*sizeof(int32_t);\n",
        "  CUDA_OK(cudaMalloc(&dC32, bytesC32), \"malloc C32\");\n",
        "  CUDA_OK(cudaMemset(dC32, 0, bytesC32), \"memset C\");\n",
        "\n",
        "  // cuBLAS handle + TensorOps\n",
        "  cublasHandle_t h; CUBLAS_OK(cublasCreate(&h), \"cublasCreate\");\n",
        "  CUBLAS_OK(cublasSetMathMode(h, CUBLAS_TENSOR_OP_MATH), \"mathMode\");\n",
        "\n",
        "  // GEMM (C^T = B^T · A^T), column-major convention\n",
        "  const int m = a.N, n = a.M, k = a.K;\n",
        "  const int lda = a.K;   // rows of A (pre-transpose)  *** FIXED ***\n",
        "  const int ldb = a.M;   // rows of B (pre-transpose)  *** FIXED ***\n",
        "  const int ldc = a.N;   // rows of C^T\n",
        "  const cublasOperation_t opA = CUBLAS_OP_T;\n",
        "  const cublasOperation_t opB = CUBLAS_OP_T;\n",
        "  const int32_t alpha = 1, beta = 0;\n",
        "\n",
        "  // simple plan: one graph per prime unless --groups overrides\n",
        "  int groups = (a.groups<=0)? Pn : max(1, min(a.groups, Pn));\n",
        "  vector<int> gsize(groups,0); for(int i=0;i<Pn;i++) gsize[i%groups]++;\n",
        "  vector<cudaStream_t> streams(groups); vector<cudaGraph_t> graphs(groups); vector<cudaGraphExec_t> execs(groups);\n",
        "\n",
        "  for(int gi=0, off=0; gi<groups; ++gi){\n",
        "    CUDA_OK(cudaStreamCreateWithFlags(&streams[gi], cudaStreamNonBlocking), \"stream\");\n",
        "    CUBLAS_OK(cublasSetStream(h, streams[gi]), \"setStream\");\n",
        "    int gsz = gsize[gi];\n",
        "    CUDA_OK(cudaStreamBeginCapture(streams[gi], cudaStreamCaptureModeGlobal), \"cap begin\");\n",
        "    for(int s=0; s<gsz; ++s){\n",
        "      int pi = off + s;\n",
        "      const int8_t* Ap = dB8 + (size_t)pi*a.K*a.N;  // A operand buffer (B row-major), opA=T\n",
        "      const int8_t* Bp = dA8 + (size_t)pi*a.M*a.K;  // B operand buffer (A row-major), opB=T\n",
        "      int32_t*      Cp = dC32 + (size_t)pi*a.M*a.N; // C^T buffer (N×M)\n",
        "      CUBLAS_OK(\n",
        "        cublasGemmEx(\n",
        "          h, opA, opB, m, n, k,\n",
        "          &alpha,\n",
        "          Ap, CUDA_R_8I, lda,\n",
        "          Bp, CUDA_R_8I, ldb,\n",
        "          &beta,\n",
        "          Cp, CUDA_R_32I, ldc,\n",
        "          CUDA_R_32I, CUBLAS_GEMM_DEFAULT_TENSOR_OP\n",
        "        ),\n",
        "        \"GemmEx(TC)\"\n",
        "      );\n",
        "    }\n",
        "    CUDA_OK(cudaStreamEndCapture(streams[gi], &graphs[gi]), \"cap end\");\n",
        "    CUDA_OK(cudaGraphInstantiate(&execs[gi], graphs[gi], nullptr, nullptr, 0), \"graph inst\");\n",
        "    off += gsz;\n",
        "  }\n",
        "\n",
        "  int iters=0; auto t0=clk::now();\n",
        "  do{\n",
        "    for(int gi=0; gi<groups; ++gi) CUDA_OK(cudaGraphLaunch(execs[gi], streams[gi]), \"launch\");\n",
        "    for(int gi=0; gi<groups; ++gi) CUDA_OK(cudaStreamSynchronize(streams[gi]), \"sync\");\n",
        "    iters++;\n",
        "  }while( chrono::duration_cast<chrono::milliseconds>(clk::now()-t0).count() < a.ms_min );\n",
        "  double secs = chrono::duration<double>(clk::now()-t0).count();\n",
        "\n",
        "  vector<int32_t> hC((size_t)a.M*a.N*Pn);\n",
        "  CUDA_OK(cudaMemcpy(hC.data(), dC32, bytesC32, cudaMemcpyDeviceToHost), \"cpy C\");\n",
        "  uint64_t H=0;\n",
        "  for(int pi=0; pi<Pn; ++pi){\n",
        "    const int32_t* Cp = hC.data() + (size_t)pi*a.M*a.N;\n",
        "    vector<int32_t> tmp(Cp, Cp + (size_t)a.M*a.N);\n",
        "    H ^= crt_hash_strided(P, tmp, a.N, a.M, a.recon_K); // buffer is C^T\n",
        "  }\n",
        "\n",
        "  double logical_macs = (double)a.M*(double)a.N*(double)a.K;\n",
        "  double logical_total = logical_macs * iters;\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [G011e_FIX2_A100_CUBLAS] M=%d N=%d K=%d primes=%d groups=%d iters=%d time=%.2f ms (captured: %d graphs)\\n\",\n",
        "         a.M,a.N,a.K,(int)P.size(),groups,iters, secs*1000.0, groups);\n",
        "  printf(\"  Logical MACs/s:        %.3f G-mac/s\\n\",  (logical_total/secs)/1e9);\n",
        "  printf(\"  Modular MACs/s:        %.3f G-mac/s   (× primes)\\n\", (logical_total*P.size()/secs)/1e9);\n",
        "  printf(\"  dp4a-equiv inst/s:     %.3f G-inst/s  (~ modular/4)\\n\", (logical_total*P.size()/secs)/1e9/4.0);\n",
        "  printf(\"  CRT (strided) hash:    0x%016llx\\n\", (unsigned long long)H);\n",
        "  printf(\"  GRAPH: %d streams/graphs (auto), prepack=YES, cuBLAS GemmEx TensorOp path\\n\", groups);\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  for(int gi=0; gi<groups; ++gi){ cudaGraphExecDestroy(execs[gi]); cudaGraphDestroy(graphs[gi]); cudaStreamDestroy(streams[gi]); }\n",
        "  cublasDestroy(h);\n",
        "  cudaFree(dC32); cudaFree(dA8); cudaFree(dB8); cudaFree(dA32); cudaFree(dB32);\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# build (A100)\n",
        "nvcc -O3 -std=c++17 -arch=sm_80 g011e_fix2_a100_cublas_multigraph.cu -lcublas -o g011e_fix2\n",
        "\n",
        "# small\n",
        "./g011e_fix2 --M 512 --N 512 --K 512 --primes 5 --ms 280 --groups 0\n",
        "\n",
        "# big\n",
        "./g011e_fix2 --M 1024 --N 1024 --K 2048 --primes 9 --ms 450 --groups 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mUYGCT3xyJs",
        "outputId": "5a331ed0-dfd6-4ae2-d14c-3626aa3fdb8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================\n",
            " A100 MULTIGRAPH CUBLAS  GPU=NVIDIA A100-SXM4-40GB  CC=8.0  SMs=108\n",
            " M=512 N=512 K=512 primes=5  ms_min=280  seed=12345  groups=0\n",
            "============================================================================\n",
            "============================================================================\n",
            " [G011e_FIX2_A100_CUBLAS] M=512 N=512 K=512 primes=5 groups=5 iters=5312 time=280.06 ms (captured: 5 graphs)\n",
            "  Logical MACs/s:        2545.759 G-mac/s\n",
            "  Modular MACs/s:        12728.796 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     3182.199 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0xb3061dcd5dc79195\n",
            "  GRAPH: 5 streams/graphs (auto), prepack=YES, cuBLAS GemmEx TensorOp path\n",
            "============================================================================\n",
            "============================================================================\n",
            " A100 MULTIGRAPH CUBLAS  GPU=NVIDIA A100-SXM4-40GB  CC=8.0  SMs=108\n",
            " M=1024 N=1024 K=2048 primes=9  ms_min=450  seed=12345  groups=0\n",
            "============================================================================\n",
            "============================================================================\n",
            " [G011e_FIX2_A100_CUBLAS] M=1024 N=1024 K=2048 primes=9 groups=9 iters=790 time=450.38 ms (captured: 9 graphs)\n",
            "  Logical MACs/s:        3766.885 G-mac/s\n",
            "  Modular MACs/s:        33901.969 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     8475.492 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x4733534a0c23d3a3\n",
            "  GRAPH: 9 streams/graphs (auto), prepack=YES, cuBLAS GemmEx TensorOp path\n",
            "============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# ============================\n",
        "# G011e_FIX2 :: A100 cuBLAS INT8 RNS (MULTIGRAPH, no cuBLASLt)\n",
        "# Correct leading dims for opA=opB=T: lda=K, ldb=M, ldc=N.\n",
        "# ============================\n",
        "\n",
        "cat > g011e_fix2_a100_cublas_multigraph.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "using namespace std;\n",
        "using clk = chrono::high_resolution_clock;\n",
        "\n",
        "#define CUDA_OK(x,msg) do{ cudaError_t _e=(x); if(_e!=cudaSuccess){ \\\n",
        "  fprintf(stderr,\"CUDA ERROR @%s: %s\\n\", msg, cudaGetErrorString(_e)); exit(1);} }while(0)\n",
        "#define CUBLAS_OK(x,msg) do{ cublasStatus_t _s=(x); if(_s!=CUBLAS_STATUS_SUCCESS){ \\\n",
        "  fprintf(stderr,\"CUBLAS ERROR @%s: %d\\n\", msg, (int)_s); exit(1);} }while(0)\n",
        "\n",
        "static vector<int> primes_list(int P){\n",
        "  static const int all[] = {127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53,47,43,41,37,31,29,23,19,17,13,11,7,5,3};\n",
        "  int maxP=(int)(sizeof(all)/sizeof(all[0]));\n",
        "  return vector<int>(all, all+max(1,min(P,maxP)));\n",
        "}\n",
        "\n",
        "struct Args {\n",
        "  int M=1024, N=1024, K=2048;\n",
        "  int primes=9, ms_min=400, recon_K=8192;\n",
        "  long long cert_bound=0; unsigned seed=12345u;\n",
        "  int groups=0; // 0 => one graph per prime\n",
        "};\n",
        "static void parse(int argc,char**argv,Args& a){\n",
        "  for(int i=1;i<argc;i++){\n",
        "    string s=argv[i]; auto need=[&]{ if(i+1>=argc){fprintf(stderr,\"Missing %s\\n\",s.c_str()); exit(1);} };\n",
        "    if(s==\"--M\"){need(); a.M=atoi(argv[++i]);}\n",
        "    else if(s==\"--N\"){need(); a.N=atoi(argv[++i]);}\n",
        "    else if(s==\"--K\"){need(); a.K=atoi(argv[++i]);}\n",
        "    else if(s==\"--primes\"){need(); a.primes=atoi(argv[++i]);}\n",
        "    else if(s==\"--ms\"){need(); a.ms_min=atoi(argv[++i]);}\n",
        "    else if(s==\"--reconK\"){need(); a.recon_K=atoi(argv[++i]);}\n",
        "    else if(s==\"--cert\"){need(); a.cert_bound=atoll(argv[++i]);}\n",
        "    else if(s==\"--seed\"){need(); a.seed=(unsigned)strtoul(argv[++i],nullptr,10);}\n",
        "    else if(s==\"--groups\"){need(); a.groups=atoi(argv[++i]);}\n",
        "  }\n",
        "}\n",
        "\n",
        "static void fill_rand_i32(vector<int32_t>&A,int R,int C,unsigned seed,int maxAbs=700){\n",
        "  mt19937 rng(seed); uniform_int_distribution<int>d(-maxAbs,maxAbs);\n",
        "  A.resize((size_t)R*C); for(auto&x:A)x=d(rng);\n",
        "}\n",
        "static uint64_t mix64(uint64_t x){ x^=x>>33; x*=0xff51afd7ed558ccdULL; x^=x>>33; x*=0xc4ceb9fe1a85ec53ULL; x^=x>>33; return x; }\n",
        "static uint64_t crt_hash_strided(const vector<int>& P, const vector<int32_t>& C, int M,int N, int strideK){\n",
        "  uint64_t h=0; size_t S=(size_t)M*N, step=max(1, (int)(S/max(1,strideK)));\n",
        "  for(size_t i=0;i<S; i+=step){\n",
        "    int64_t v=C[i]; for(int p: P){ int32_t r=(int32_t)(v%p); if(r<0) r+=p; h ^= mix64(((uint64_t)p<<32) ^ (uint64_t)r); }\n",
        "  }\n",
        "  return h;\n",
        "}\n",
        "\n",
        "// pack residues to int8 (row-major in/out)\n",
        "__global__ void k_pack_mod_s8_rowmajor(const int32_t* __restrict__ A, int8_t* __restrict__ Ao,\n",
        "                                       int R, int C, int p){\n",
        "  int idx = blockDim.x*blockIdx.x + threadIdx.x;\n",
        "  int n = R*C;\n",
        "  for(int i=idx;i<n;i+=gridDim.x*blockDim.x){\n",
        "    int32_t v = A[i]%p; if(v<0) v += p;\n",
        "    Ao[i] = (int8_t)(v);\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc,char**argv){\n",
        "  ios::sync_with_stdio(false);\n",
        "  Args a; parse(argc,argv,a);\n",
        "\n",
        "  cudaDeviceProp prop; CUDA_OK(cudaGetDeviceProperties(&prop,0),\"props\");\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" A100 MULTIGRAPH CUBLAS  GPU=%s  CC=%d.%d  SMs=%d\\n\", prop.name, prop.major, prop.minor, prop.multiProcessorCount);\n",
        "  printf(\" M=%d N=%d K=%d primes=%d  ms_min=%d  seed=%u  groups=%d\\n\", a.M,a.N,a.K,a.primes,a.ms_min,a.seed,a.groups);\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  // host matrices (row-major)\n",
        "  vector<int32_t> hA,hB; fill_rand_i32(hA,a.M,a.K,a.seed+1); fill_rand_i32(hB,a.K,a.N,a.seed+2);\n",
        "\n",
        "  // device int32 sources\n",
        "  int32_t *dA32=nullptr, *dB32=nullptr;\n",
        "  size_t bytesA32=(size_t)a.M*a.K*sizeof(int32_t);\n",
        "  size_t bytesB32=(size_t)a.K*a.N*sizeof(int32_t);\n",
        "  CUDA_OK(cudaMalloc(&dA32, bytesA32), \"malloc A32\");\n",
        "  CUDA_OK(cudaMalloc(&dB32, bytesB32), \"malloc B32\");\n",
        "  CUDA_OK(cudaMemcpy(dA32, hA.data(), bytesA32, cudaMemcpyHostToDevice), \"cpy A32\");\n",
        "  CUDA_OK(cudaMemcpy(dB32, hB.data(), bytesB32, cudaMemcpyHostToDevice), \"cpy B32\");\n",
        "\n",
        "  // primes + prepack int8 residues once\n",
        "  vector<int> P = primes_list(a.primes);\n",
        "  const int Pn = (int)P.size();\n",
        "  int8_t *dA8=nullptr, *dB8=nullptr;\n",
        "  size_t bytesA8=(size_t)a.M*a.K*Pn*sizeof(int8_t);\n",
        "  size_t bytesB8=(size_t)a.K*a.N*Pn*sizeof(int8_t);\n",
        "  CUDA_OK(cudaMalloc(&dA8, bytesA8), \"malloc A8\");\n",
        "  CUDA_OK(cudaMalloc(&dB8, bytesB8), \"malloc B8\");\n",
        "\n",
        "  dim3 tpb(512);\n",
        "  dim3 gA((a.M*a.K + tpb.x-1)/tpb.x), gB((a.K*a.N + tpb.x-1)/tpb.x);\n",
        "  for(int pi=0; pi<Pn; ++pi){\n",
        "    k_pack_mod_s8_rowmajor<<<gA,tpb>>>(dA32, dA8 + (size_t)pi*a.M*a.K, a.M,a.K, P[pi]);\n",
        "    k_pack_mod_s8_rowmajor<<<gB,tpb>>>(dB32, dB8 + (size_t)pi*a.K*a.N, a.K,a.N, P[pi]);\n",
        "  }\n",
        "  CUDA_OK(cudaDeviceSynchronize(),\"pack sync\");\n",
        "\n",
        "  // output s32 (C^T buffers)\n",
        "  int32_t* dC32=nullptr; size_t bytesC32=(size_t)a.M*a.N*Pn*sizeof(int32_t);\n",
        "  CUDA_OK(cudaMalloc(&dC32, bytesC32), \"malloc C32\");\n",
        "  CUDA_OK(cudaMemset(dC32, 0, bytesC32), \"memset C\");\n",
        "\n",
        "  // cuBLAS handle + TensorOps\n",
        "  cublasHandle_t h; CUBLAS_OK(cublasCreate(&h), \"cublasCreate\");\n",
        "  CUBLAS_OK(cublasSetMathMode(h, CUBLAS_TENSOR_OP_MATH), \"mathMode\");\n",
        "\n",
        "  // GEMM (C^T = B^T · A^T), column-major convention\n",
        "  const int m = a.N, n = a.M, k = a.K;\n",
        "  const int lda = a.K;   // rows of A (pre-transpose)  *** FIXED ***\n",
        "  const int ldb = a.M;   // rows of B (pre-transpose)  *** FIXED ***\n",
        "  const int ldc = a.N;   // rows of C^T\n",
        "  const cublasOperation_t opA = CUBLAS_OP_T;\n",
        "  const cublasOperation_t opB = CUBLAS_OP_T;\n",
        "  const int32_t alpha = 1, beta = 0;\n",
        "\n",
        "  // simple plan: one graph per prime unless --groups overrides\n",
        "  int groups = (a.groups<=0)? Pn : max(1, min(a.groups, Pn));\n",
        "  vector<int> gsize(groups,0); for(int i=0;i<Pn;i++) gsize[i%groups]++;\n",
        "  vector<cudaStream_t> streams(groups); vector<cudaGraph_t> graphs(groups); vector<cudaGraphExec_t> execs(groups);\n",
        "\n",
        "  for(int gi=0, off=0; gi<groups; ++gi){\n",
        "    CUDA_OK(cudaStreamCreateWithFlags(&streams[gi], cudaStreamNonBlocking), \"stream\");\n",
        "    CUBLAS_OK(cublasSetStream(h, streams[gi]), \"setStream\");\n",
        "    int gsz = gsize[gi];\n",
        "    CUDA_OK(cudaStreamBeginCapture(streams[gi], cudaStreamCaptureModeGlobal), \"cap begin\");\n",
        "    for(int s=0; s<gsz; ++s){\n",
        "      int pi = off + s;\n",
        "      const int8_t* Ap = dB8 + (size_t)pi*a.K*a.N;  // A operand buffer (B row-major), opA=T\n",
        "      const int8_t* Bp = dA8 + (size_t)pi*a.M*a.K;  // B operand buffer (A row-major), opB=T\n",
        "      int32_t*      Cp = dC32 + (size_t)pi*a.M*a.N; // C^T buffer (N×M)\n",
        "      CUBLAS_OK(\n",
        "        cublasGemmEx(\n",
        "          h, opA, opB, m, n, k,\n",
        "          &alpha,\n",
        "          Ap, CUDA_R_8I, lda,\n",
        "          Bp, CUDA_R_8I, ldb,\n",
        "          &beta,\n",
        "          Cp, CUDA_R_32I, ldc,\n",
        "          CUDA_R_32I, CUBLAS_GEMM_DEFAULT_TENSOR_OP\n",
        "        ),\n",
        "        \"GemmEx(TC)\"\n",
        "      );\n",
        "    }\n",
        "    CUDA_OK(cudaStreamEndCapture(streams[gi], &graphs[gi]), \"cap end\");\n",
        "    CUDA_OK(cudaGraphInstantiate(&execs[gi], graphs[gi], nullptr, nullptr, 0), \"graph inst\");\n",
        "    off += gsz;\n",
        "  }\n",
        "\n",
        "  int iters=0; auto t0=clk::now();\n",
        "  do{\n",
        "    for(int gi=0; gi<groups; ++gi) CUDA_OK(cudaGraphLaunch(execs[gi], streams[gi]), \"launch\");\n",
        "    for(int gi=0; gi<groups; ++gi) CUDA_OK(cudaStreamSynchronize(streams[gi]), \"sync\");\n",
        "    iters++;\n",
        "  }while( chrono::duration_cast<chrono::milliseconds>(clk::now()-t0).count() < a.ms_min );\n",
        "  double secs = chrono::duration<double>(clk::now()-t0).count();\n",
        "\n",
        "  vector<int32_t> hC((size_t)a.M*a.N*Pn);\n",
        "  CUDA_OK(cudaMemcpy(hC.data(), dC32, bytesC32, cudaMemcpyDeviceToHost), \"cpy C\");\n",
        "  uint64_t H=0;\n",
        "  for(int pi=0; pi<Pn; ++pi){\n",
        "    const int32_t* Cp = hC.data() + (size_t)pi*a.M*a.N;\n",
        "    vector<int32_t> tmp(Cp, Cp + (size_t)a.M*a.N);\n",
        "    H ^= crt_hash_strided(P, tmp, a.N, a.M, a.recon_K); // buffer is C^T\n",
        "  }\n",
        "\n",
        "  double logical_macs = (double)a.M*(double)a.N*(double)a.K;\n",
        "  double logical_total = logical_macs * iters;\n",
        "\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [G011e_FIX2_A100_CUBLAS] M=%d N=%d K=%d primes=%d groups=%d iters=%d time=%.2f ms (captured: %d graphs)\\n\",\n",
        "         a.M,a.N,a.K,(int)P.size(),groups,iters, secs*1000.0, groups);\n",
        "  printf(\"  Logical MACs/s:        %.3f G-mac/s\\n\",  (logical_total/secs)/1e9);\n",
        "  printf(\"  Modular MACs/s:        %.3f G-mac/s   (× primes)\\n\", (logical_total*P.size()/secs)/1e9);\n",
        "  printf(\"  dp4a-equiv inst/s:     %.3f G-inst/s  (~ modular/4)\\n\", (logical_total*P.size()/secs)/1e9/4.0);\n",
        "  printf(\"  CRT (strided) hash:    0x%016llx\\n\", (unsigned long long)H);\n",
        "  printf(\"  GRAPH: %d streams/graphs (auto), prepack=YES, cuBLAS GemmEx TensorOp path\\n\", groups);\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  for(int gi=0; gi<groups; ++gi){ cudaGraphExecDestroy(execs[gi]); cudaGraphDestroy(graphs[gi]); cudaStreamDestroy(streams[gi]); }\n",
        "  cublasDestroy(h);\n",
        "  cudaFree(dC32); cudaFree(dA8); cudaFree(dB8); cudaFree(dA32); cudaFree(dB32);\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# build (A100)\n",
        "nvcc -O3 -std=c++17 -arch=sm_80 g011e_fix2_a100_cublas_multigraph.cu -lcublas -o g011e_fix2\n",
        "\n",
        "# small\n",
        "./g011e_fix2 --M 512 --N 512 --K 512 --primes 5 --ms 280 --groups 0\n",
        "\n",
        "# big\n",
        "./g011e_fix2 --M 1024 --N 1024 --K 2048 --primes 9 --ms 450 --groups 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDjepXnxzDVf",
        "outputId": "d17d32dd-66ab-45b9-9cd5-43aede26facb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================\n",
            " A100 MULTIGRAPH CUBLAS  GPU=NVIDIA A100-SXM4-40GB  CC=8.0  SMs=108\n",
            " M=512 N=512 K=512 primes=5  ms_min=280  seed=12345  groups=0\n",
            "============================================================================\n",
            "============================================================================\n",
            " [G011e_FIX2_A100_CUBLAS] M=512 N=512 K=512 primes=5 groups=5 iters=5233 time=280.04 ms (captured: 5 graphs)\n",
            "  Logical MACs/s:        2508.103 G-mac/s\n",
            "  Modular MACs/s:        12540.517 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     3135.129 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0xb3061dcd5dc79195\n",
            "  GRAPH: 5 streams/graphs (auto), prepack=YES, cuBLAS GemmEx TensorOp path\n",
            "============================================================================\n",
            "============================================================================\n",
            " A100 MULTIGRAPH CUBLAS  GPU=NVIDIA A100-SXM4-40GB  CC=8.0  SMs=108\n",
            " M=1024 N=1024 K=2048 primes=9  ms_min=450  seed=12345  groups=0\n",
            "============================================================================\n",
            "============================================================================\n",
            " [G011e_FIX2_A100_CUBLAS] M=1024 N=1024 K=2048 primes=9 groups=9 iters=789 time=450.34 ms (captured: 9 graphs)\n",
            "  Logical MACs/s:        3762.415 G-mac/s\n",
            "  Modular MACs/s:        33861.736 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     8465.434 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x4733534a0c23d3a3\n",
            "  GRAPH: 9 streams/graphs (auto), prepack=YES, cuBLAS GemmEx TensorOp path\n",
            "============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# =============================================================================\n",
        "# G011f_FIX :: A100 cuBLAS INT8 RNS (MULTIGRAPH + SPLIT-K + on-GPU reduce)\n",
        "#  - Exact RNS int8 (primes ≤127), s8×s8→s32, TensorOp math (A100)\n",
        "#  - One-time GPU prepack (int32→int8) for A,B (row-major sources)\n",
        "#  - Per-prime Split-K: K sliced into 'splitK' stripes; each slice is its own\n",
        "#    captured cuBLAS GEMM in its own stream + its own cuBLAS handle\n",
        "#  - After all slices, sum partial C_s on GPU → exact int32 result\n",
        "#  - Transpose trick: compute Cᵗ (N×M, col-major) = Bᵗ(N×K) · Aᵗ(K×M)\n",
        "#    **Correct leading dims** for this path: lda=N, ldb=M, ldc=N\n",
        "#  - Build (A100):  nvcc -O3 -std=c++17 -arch=sm_80 g011f_fix_splitk_multigraph.cu -lcublas -o g011f_fix\n",
        "# =============================================================================\n",
        "\n",
        "cat > g011f_fix_splitk_multigraph.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "using namespace std; using clk = chrono::high_resolution_clock;\n",
        "\n",
        "#define CUDA_OK(x,msg) do{ cudaError_t _e=(x); if(_e!=cudaSuccess){ \\\n",
        "  fprintf(stderr,\"CUDA ERROR @%s: %s\\n\", msg, cudaGetErrorString(_e)); exit(1);} }while(0)\n",
        "#define CUBLAS_OK(x,msg) do{ cublasStatus_t _s=(x); if(_s!=CUBLAS_STATUS_SUCCESS){ \\\n",
        "  fprintf(stderr,\"CUBLAS ERROR @%s: %d\\n\", msg, (int)_s); exit(1);} }while(0)\n",
        "\n",
        "static vector<int> primes_list(int P){\n",
        "  static const int all[] = {127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53,47,43,41,37,31,29,23,19,17,13,11,7,5,3};\n",
        "  int maxP=(int)(sizeof(all)/sizeof(all[0])); P=max(1,min(P,maxP));\n",
        "  return vector<int>(all, all+P);\n",
        "}\n",
        "static void fill_rand_i32(vector<int32_t>&A,int R,int C,unsigned seed,int maxAbs=700){\n",
        "  mt19937 rng(seed); uniform_int_distribution<int>d(-maxAbs,maxAbs);\n",
        "  A.resize((size_t)R*C); for(auto&x:A)x=d(rng);\n",
        "}\n",
        "static uint64_t mix64(uint64_t x){ x^=x>>33; x*=0xff51afd7ed558ccdULL; x^=x>>33; x*=0xc4ceb9fe1a85ec53ULL; x^=x>>33; return x; }\n",
        "static uint64_t crt_hash_strided(const vector<int>& P, const int32_t* Ccol, int M,int N, int strideK){\n",
        "  uint64_t h=0; size_t S=(size_t)M*N, step=max<size_t>(1, S/max(1,strideK));\n",
        "  for(size_t i=0;i<S;i+=step){\n",
        "    int64_t v=Ccol[i]; for(int p: P){ int32_t r=(int32_t)(v%p); if(r<0) r+=p; h ^= mix64(((uint64_t)p<<32) ^ (uint64_t)r); }\n",
        "  } return h;\n",
        "}\n",
        "\n",
        "// int32→int8 mod pack (row-major)\n",
        "__global__ void k_pack_mod_s8(const int32_t* __restrict__ in, int8_t* __restrict__ out, int n, int p){\n",
        "  int i = blockDim.x*blockIdx.x + threadIdx.x;\n",
        "  for(int t=i; t<n; t+=gridDim.x*blockDim.x){\n",
        "    int32_t v=in[t]%p; if(v<0) v+=p; out[t]=(int8_t)v;\n",
        "  }\n",
        "}\n",
        "\n",
        "// C_reduce[MxN]: sum partials across splitK\n",
        "__global__ void k_reduce_splitk(const int32_t* __restrict__ parts, int32_t* __restrict__ C,\n",
        "                                int M, int N, int splitK){\n",
        "  size_t idx = blockDim.x*blockIdx.x + threadIdx.x;\n",
        "  size_t S=(size_t)M*N;\n",
        "  for(size_t t=idx; t<S; t+=gridDim.x*blockDim.x){\n",
        "    int64_t acc=0;\n",
        "    #pragma unroll\n",
        "    for(int s=0;s<splitK;s++) acc += (int64_t)parts[(size_t)s*S + t];\n",
        "    C[t] = (int32_t)acc;\n",
        "  }\n",
        "}\n",
        "\n",
        "struct Args{\n",
        "  int M=1024,N=1024,K=2048,primes=9,ms_min=450,splitK=4;\n",
        "  int recon_K=8192; long long cert_bound=0; unsigned seed=12345u;\n",
        "};\n",
        "static void parse(int argc,char**argv,Args&a){\n",
        "  for(int i=1;i<argc;i++){\n",
        "    string s=argv[i]; auto need=[&]{ if(i+1>=argc){fprintf(stderr,\"Missing %s\\n\",s.c_str()); exit(1);} };\n",
        "    if(s==\"--M\"){need(); a.M=atoi(argv[++i]);}\n",
        "    else if(s==\"--N\"){need(); a.N=atoi(argv[++i]);}\n",
        "    else if(s==\"--K\"){need(); a.K=atoi(argv[++i]);}\n",
        "    else if(s==\"--primes\"){need(); a.primes=atoi(argv[++i]);}\n",
        "    else if(s==\"--ms\"){need(); a.ms_min=atoi(argv[++i]);}\n",
        "    else if(s==\"--splitK\"){need(); a.splitK=atoi(argv[++i]);}\n",
        "    else if(s==\"--seed\"){need(); a.seed=(unsigned)strtoul(argv[++i],nullptr,10);}\n",
        "    else if(s==\"--reconK\"){need(); a.recon_K=atoi(argv[++i]);}\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc,char**argv){\n",
        "  ios::sync_with_stdio(false);\n",
        "  Args a; parse(argc,argv,a);\n",
        "  if(a.splitK<1) a.splitK=1;\n",
        "  if(a.K%a.splitK!=0){ fprintf(stderr,\"splitK must divide K exactly.\\n\"); return 2; }\n",
        "  const int kSlice = a.K / a.splitK;\n",
        "\n",
        "  cudaDeviceProp prop; CUDA_OK(cudaGetDeviceProperties(&prop,0),\"props\");\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" A100 SPLITK MULTIGRAPH (FIX)  GPU=%s  CC=%d.%d  SMs=%d\\n\", prop.name, prop.major, prop.minor, prop.multiProcessorCount);\n",
        "  printf(\" M=%d N=%d K=%d primes=%d  splitK=%d  ms_min=%d  seed=%u\\n\", a.M,a.N,a.K,a.primes,a.splitK,a.ms_min,a.seed);\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  // host data (row-major)\n",
        "  vector<int32_t> hA,hB; fill_rand_i32(hA,a.M,a.K,a.seed+1); fill_rand_i32(hB,a.K,a.N,a.seed+2);\n",
        "  // device int32 inputs\n",
        "  int32_t *dA32=nullptr,*dB32=nullptr;\n",
        "  size_t nA=(size_t)a.M*a.K, nB=(size_t)a.K*a.N;\n",
        "  CUDA_OK(cudaMalloc(&dA32, nA*sizeof(int32_t)),\"A32\");\n",
        "  CUDA_OK(cudaMalloc(&dB32, nB*sizeof(int32_t)),\"B32\");\n",
        "  CUDA_OK(cudaMemcpy(dA32,hA.data(),nA*sizeof(int32_t),cudaMemcpyHostToDevice),\"cpyA\");\n",
        "  CUDA_OK(cudaMemcpy(dB32,hB.data(),nB*sizeof(int32_t),cudaMemcpyHostToDevice),\"cpyB\");\n",
        "\n",
        "  // primes & prepacked s8\n",
        "  vector<int> P=primes_list(a.primes); int Pn=(int)P.size();\n",
        "  int8_t *dA8=nullptr,*dB8=nullptr;\n",
        "  CUDA_OK(cudaMalloc(&dA8, nA*Pn),\"A8\"); CUDA_OK(cudaMalloc(&dB8, nB*Pn),\"B8\");\n",
        "  dim3 t(512); dim3 gA((nA+t.x-1)/t.x), gB((nB+t.x-1)/t.x);\n",
        "  for(int pi=0; pi<Pn; ++pi){\n",
        "    k_pack_mod_s8<<<gA,t>>>(dA32, dA8 + (size_t)pi*nA, (int)nA, P[pi]);  // A: [M x K] row-major\n",
        "    k_pack_mod_s8<<<gB,t>>>(dB32, dB8 + (size_t)pi*nB, (int)nB, P[pi]);  // B: [K x N] row-major\n",
        "  }\n",
        "  CUDA_OK(cudaDeviceSynchronize(),\"pack sync\");\n",
        "\n",
        "  // partial outputs per slice (we store C^T slices as N×M col-major)\n",
        "  size_t nC = (size_t)a.M*a.N;\n",
        "  int32_t *dCparts=nullptr, *dC=nullptr;\n",
        "  CUDA_OK(cudaMalloc(&dCparts, nC * a.splitK * Pn * sizeof(int32_t)), \"Cparts\");\n",
        "  CUDA_OK(cudaMemset(dCparts, 0, nC * a.splitK * Pn * sizeof(int32_t)), \"zero parts\");\n",
        "  CUDA_OK(cudaMalloc(&dC, nC * Pn * sizeof(int32_t)), \"C\");\n",
        "\n",
        "  // ----- cuBLAS handles: one per (prime, slice) to avoid internal contention -----\n",
        "  const int graphsTot = Pn * a.splitK;\n",
        "  vector<cudaStream_t>    ss(graphsTot);\n",
        "  vector<cublasHandle_t>  hh(graphsTot);\n",
        "  vector<cudaGraph_t>     gs(graphsTot);\n",
        "  vector<cudaGraphExec_t> ex(graphsTot);\n",
        "\n",
        "  auto idx = [&](int pi,int s){ return pi*a.splitK + s; };\n",
        "\n",
        "  // GEMM dims for C^T = B^T · A^T  (both T = transpose trick)\n",
        "  const int m = a.N, n = a.M;      // C^T is [m x n] = [N x M]\n",
        "  const cublasOperation_t opA=CUBLAS_OP_T, opB=CUBLAS_OP_T;\n",
        "  // *** Correct leading dims for this trick ***\n",
        "  const int lda = a.N;  // B is [K x N] row-major → for opA=T, set lda=N\n",
        "  const int ldb = a.M;  // A is [M x K] row-major → for opB=T, set ldb=M\n",
        "  const int ldc = a.N;  // C^T is [N x M] col-major → leading dim = N\n",
        "  const int32_t alpha=1, beta=0;\n",
        "\n",
        "  for(int pi=0; pi<Pn; ++pi){\n",
        "    for(int s=0; s<a.splitK; ++s){\n",
        "      int id = idx(pi,s);\n",
        "      CUDA_OK(cudaStreamCreateWithFlags(&ss[id], cudaStreamNonBlocking), \"stream\");\n",
        "      CUBLAS_OK(cublasCreate(&hh[id]), \"cublasCreate\");\n",
        "      CUBLAS_OK(cublasSetMathMode(hh[id], CUBLAS_TENSOR_OP_MATH), \"math\");\n",
        "      CUBLAS_OK(cublasSetStream(hh[id], ss[id]), \"setStream\");\n",
        "\n",
        "      const int k0 = s * kSlice;\n",
        "      const int k  = kSlice;\n",
        "\n",
        "      // slice views into packed arrays (row-major underlying)\n",
        "      // B_slice: rows k0..k0+kSlice-1 of B[K x N]\n",
        "      const int8_t* A_slice = dB8 + (size_t)pi*nB + (size_t)k0*a.N; // goes to 'A' operand with opA=T\n",
        "      // A_slice_actual: columns k0.. in A[M x K]\n",
        "      const int8_t* B_slice = dA8 + (size_t)pi*nA + (size_t)k0;     // goes to 'B' operand with opB=T\n",
        "      int32_t*      C_out   = dCparts + ((size_t)pi*a.splitK + s)*nC;\n",
        "\n",
        "      CUDA_OK(cudaStreamBeginCapture(ss[id], cudaStreamCaptureModeGlobal), \"cap begin\");\n",
        "\n",
        "      CUBLAS_OK(cublasGemmEx(\n",
        "        hh[id], opA, opB, m, n, k,\n",
        "        &alpha,\n",
        "        A_slice, CUDA_R_8I, lda,\n",
        "        B_slice, CUDA_R_8I, ldb,\n",
        "        &beta,\n",
        "        C_out,   CUDA_R_32I, ldc,\n",
        "        CUDA_R_32I, CUBLAS_GEMM_DEFAULT_TENSOR_OP\n",
        "      ), \"gemm slice\");\n",
        "\n",
        "      CUDA_OK(cudaStreamEndCapture(ss[id], &gs[id]), \"cap end\");\n",
        "      CUDA_OK(cudaGraphInstantiate(&ex[id], gs[id], nullptr, nullptr, 0), \"inst\");\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // timing loop\n",
        "  int iters=0; auto t0=clk::now();\n",
        "  do{\n",
        "    for(int id=0; id<graphsTot; ++id) CUDA_OK(cudaGraphLaunch(ex[id], ss[id]), \"launch\");\n",
        "    for(int id=0; id<graphsTot; ++id) CUDA_OK(cudaStreamSynchronize(ss[id]), \"sync\");\n",
        "\n",
        "    // reduce all slices per prime into final C\n",
        "    int threads = 256;\n",
        "    int blocks  = (int)((nC + threads - 1)/threads);\n",
        "    for(int pi=0; pi<Pn; ++pi){\n",
        "      const int32_t* parts = dCparts + (size_t)pi*a.splitK*nC;\n",
        "      int32_t* Cout = dC + (size_t)pi*nC;\n",
        "      k_reduce_splitk<<<blocks,threads>>>(parts, Cout, a.M, a.N, a.splitK);\n",
        "    }\n",
        "    CUDA_OK(cudaDeviceSynchronize(),\"reduce sync\");\n",
        "\n",
        "    iters++;\n",
        "  }while( chrono::duration_cast<chrono::milliseconds>(clk::now()-t0).count() < a.ms_min );\n",
        "\n",
        "  double secs = chrono::duration<double>(clk::now()-t0).count();\n",
        "\n",
        "  // pull back & hash (read C^T as N×M col-major)\n",
        "  vector<int32_t> hC(nC*Pn);\n",
        "  CUDA_OK(cudaMemcpy(hC.data(), dC, nC*Pn*sizeof(int32_t), cudaMemcpyDeviceToHost), \"cpyC\");\n",
        "  uint64_t H=0;\n",
        "  for(int pi=0; pi<Pn; ++pi) H ^= crt_hash_strided(P, hC.data() + (size_t)pi*nC, a.N, a.M, a.recon_K);\n",
        "\n",
        "  double logical = (double)a.M*(double)a.N*(double)a.K;\n",
        "  double Gmac_s  = (logical*iters)/secs/1e9;\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [G011f_SPLITK_FIX] M=%d N=%d K=%d primes=%d splitK=%d graphs=%d iters=%d time=%.2f ms\\n\",\n",
        "         a.M,a.N,a.K,Pn,a.splitK,graphsTot,iters, secs*1000.0);\n",
        "  printf(\"  Logical MACs/s:        %.3f G-mac/s\\n\",  Gmac_s);\n",
        "  printf(\"  Modular MACs/s:        %.3f G-mac/s   (× primes)\\n\", Gmac_s*Pn);\n",
        "  printf(\"  dp4a-equiv inst/s:     %.3f G-inst/s  (~ modular/4)\\n\", (Gmac_s*Pn)/4.0);\n",
        "  printf(\"  CRT (strided) hash:    0x%016llx\\n\", (unsigned long long)H);\n",
        "  printf(\"  GRAPH: %d streams, %d cuBLAS handles (one per (prime,slice))\\n\", graphsTot, graphsTot);\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  for(auto& e: ex) cudaGraphExecDestroy(e);\n",
        "  for(auto& g: gs) cudaGraphDestroy(g);\n",
        "  for(auto& h: hh) cublasDestroy(h);\n",
        "  for(auto& s: ss) cudaStreamDestroy(s);\n",
        "  cudaFree(dC); cudaFree(dCparts); cudaFree(dA8); cudaFree(dB8); cudaFree(dA32); cudaFree(dB32);\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# build for A100\n",
        "nvcc -O3 -std=c++17 -arch=sm_80 g011f_fix_splitk_multigraph.cu -lcublas -o g011f_fix\n",
        "\n",
        "# sanity (matches your prior small run)\n",
        "./g011f_fix --M 512 --N 512 --K 512 --primes 5 --ms 280 --splitK 2\n",
        "\n",
        "# big (the one that crashed before)\n",
        "./g011f_fix --M 1024 --N 1024 --K 2048 --primes 9 --ms 450 --splitK 4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOHzhYQn0KUx",
        "outputId": "31ff2b86-b746-4956-ba47-9d7faeac4284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================\n",
            " A100 SPLITK MULTIGRAPH (FIX)  GPU=NVIDIA A100-SXM4-40GB  CC=8.0  SMs=108\n",
            " M=512 N=512 K=512 primes=5  splitK=2  ms_min=280  seed=12345\n",
            "============================================================================\n",
            "============================================================================\n",
            " [G011f_SPLITK_FIX] M=512 N=512 K=512 primes=5 splitK=2 graphs=10 iters=2518 time=280.10 ms\n",
            "  Logical MACs/s:        1206.563 G-mac/s\n",
            "  Modular MACs/s:        6032.816 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     1508.204 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x2d7d2109488843d0\n",
            "  GRAPH: 10 streams, 10 cuBLAS handles (one per (prime,slice))\n",
            "============================================================================\n",
            "============================================================================\n",
            " A100 SPLITK MULTIGRAPH (FIX)  GPU=NVIDIA A100-SXM4-40GB  CC=8.0  SMs=108\n",
            " M=1024 N=1024 K=2048 primes=9  splitK=4  ms_min=450  seed=12345\n",
            "============================================================================\n",
            "============================================================================\n",
            " [G011f_SPLITK_FIX] M=1024 N=1024 K=2048 primes=9 splitK=4 graphs=36 iters=476 time=450.17 ms\n",
            "  Logical MACs/s:        2270.693 G-mac/s\n",
            "  Modular MACs/s:        20436.236 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     5109.059 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x8cf76f1a394dfd9f\n",
            "  GRAPH: 36 streams, 36 cuBLAS handles (one per (prime,slice))\n",
            "============================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "\n",
        "# =============================================================================\n",
        "# G011f_FIX :: A100 cuBLAS INT8 RNS (MULTIGRAPH + SPLIT-K + on-GPU reduce)\n",
        "#  - Exact RNS int8 (primes ≤127), s8×s8→s32, TensorOp math (A100)\n",
        "#  - One-time GPU prepack (int32→int8) for A,B (row-major sources)\n",
        "#  - Per-prime Split-K: K sliced into 'splitK' stripes; each slice is its own\n",
        "#    captured cuBLAS GEMM in its own stream + its own cuBLAS handle\n",
        "#  - After all slices, sum partial C_s on GPU → exact int32 result\n",
        "#  - Transpose trick: compute Cᵗ (N×M, col-major) = Bᵗ(N×K) · Aᵗ(K×M)\n",
        "#    **Correct leading dims** for this path: lda=N, ldb=M, ldc=N\n",
        "#  - Build (A100):  nvcc -O3 -std=c++17 -arch=sm_80 g011f_fix_splitk_multigraph.cu -lcublas -o g011f_fix\n",
        "# =============================================================================\n",
        "\n",
        "cat > g011f_fix_splitk_multigraph.cu <<'CU'\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cublas_v2.h>\n",
        "using namespace std; using clk = chrono::high_resolution_clock;\n",
        "\n",
        "#define CUDA_OK(x,msg) do{ cudaError_t _e=(x); if(_e!=cudaSuccess){ \\\n",
        "  fprintf(stderr,\"CUDA ERROR @%s: %s\\n\", msg, cudaGetErrorString(_e)); exit(1);} }while(0)\n",
        "#define CUBLAS_OK(x,msg) do{ cublasStatus_t _s=(x); if(_s!=CUBLAS_STATUS_SUCCESS){ \\\n",
        "  fprintf(stderr,\"CUBLAS ERROR @%s: %d\\n\", msg, (int)_s); exit(1);} }while(0)\n",
        "\n",
        "static vector<int> primes_list(int P){\n",
        "  static const int all[] = {127,113,109,107,103,101,97,89,83,79,73,71,67,61,59,53,47,43,41,37,31,29,23,19,17,13,11,7,5,3};\n",
        "  int maxP=(int)(sizeof(all)/sizeof(all[0])); P=max(1,min(P,maxP));\n",
        "  return vector<int>(all, all+P);\n",
        "}\n",
        "static void fill_rand_i32(vector<int32_t>&A,int R,int C,unsigned seed,int maxAbs=700){\n",
        "  mt19937 rng(seed); uniform_int_distribution<int>d(-maxAbs,maxAbs);\n",
        "  A.resize((size_t)R*C); for(auto&x:A)x=d(rng);\n",
        "}\n",
        "static uint64_t mix64(uint64_t x){ x^=x>>33; x*=0xff51afd7ed558ccdULL; x^=x>>33; x*=0xc4ceb9fe1a85ec53ULL; x^=x>>33; return x; }\n",
        "static uint64_t crt_hash_strided(const vector<int>& P, const int32_t* Ccol, int M,int N, int strideK){\n",
        "  uint64_t h=0; size_t S=(size_t)M*N, step=max<size_t>(1, S/max(1,strideK));\n",
        "  for(size_t i=0;i<S;i+=step){\n",
        "    int64_t v=Ccol[i]; for(int p: P){ int32_t r=(int32_t)(v%p); if(r<0) r+=p; h ^= mix64(((uint64_t)p<<32) ^ (uint64_t)r); }\n",
        "  } return h;\n",
        "}\n",
        "\n",
        "// int32→int8 mod pack (row-major)\n",
        "__global__ void k_pack_mod_s8(const int32_t* __restrict__ in, int8_t* __restrict__ out, int n, int p){\n",
        "  int i = blockDim.x*blockIdx.x + threadIdx.x;\n",
        "  for(int t=i; t<n; t+=gridDim.x*blockDim.x){\n",
        "    int32_t v=in[t]%p; if(v<0) v+=p; out[t]=(int8_t)v;\n",
        "  }\n",
        "}\n",
        "\n",
        "// C_reduce[MxN]: sum partials across splitK\n",
        "__global__ void k_reduce_splitk(const int32_t* __restrict__ parts, int32_t* __restrict__ C,\n",
        "                                int M, int N, int splitK){\n",
        "  size_t idx = blockDim.x*blockIdx.x + threadIdx.x;\n",
        "  size_t S=(size_t)M*N;\n",
        "  for(size_t t=idx; t<S; t+=gridDim.x*blockDim.x){\n",
        "    int64_t acc=0;\n",
        "    #pragma unroll\n",
        "    for(int s=0;s<splitK;s++) acc += (int64_t)parts[(size_t)s*S + t];\n",
        "    C[t] = (int32_t)acc;\n",
        "  }\n",
        "}\n",
        "\n",
        "struct Args{\n",
        "  int M=1024,N=1024,K=2048,primes=9,ms_min=450,splitK=4;\n",
        "  int recon_K=8192; long long cert_bound=0; unsigned seed=12345u;\n",
        "};\n",
        "static void parse(int argc,char**argv,Args&a){\n",
        "  for(int i=1;i<argc;i++){\n",
        "    string s=argv[i]; auto need=[&]{ if(i+1>=argc){fprintf(stderr,\"Missing %s\\n\",s.c_str()); exit(1);} };\n",
        "    if(s==\"--M\"){need(); a.M=atoi(argv[++i]);}\n",
        "    else if(s==\"--N\"){need(); a.N=atoi(argv[++i]);}\n",
        "    else if(s==\"--K\"){need(); a.K=atoi(argv[++i]);}\n",
        "    else if(s==\"--primes\"){need(); a.primes=atoi(argv[++i]);}\n",
        "    else if(s==\"--ms\"){need(); a.ms_min=atoi(argv[++i]);}\n",
        "    else if(s==\"--splitK\"){need(); a.splitK=atoi(argv[++i]);}\n",
        "    else if(s==\"--seed\"){need(); a.seed=(unsigned)strtoul(argv[++i],nullptr,10);}\n",
        "    else if(s==\"--reconK\"){need(); a.recon_K=atoi(argv[++i]);}\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(int argc,char**argv){\n",
        "  ios::sync_with_stdio(false);\n",
        "  Args a; parse(argc,argv,a);\n",
        "  if(a.splitK<1) a.splitK=1;\n",
        "  if(a.K%a.splitK!=0){ fprintf(stderr,\"splitK must divide K exactly.\\n\"); return 2; }\n",
        "  const int kSlice = a.K / a.splitK;\n",
        "\n",
        "  cudaDeviceProp prop; CUDA_OK(cudaGetDeviceProperties(&prop,0),\"props\");\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" A100 SPLITK MULTIGRAPH (FIX)  GPU=%s  CC=%d.%d  SMs=%d\\n\", prop.name, prop.major, prop.minor, prop.multiProcessorCount);\n",
        "  printf(\" M=%d N=%d K=%d primes=%d  splitK=%d  ms_min=%d  seed=%u\\n\", a.M,a.N,a.K,a.primes,a.splitK,a.ms_min,a.seed);\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  // host data (row-major)\n",
        "  vector<int32_t> hA,hB; fill_rand_i32(hA,a.M,a.K,a.seed+1); fill_rand_i32(hB,a.K,a.N,a.seed+2);\n",
        "  // device int32 inputs\n",
        "  int32_t *dA32=nullptr,*dB32=nullptr;\n",
        "  size_t nA=(size_t)a.M*a.K, nB=(size_t)a.K*a.N;\n",
        "  CUDA_OK(cudaMalloc(&dA32, nA*sizeof(int32_t)),\"A32\");\n",
        "  CUDA_OK(cudaMalloc(&dB32, nB*sizeof(int32_t)),\"B32\");\n",
        "  CUDA_OK(cudaMemcpy(dA32,hA.data(),nA*sizeof(int32_t),cudaMemcpyHostToDevice),\"cpyA\");\n",
        "  CUDA_OK(cudaMemcpy(dB32,hB.data(),nB*sizeof(int32_t),cudaMemcpyHostToDevice),\"cpyB\");\n",
        "\n",
        "  // primes & prepacked s8\n",
        "  vector<int> P=primes_list(a.primes); int Pn=(int)P.size();\n",
        "  int8_t *dA8=nullptr,*dB8=nullptr;\n",
        "  CUDA_OK(cudaMalloc(&dA8, nA*Pn),\"A8\"); CUDA_OK(cudaMalloc(&dB8, nB*Pn),\"B8\");\n",
        "  dim3 t(512); dim3 gA((nA+t.x-1)/t.x), gB((nB+t.x-1)/t.x);\n",
        "  for(int pi=0; pi<Pn; ++pi){\n",
        "    k_pack_mod_s8<<<gA,t>>>(dA32, dA8 + (size_t)pi*nA, (int)nA, P[pi]);  // A: [M x K] row-major\n",
        "    k_pack_mod_s8<<<gB,t>>>(dB32, dB8 + (size_t)pi*nB, (int)nB, P[pi]);  // B: [K x N] row-major\n",
        "  }\n",
        "  CUDA_OK(cudaDeviceSynchronize(),\"pack sync\");\n",
        "\n",
        "  // partial outputs per slice (we store C^T slices as N×M col-major)\n",
        "  size_t nC = (size_t)a.M*a.N;\n",
        "  int32_t *dCparts=nullptr, *dC=nullptr;\n",
        "  CUDA_OK(cudaMalloc(&dCparts, nC * a.splitK * Pn * sizeof(int32_t)), \"Cparts\");\n",
        "  CUDA_OK(cudaMemset(dCparts, 0, nC * a.splitK * Pn * sizeof(int32_t)), \"zero parts\");\n",
        "  CUDA_OK(cudaMalloc(&dC, nC * Pn * sizeof(int32_t)), \"C\");\n",
        "\n",
        "  // ----- cuBLAS handles: one per (prime, slice) to avoid internal contention -----\n",
        "  const int graphsTot = Pn * a.splitK;\n",
        "  vector<cudaStream_t>    ss(graphsTot);\n",
        "  vector<cublasHandle_t>  hh(graphsTot);\n",
        "  vector<cudaGraph_t>     gs(graphsTot);\n",
        "  vector<cudaGraphExec_t> ex(graphsTot);\n",
        "\n",
        "  auto idx = [&](int pi,int s){ return pi*a.splitK + s; };\n",
        "\n",
        "  // GEMM dims for C^T = B^T · A^T  (both T = transpose trick)\n",
        "  const int m = a.N, n = a.M;      // C^T is [m x n] = [N x M]\n",
        "  const cublasOperation_t opA=CUBLAS_OP_T, opB=CUBLAS_OP_T;\n",
        "  // *** Correct leading dims for this trick ***\n",
        "  const int lda = a.N;  // B is [K x N] row-major → for opA=T, set lda=N\n",
        "  const int ldb = a.M;  // A is [M x K] row-major → for opB=T, set ldb=M\n",
        "  const int ldc = a.N;  // C^T is [N x M] col-major → leading dim = N\n",
        "  const int32_t alpha=1, beta=0;\n",
        "\n",
        "  for(int pi=0; pi<Pn; ++pi){\n",
        "    for(int s=0; s<a.splitK; ++s){\n",
        "      int id = idx(pi,s);\n",
        "      CUDA_OK(cudaStreamCreateWithFlags(&ss[id], cudaStreamNonBlocking), \"stream\");\n",
        "      CUBLAS_OK(cublasCreate(&hh[id]), \"cublasCreate\");\n",
        "      CUBLAS_OK(cublasSetMathMode(hh[id], CUBLAS_TENSOR_OP_MATH), \"math\");\n",
        "      CUBLAS_OK(cublasSetStream(hh[id], ss[id]), \"setStream\");\n",
        "\n",
        "      const int k0 = s * kSlice;\n",
        "      const int k  = kSlice;\n",
        "\n",
        "      // slice views into packed arrays (row-major underlying)\n",
        "      // B_slice: rows k0..k0+kSlice-1 of B[K x N]\n",
        "      const int8_t* A_slice = dB8 + (size_t)pi*nB + (size_t)k0*a.N; // goes to 'A' operand with opA=T\n",
        "      // A_slice_actual: columns k0.. in A[M x K]\n",
        "      const int8_t* B_slice = dA8 + (size_t)pi*nA + (size_t)k0;     // goes to 'B' operand with opB=T\n",
        "      int32_t*      C_out   = dCparts + ((size_t)pi*a.splitK + s)*nC;\n",
        "\n",
        "      CUDA_OK(cudaStreamBeginCapture(ss[id], cudaStreamCaptureModeGlobal), \"cap begin\");\n",
        "\n",
        "      CUBLAS_OK(cublasGemmEx(\n",
        "        hh[id], opA, opB, m, n, k,\n",
        "        &alpha,\n",
        "        A_slice, CUDA_R_8I, lda,\n",
        "        B_slice, CUDA_R_8I, ldb,\n",
        "        &beta,\n",
        "        C_out,   CUDA_R_32I, ldc,\n",
        "        CUDA_R_32I, CUBLAS_GEMM_DEFAULT_TENSOR_OP\n",
        "      ), \"gemm slice\");\n",
        "\n",
        "      CUDA_OK(cudaStreamEndCapture(ss[id], &gs[id]), \"cap end\");\n",
        "      CUDA_OK(cudaGraphInstantiate(&ex[id], gs[id], nullptr, nullptr, 0), \"inst\");\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // timing loop\n",
        "  int iters=0; auto t0=clk::now();\n",
        "  do{\n",
        "    for(int id=0; id<graphsTot; ++id) CUDA_OK(cudaGraphLaunch(ex[id], ss[id]), \"launch\");\n",
        "    for(int id=0; id<graphsTot; ++id) CUDA_OK(cudaStreamSynchronize(ss[id]), \"sync\");\n",
        "\n",
        "    // reduce all slices per prime into final C\n",
        "    int threads = 256;\n",
        "    int blocks  = (int)((nC + threads - 1)/threads);\n",
        "    for(int pi=0; pi<Pn; ++pi){\n",
        "      const int32_t* parts = dCparts + (size_t)pi*a.splitK*nC;\n",
        "      int32_t* Cout = dC + (size_t)pi*nC;\n",
        "      k_reduce_splitk<<<blocks,threads>>>(parts, Cout, a.M, a.N, a.splitK);\n",
        "    }\n",
        "    CUDA_OK(cudaDeviceSynchronize(),\"reduce sync\");\n",
        "\n",
        "    iters++;\n",
        "  }while( chrono::duration_cast<chrono::milliseconds>(clk::now()-t0).count() < a.ms_min );\n",
        "\n",
        "  double secs = chrono::duration<double>(clk::now()-t0).count();\n",
        "\n",
        "  // pull back & hash (read C^T as N×M col-major)\n",
        "  vector<int32_t> hC(nC*Pn);\n",
        "  CUDA_OK(cudaMemcpy(hC.data(), dC, nC*Pn*sizeof(int32_t), cudaMemcpyDeviceToHost), \"cpyC\");\n",
        "  uint64_t H=0;\n",
        "  for(int pi=0; pi<Pn; ++pi) H ^= crt_hash_strided(P, hC.data() + (size_t)pi*nC, a.N, a.M, a.recon_K);\n",
        "\n",
        "  double logical = (double)a.M*(double)a.N*(double)a.K;\n",
        "  double Gmac_s  = (logical*iters)/secs/1e9;\n",
        "  printf(\"============================================================================\\n\");\n",
        "  printf(\" [G011f_SPLITK_FIX] M=%d N=%d K=%d primes=%d splitK=%d graphs=%d iters=%d time=%.2f ms\\n\",\n",
        "         a.M,a.N,a.K,Pn,a.splitK,graphsTot,iters, secs*1000.0);\n",
        "  printf(\"  Logical MACs/s:        %.3f G-mac/s\\n\",  Gmac_s);\n",
        "  printf(\"  Modular MACs/s:        %.3f G-mac/s   (× primes)\\n\", Gmac_s*Pn);\n",
        "  printf(\"  dp4a-equiv inst/s:     %.3f G-inst/s  (~ modular/4)\\n\", (Gmac_s*Pn)/4.0);\n",
        "  printf(\"  CRT (strided) hash:    0x%016llx\\n\", (unsigned long long)H);\n",
        "  printf(\"  GRAPH: %d streams, %d cuBLAS handles (one per (prime,slice))\\n\", graphsTot, graphsTot);\n",
        "  printf(\"============================================================================\\n\");\n",
        "\n",
        "  for(auto& e: ex) cudaGraphExecDestroy(e);\n",
        "  for(auto& g: gs) cudaGraphDestroy(g);\n",
        "  for(auto& h: hh) cublasDestroy(h);\n",
        "  for(auto& s: ss) cudaStreamDestroy(s);\n",
        "  cudaFree(dC); cudaFree(dCparts); cudaFree(dA8); cudaFree(dB8); cudaFree(dA32); cudaFree(dB32);\n",
        "  return 0;\n",
        "}\n",
        "CU\n",
        "\n",
        "# build for A100\n",
        "nvcc -O3 -std=c++17 -arch=sm_80 g011f_fix_splitk_multigraph.cu -lcublas -o g011f_fix\n",
        "\n",
        "# sanity (matches your prior small run)\n",
        "./g011f_fix --M 512 --N 512 --K 512 --primes 5 --ms 280 --splitK 2\n",
        "\n",
        "# big (the one that crashed before)\n",
        "./g011f_fix --M 1024 --N 1024 --K 2048 --primes 9 --ms 450 --splitK 4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_eMJL9T3zJc",
        "outputId": "cf3e6342-522f-49aa-e16a-e8b95861169b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================\n",
            " A100 SPLITK MULTIGRAPH (FIX)  GPU=NVIDIA A100-SXM4-40GB  CC=8.0  SMs=108\n",
            " M=512 N=512 K=512 primes=5  splitK=2  ms_min=280  seed=12345\n",
            "============================================================================\n",
            "============================================================================\n",
            " [G011f_SPLITK_FIX] M=512 N=512 K=512 primes=5 splitK=2 graphs=10 iters=2330 time=280.04 ms\n",
            "  Logical MACs/s:        1116.734 G-mac/s\n",
            "  Modular MACs/s:        5583.670 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     1395.917 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x2d7d2109488843d0\n",
            "  GRAPH: 10 streams, 10 cuBLAS handles (one per (prime,slice))\n",
            "============================================================================\n",
            "============================================================================\n",
            " A100 SPLITK MULTIGRAPH (FIX)  GPU=NVIDIA A100-SXM4-40GB  CC=8.0  SMs=108\n",
            " M=1024 N=1024 K=2048 primes=9  splitK=4  ms_min=450  seed=12345\n",
            "============================================================================\n",
            "============================================================================\n",
            " [G011f_SPLITK_FIX] M=1024 N=1024 K=2048 primes=9 splitK=4 graphs=36 iters=472 time=450.31 ms\n",
            "  Logical MACs/s:        2250.902 G-mac/s\n",
            "  Modular MACs/s:        20258.121 G-mac/s   (× primes)\n",
            "  dp4a-equiv inst/s:     5064.530 G-inst/s  (~ modular/4)\n",
            "  CRT (strided) hash:    0x8cf76f1a394dfd9f\n",
            "  GRAPH: 36 streams, 36 cuBLAS handles (one per (prime,slice))\n",
            "============================================================================\n"
          ]
        }
      ]
    }
  ]
}